{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# major problem what we have is that the models try to generalise to all cells and do not focus on local temporal features\n",
    "\n",
    "in this notebook we are going to simplify our problem by only looking at the individual cells. This allows us to ocmpare different techniques like the moving averages and actual hawkes processes (point processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd /content/gdrive/My\\ Drive/masters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls ./data/processed\n",
    "\n",
    "# T1H-X1700M-Y1760M/  T24H-X850M-Y880M/  T3H-X850M-Y880M/\n",
    "# T12H-X850M-Y880M/  T24H-X425M-Y440M/   T24H-X85M-Y110M/   T6H-X850M-Y880M/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging as log\n",
    "from time import strftime\n",
    "from copy import deepcopy\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from utils.data_processing import *\n",
    "from logger.logger import setup_logging\n",
    "from utils.configs import BaseConf\n",
    "from utils.utils import write_json, Timer\n",
    "from models.kangkang_fnn_models import KangFeedForwardNetwork\n",
    "from dataloaders.flat_loader import FlatDataLoaders\n",
    "from datasets.flat_dataset import FlatDataGroup\n",
    "from utils.metrics import PRCurvePlotter, ROCCurvePlotter, LossPlotter\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score\n",
    "from models.model_result import ModelResult\n",
    "from utils.mock_data import mock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-19T19:42:10 | root | INFO | =====================================BEGIN=====================================\n",
      "2019-10-19T19:42:10 | root | INFO | Device: cpu\n",
      "2019-10-19T19:42:10 | root | INFO | Data shapes of files in generated_data.npz\n",
      "2019-10-19T19:42:10 | root | INFO | \tcrime_feature_indices shape (11,)\n",
      "2019-10-19T19:42:10 | root | INFO | \tcrime_types_grids shape (365, 11, 47, 33)\n",
      "2019-10-19T19:42:10 | root | INFO | \tcrime_grids shape (365, 1, 47, 33)\n",
      "2019-10-19T19:42:10 | root | INFO | \tdemog_grid shape (1, 37, 47, 33)\n",
      "2019-10-19T19:42:10 | root | INFO | \tstreet_grid shape (1, 512, 47, 33)\n",
      "2019-10-19T19:42:10 | root | INFO | \ttime_vectors shape (366, 52)\n",
      "2019-10-19T19:42:10 | root | INFO | \tweather_vectors shape (365, 11)\n",
      "2019-10-19T19:42:10 | root | INFO | \tx_range shape (33,)\n",
      "2019-10-19T19:42:10 | root | INFO | \ty_range shape (47,)\n",
      "2019-10-19T19:42:10 | root | INFO | \tt_range shape (366,)\n",
      "shape crimes_train ->  (256, 1, 763)\n",
      "shape crimes ->  (364, 1, 763)\n"
     ]
    }
   ],
   "source": [
    "data_dim_str = \"T24H-X850M-Y880M\"  #\"T1H-X1700M-Y1760M\"  # needs to exist\n",
    "model_name = \"RNN-CRIME-MODEL\"  # needs to be created\n",
    "\n",
    "data_path = f\"./data/processed/{data_dim_str}/\"\n",
    "model_path = data_path + f\"models/{model_name}/\"\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# logging config is set globally thus we only need to call this in this file\n",
    "# imported function logs will follow the configuration\n",
    "setup_logging(save_dir=model_path, log_config='./logger/standard_logger_config.json', default_level=log.INFO)\n",
    "log.info(\"=====================================BEGIN=====================================\")\n",
    "\n",
    "# manually set the config\n",
    "conf_dict = {\n",
    "    \"seed\": 3,\n",
    "    \"use_cuda\": False,\n",
    "    \n",
    "    \"use_crime_types\": False,\n",
    "    \n",
    "    # data group/data set related\n",
    "    \"val_ratio\": 0.1,  # ratio of the total dataset\n",
    "    \"tst_ratio\": 0.2,# ratio of the total dataset\n",
    "    \"seq_len\": 1,\n",
    "    \"flatten_grid\": True,  # if the shaper should be used to squeeze the data\n",
    "    \n",
    "    # shaper related \n",
    "    \"shaper_top_k\": -1,  # if less then 0, top_k will not be applied\n",
    "    \"shaper_threshold\": 0,\n",
    "\n",
    "    \n",
    "    # data loader related\n",
    "    \"sub_sample_train_set\": True,\n",
    "    \"sub_sample_validation_set\": True,\n",
    "    \"sub_sample_test_set\": False,\n",
    "    \n",
    "    # training parameters\n",
    "    \"resume\": False,\n",
    "    \"early_stopping\": False,\n",
    "    \"tolerance\": 1e-8,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-8,\n",
    "    \"max_epochs\": 1,\n",
    "    \"batch_size\": 64,\n",
    "    \"dropout\": 0.2,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 6,\n",
    "}\n",
    "conf = BaseConf(conf_dict=conf_dict)\n",
    "conf.timer = Timer()\n",
    "\n",
    "info = deepcopy(conf.__dict__)\n",
    "info[\"start_time\"] = strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "# DATA LOADER SETUP\n",
    "np.random.seed(conf.seed)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(conf.seed)\n",
    "else:\n",
    "    torch.manual_seed(conf.seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "log.info(f\"Device: {device}\")\n",
    "info[\"device\"] = device.type\n",
    "conf.device = device\n",
    "\n",
    "# GET DATA\n",
    "data_group = FlatDataGroup(data_path=data_path, conf=conf)\n",
    "loaders = FlatDataLoaders(data_group=data_group, conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2595"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders = FlatDataLoaders(data_group=data_group,conf=conf)\n",
    "len(loaders.train_loader)  # loader outputs are dependent on the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grids = data_group.shaper.unsqueeze(data_group.crimes)[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating mock data for the models\n",
    "### Cumsum example from tutorial [5 Examples of Simple Sequence Prediction Problems for LSTMs](https://machinelearningmastery.com/sequence-prediction-problems-learning-lstm-recurrent-neural-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.mock_data import mock_rnn_data\n",
    "from utils.plots import im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockLoaders:\n",
    "    def __init__(self, train_loader=None, validation_loader=None, test_loader=None):\n",
    "        self.train_loader = train_loader\n",
    "        self.validation_loader = validation_loader\n",
    "        self.test_loader = test_loader\n",
    "    \n",
    "\n",
    "class MockRNNLoader:\n",
    "    def __init__(self, seq_len, batch_size, n_samples):\n",
    "        \n",
    "        X,t = mock_rnn_data(seq_len=seq_len, batch_size=n_samples) #(seq_len, n_features, batch_size)\n",
    "        X,t  = np.swapaxes(X,1,2),np.swapaxes(t,1,2) # (seq_len, batch, input_size)\n",
    "                \n",
    "        \n",
    "        indices = np.expand_dims(np.arange(n_samples), axis=0)\n",
    "        indices = np.expand_dims(indices, axis=2)\n",
    "        \n",
    "        vectors = [indices]\n",
    "        i = 0\n",
    "        for j in vector_size:\n",
    "            vectors.append(X[:,:,i:i+j])\n",
    "            i += j\n",
    "        vectors.append(y)    \n",
    "        \n",
    "        self.n_samples = n_samples\n",
    "        self.n_feats = n_feats\n",
    "        self.vectors = vectors\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = int(np.ceil(self.n_samples / self.batch_size))\n",
    "        self.current_batch = 0\n",
    "        \n",
    "        \n",
    "        self.max_index = n_samples\n",
    "        self.min_index = 0\n",
    "        self.dataset = self # just to act as an interface\n",
    "   \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.current_batch = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_batch >= self.num_batches:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.current_batch += 1\n",
    "            start_index = (self.current_batch - 1) * self.batch_size\n",
    "            stop_index = self.current_batch * self.batch_size\n",
    "            if stop_index > len(self):\n",
    "                stop_index = len(self)\n",
    "            return self[start_index:stop_index]\n",
    "        \n",
    "            \n",
    "    def __getitem__(self, index):        \n",
    "        return tuple(map(lambda x: x[:,index], self.vectors))\n",
    "    \n",
    "vector_size= [3,6,13]#[37,65,512]\n",
    "batch_size = 100    \n",
    "class_split=0.5\n",
    "train_loader = MockLoader(vector_size, batch_size, n_samples=7000, class_split=class_split)\n",
    "validation_loader = MockLoader(vector_size, batch_size, n_samples=1000, class_split=class_split)\n",
    "test_loader = MockLoader(vector_size, batch_size, n_samples=2000, class_split=class_split)\n",
    "loaders = MockLoaders(train_loader,validation_loader,test_loader)\n",
    "\n",
    "X,t = mock_rnn_data() #(seq_len, n_features, batch_size)\n",
    "X,t  = np.swapaxes(X,1,2),np.swapaxes(t,1,2) # (seq_len, batch, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAI3CAYAAAC8k9CMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAcyUlEQVR4nO3dbaxlV3kf8P+TMcbFQAIYiGM7sZuaFgslEI1MUkuNeQuGVjiRArLbIiey6n7ASXhRGyetSET7IUkTaKpaJENwgYjgUIeUEXXjUIeIpiqux0CNX2Jl5FA82MUYCEFBYDz36Yd7HC43c1/m3nvO3WfN7ycdzdnn7Lv3utt7Rsv/9ay1q7sDALAMvm2/GwAAsF06LgDA0tBxAQCWho4LALA0dFwAgKWh4wIALA0dFwBgLqrqhqp6uKru2uD7qqr/UFVHq+rOqvqBrY6p4wIAzMu7kly2yfevSHLh7HVNkrdvdUAdFwBgLrr7o0m+uMkulyd5T6/6WJLvqKqzNzvmaXvZQABg/7z8RWf2F754fCHnuuPOr9+d5GtrPjrU3YdO8jDnJHlgzfax2WcPbfQDOi4AMIgvfPF4/vct372Qcx04+8++1t0Hd3mYOsFnmz6LyFARALBfjiU5b832uUke3OwHJC4AMIhOspKV/W7GyTic5NqqujHJC5N8ubs3HCZKdFwAgDmpqvcluTTJWVV1LMkvJHlCknT3byS5OckrkxxN8tUkP7nVMXVcAGAYneM9ncSlu6/c4vtO8rqTOaYaFwBgaUhcAGAQqzUum07KWXoSFwBgaUhcAGAgSzar6KRJXACApSFxAYBBdDrHW40LAMAkSFwAYCBmFQEATISOCwCwNAwVAcAgOslxQ0UAANMgcQGAgSjOBQCYCIkLAAyiEwvQAQBMhcQFAAYy9iMWJS4AwBKRuADAIDptHRcAgKmQuADAKDo5PnbgInEBAJaHxAUABtExqwgAYDIkLgAwjMrx1H43Yq4kLgDA0tBxAQCWhqEiABhEJ1kxHRoAYBokLgAwEMW5AAATIXEBgEF0JC4AAJMhcQGAgay0xAUAYBIkLgAwCDUuAAATInEBgEF0KscHzyTG/u0AgKFIXABgIGYVAQBMhMQFAAZhVhEAwITouAAAS8NQEQAMo3K8x84kxv7tAIChSFwAYBCdZGXwTGLs3w4AGIrEBQAGYjo0AMBESFwAYBDdZhUBAEyGxAUABrKixgUAYBokLgAwiNWHLI6dSYz92wEAQ5G4AMAwzCoCAJgMiQsADMKzigAAJkTHBQBYGoaKAGAgx9sCdAAAkyBxAYBBdMoCdAAAUyFxAYCBrFiADgBgGiQuADAID1kEAJgQiQsADKJT1nEBAJgKiQsADMRDFgEAJkLiAgCD6E6OW8cFAGAaJC4AMIzKSswqAgCYBB0XAGBpGCoCgEF0FOcCAEyGxAUABuIhiwAAEyFxAYBBdCorHrIIADANEhcAGIgaFwCAiZC4AMAgOsmKdVwAAKZB4gIAw6gc95BFAIBpkLgAwCDUuAAATIjEBQAGosYFAGAiJC4AMIjuUuMCADAVOi4AwNIwVAQAAzluqAgAYBokLgAwiE6yYjo0AMDJq6rLquq+qjpaVded4PvvrqqPVNUnqurOqnrlVseUuADAMGoyNS5VdSDJ9UleluRYktur6nB337Nmt3+d5P3d/faquijJzUnO3+y40/jtAIDRXJzkaHff392PJrkxyeXr9ukkT529//YkD251UIkLAAxi9SGLC6txOauqjqzZPtTdh9Zsn5PkgTXbx5K8cN0xfjHJH1bVTyU5M8lLtzqpjgsAsBOPdPfBTb4/UQ+q121fmeRd3f1rVfVDSX67qp7X3SsbHVTHBQAGcnw6VSDHkpy3Zvvc/M2hoKuTXJYk3f2/quqMJGcleXijg07mtwMAhnJ7kgur6oKqOj3JFUkOr9vnM0lekiRV9dwkZyT5/GYHlbgAwCA6tcgal01192NVdW2SW5IcSHJDd99dVW9JcqS7Dyd5U5J3VNUbsjqM9BPdvX446VvouAAAc9HdN2d1ivPaz9685v09SS45mWPquADAQFYGrwIZ+7cDAIYicQGAQXQnxydS4zIvEhcAYGnouAAAS8NQEQAMZCrToedF4gIALA2JCwAMYnUBurEzibF/OwBgKBIXABjI8RM+lHkcEhcAYGlIXABgEB2zigAAJkPiAgDDMKsIAGAyJC4AMJAVs4oAAKZB4gIAg+hOjptVBAAwDRIXABiIWUUAABOh4wIALA1DRQAwiE5Z8h8AYCokLgAwEAvQAQBMhMQFAAbRiRoXAICpkLgAwEAsQAcAMBESFwAYRVvHBQBgMiQuADCIjnVcAAAmQ+ICAANR4wIAMBESFwAYhJVzAQAmRMcFAFgahooAYCCGigAAJkLiAgCD6FjyHwBgMiQuADAQS/4DAEyExAUARtFmFQEATIbEBQAGYcl/AIAJkbgAwEAkLgAAEyFxAYBBWDkXAGBCJC4AMJCWuAAATIOOCwCwNAwVAcBAPGQRAGAiJC4AMIj2kEUAgOmQuADAQEyHBgCYCIkLAAzDkv8AAJMhcQGAgahxAQCYCIkLAAyiYx0XAIDJkLgAwCh6dfXckUlcAIClIXEBgIF4OjQAwETouAAAS8NQEQAMomMBOgCAyZC4AMAwPGQRAGAyJC4AMBAL0AEATITEBQAGYlYRAMBESFwAYBDdEhcAgMmQuADAQKzjAgAwERIXABiIdVwAACZC4gIAAzGrCABgInbVcamqy6rqvqo6WlXX7VWjAABOZMdDRVV1IMn1SV6W5FiS26vqcHffs9HPnF5P7DNy5k5PCQBL5Wv5qzzaX1/Y2E2nhh8q2k2Ny8VJjnb3/UlSVTcmuTzJhh2XM3JmXlgv2cUpAWB53Na37ncThrOboaJzkjywZvvY7LNvUVXXVNWRqjryjXx9F6cDALbSC3rtl910XE6URf2N36W7D3X3we4++IQ8cRenAwBOdbsZKjqW5Lw12+cmeXB3zQEAdsxDFjd1e5ILq+qCqjo9yRVJDu9NswAA/qYdJy7d/VhVXZvkliQHktzQ3XfvWcsAgJM3+JL/u1o5t7tvTnLzHrUFAGBTlvwHgIGocQEAmAgdFwAYSPdiXtuxnUcDVdVrquqeqrq7qn5nq2MaKgIA9tx2Hg1UVRcm+bkkl3T3l6rqWVsdV8cFAAbRmVSNy3YeDfTPklzf3V9Kku5+eKuDGioCAHbirMcf6TN7XbPu++08Gug5SZ5TVf+zqj5WVZdtdVKJCwCMopMsLnF5pLsPbvL9dh4NdFqSC5NcmtUV+P9HVT2vu/9io4NKXACAedjOo4GOJflgd3+ju/88yX1Z7chsSMcFAJiH7Twa6L8keVGSVNVZWR06un+zgxoqAoCBbHeq8rxt9GigqnpLkiPdfXj23Y9U1T1Jjif5F939hc2Oq+MCAMzFiR4N1N1vXvO+k7xx9toWHRcAGMlEEpd5UeMCACwNiQsADKOmtADdXOyq41JVn07ylawW1Dy2xXxuAIBd2YvE5UXd/cgeHAcA2C01LgAA07DbxKWT/GFVdZLf7O5D63eYPbvgmiQ5I0/a5ekAgA31pB6yOBe77bhc0t0Pzh5D/eGq+tPu/ujaHWadmUNJ8tR6+uABFgAwT7saKuruB2d/Ppzk97P6CGsAYL/0gl77ZMcdl6o6s6qe8vj7JD+S5K69ahgAwHq7GSp6dpLfr6rHj/M73f0He9IqAGCH1LicUHffn+T797AtAACbsnIuAIxk8Gkw1nEBAJaGjgsAsDQMFQHASAwVAQBMg8QFAEbRSQZf8l/iAgAsDYkLAAyk1bgAAEyDxAUARiJxAQCYBokLAIzErCIAgGnYsuNSVTdU1cNVddeaz55eVR+uqj+b/fm0+TYTANiO6sW89st2Epd3Jbls3WfXJbm1uy9McutsGwBgrrbsuHT3R5N8cd3Hlyd59+z9u5P86B63CwA4Wb3A1z7ZaY3Ls7v7oSSZ/fmsjXasqmuq6khVHflGvr7D0wEALGBWUXcfSnIoSZ5aTx98djkA7KcaflbRTjsun6uqs7v7oao6O8nDe9moKbnlwU9+y/bLv+v5+9QSWLX+nkzcl8CpY6dDRYeTXDV7f1WSD+5NcwAANrZl4lJV70tyaZKzqupYkl9I8ktJ3l9VVyf5TJJXz7ORAMA2DV6UsWXHpbuv3OCrl+xxWwAANmXJfwAYyameuEyRgtn5W2QBqGLT8e3n39kT3V/r7Wd7TuVrATuxlB0XAGADgycuHrIIACwNiQsAjKJjAbp52k5tw3bGZE8VUxufnlptyk5qB3Z6TdVZsUhT+7u/n1wLJC4AMJBS4wIAMA0SFwAYicQFAGAaFpq4POf7vppbbllMse12iid3Uvi702LhRRWL7bRgdtmKoKfW3p0Wmisi3J29ug928u/F1P5eTe3vxHpTu//n2Z61x7745V/dk2PyTRIXAGBpqHEBgIGc8rOKquqGqnq4qu5a89kvVtVnq+qTs9cr59tMAIDtJS7vSvIfk7xn3edv6+5f3fMWncLmtaiZxdK+aRlrDvaiFmte99KJzPNc+1krNs+fm9dx5nXuU6V+a2kXuxt85dwtE5fu/miSLy6gLQAAm9pNce61VXXnbCjpaRvtVFXXVNWRqjry+S8c38XpAIBT3U47Lm9P8r1Jnp/koSS/ttGO3X2ouw9298FnPuPADk8HAGypF/jaJzuaVdTdn3v8fVW9I8mH9qpBi1xbZerm9Xvt9/Xazvn3okZjv3/P7Zh6/dEyXMP94tpsbq/+LZ/a34n13AeLt6PEparOXrP5Y0nu2mhfAGCBTvXEparel+TSJGdV1bEkv5Dk0qp6flab/ukk/3yObQQASLKNjkt3X3mCj985h7YAALt0yi9ABwAwFZb8hwHsRYHgfi+etpOi7RGM+Dtt1yInIEztoZhzJXEBAJgGiQsAjETiAgAwDadM4jK1scuptYdpWMaHQC7budm9ZbxPT5V7rtqsIgCAyThlEhcAOCV07XcL5kriAgAsDYkLAIxk8BoXHZcFOVUKw+b1tGOFpAAkhooAgCUicQGAgZgODQAwEVsmLlV1XpL3JPnOJCtJDnX3r1fV05P8bpLzk3w6yWu6+0vzayr7bSe1HupDpsF/BziFSFzyWJI3dfdzk/xgktdV1UVJrktya3dfmOTW2TYAwNxsmbh090NJHpq9/0pV3ZvknCSXJ7l0ttu7k/xxkp+dSysBgK1Z8v9bVdX5SV6Q5LYkz551ah7v3Dxrg5+5pqqOVNWRz3/h+O5aCwCc0rbdcamqJyf5vSSv7+6/3O7Pdfeh7j7Y3Qef+YwDO2kjALBdvaDXPtlWx6WqnpDVTst7u/sDs48/V1Vnz74/O8nD82kiAMCqLTsuVVVJ3pnk3u5+65qvDie5avb+qiQf3PvmAQAnZfDEZTsL0F2S5LVJPlVVj8+p/Pkkv5Tk/VV1dZLPJHn1fJoIALBqO7OK/iTJRs/IfsneNgcA2A2zigAAJkLHBQBYGjouAMDS8HRoABiJGhcAgGnQcQEAloahIgAYhYcsAgBMh8QFAEYicQEAmAaJCwCMROICADANEhcAGETFrKJU1XlV9ZGqureq7q6qn5l9/otV9dmq+uTs9cr5NxcAOJVtJ3F5LMmbuvvjVfWUJHdU1Ydn372tu391fs0DAE7K4InLlh2X7n4oyUOz91+pqnuTnDPvhgEArHdSxblVdX6SFyS5bfbRtVV1Z1XdUFVP2+BnrqmqI1V15PNfOL6rxgIAm5itnLuI137Zdselqp6c5PeSvL67/zLJ25N8b5LnZzWR+bUT/Vx3H+rug9198JnPOLAHTQYATlXbmlVUVU/Iaqflvd39gSTp7s+t+f4dST40lxYCANs3eI3LdmYVVZJ3Jrm3u9+65vOz1+z2Y0nu2vvmAQB803aGii5J8tokL1439flXqupTVXVnkhclecM8GwoAbEMv6LUNVXVZVd1XVUer6rpN9vvxquqqOrjVMbczq+hPsrqmzXo3b/WzAMCpqaoOJLk+ycuSHEtye1Ud7u571u33lCQ/nW9O/NmUJf8BgHm4OMnR7r6/ux9NcmOSy0+w379J8itJvradg+q4AMBAFjgd+qzHlzuZva5Z15RzkjywZvtY1q0DV1UvSHJed297go9nFQEAO/FId29Wk3KiMpO/ro6pqm9L8rYkP3EyJ9VxAYCRTGc69LEk563ZPjfJg2u2n5LkeUn+eHUCc74zyeGqelV3H9nooIaKAIB5uD3JhVV1QVWdnuSKJIcf/7K7v9zdZ3X3+d19fpKPJdm005LouADAOBY1FXobqU53P5bk2iS3JLk3yfu7++6qektVvWqnv6KhIgBgLrr75qxbPqW737zBvpdu55g6LgAwkP18AOIiGCoCAJaGxAUARiJxAQCYBokLAAxEjQsAwERIXABgJIMnLgvtuNxx59cfOXD20f+b5Kwkjyzy3Kcg13gxXOf5c43nzzWen+/Z7waMZqEdl+5+ZpJU1ZEtHszELrnGi+E6z59rPH+u8UC2uartMlPjAgAsDR0XAGBp7Fdx7qF9Ou+pxDVeDNd5/lzj+XONB1Gz18j2JXHpbn9J5sw1XgzXef5c4/lzjVkmpkMDwEgU5wIATMPCOy5VdVlV3VdVR6vqukWff0RVdV5VfaSq7q2qu6vqZ2afP72qPlxVfzb782n73dZlV1UHquoTVfWh2fYFVXXb7Br/blWdvt9tXGZV9R1VdVNV/ensfv4h9/Heq6o3zP6tuKuq3ldVZ7iXx1G9mNd+WWjHpaoOJLk+ySuSXJTkyqq6aJFtGNRjSd7U3c9N8oNJXje7rtclubW7L0xy62yb3fmZJPeu2f7lJG+bXeMvJbl6X1o1jl9P8gfd/feSfH9Wr7X7eA9V1TlJfjrJwe5+XpIDSa6Ie5klsejE5eIkR7v7/u5+NMmNSS5fcBuG090PdffHZ++/ktV/7M/J6rV992y3dyf50f1p4Riq6twk/zDJb822K8mLk9w028U13oWqemqSf5DknUnS3Y9291/EfTwPpyX5W1V1WpInJXko7uVx9IJe+2TRHZdzkjywZvvY7DP2SFWdn+QFSW5L8uzufihZ7dwkedb+tWwI/z7Jv0yyMtt+RpK/6O7HZtvu593520k+n+Q/zYbjfquqzoz7eE9192eT/GqSz2S1w/LlJHfEvcySWHTH5UTTywevf16cqnpykt9L8vru/sv9bs9IquofJXm4u+9Y+/EJdnU/79xpSX4gydu7+wVJ/iqGhfbcrEbo8iQXJPmuJGdmdfh+PffyspK47KljSc5bs31ukgcX3IYhVdUTstppeW93f2D28eeq6uzZ92cneXi/2jeAS5K8qqo+ndUhzhdnNYH5jlncnrifd+tYkmPdfdts+6asdmTcx3vrpUn+vLs/393fSPKBJH8/7mWWxKI7LrcnuXBWvX56VgvCDi+4DcOZ1Vq8M8m93f3WNV8dTnLV7P1VST646LaNort/rrvP7e7zs3rf/lF3/5MkH0ny47PdXONd6O7/l+SBqvq7s49ekuSeuI/32meS/GBVPWn2b8fj19m9PIIFzSjaz1lFi3469GNVdW2SW7JayX5Dd9+9yDYM6pIkr03yqar65Oyzn0/yS0neX1VXZ/Ufq1fvU/tG9rNJbqyqf5vkE5kVlrJjP5XkvbP/sbk/yU9m9X+w3Md7pLtvq6qbknw8qzMSP5HVJf//a9zLLIHqNowJACN40rPO6+e85o0LOdf/uf6Nd3T3wYWcbA0r5wIAS8OzigBgIPtZf7IIEhcAYGnouAAAS8NQEQCMxFARAMA0SFwAYCCKcwEAJkLiAgCj2OcHIC6CxAUAWBoSFwAYicQFAGAaJC4AMIiKWUUAAJMhcQGAkUhcAACmQeICAAOpHjtykbgAAEtD4gIAo7ByLgDAdOi4AABLw1ARAAzEAnQAABMhcQGAkUhcAACmQeICAANR4wIAMBESFwAYicQFAGAaJC4AMIpW4wIAMBkSFwAYicQFAGAaJC4AMIiKGhcAgMmQuADASHrsyEXiAgAsDR0XAGBpGCoCgIEozgUAmAiJCwCMomMBOgCAqZC4AMBAamW/WzBfEhcAYGlIXABgJGpcAACmQeICAAOxjgsAwERIXABgFB0PWQQAmAqJCwAMRI0LAMBESFwAYCQSFwCAadBxAQCWhqEiABhERXEuAMBkSFwAYBTdFqADAJgKiQsADESNCwDAREhcAGAkEhcAgGmQuADAQNS4AABMhMQFAEbRSVbGjlwkLgDA0pC4AMBIxg5cJC4AwPKQuADAQMwqAgCYCB0XAGBpGCoCgJH02GNFEhcAYGlIXABgIIpzAQAmQscFAEbRC3xtQ1VdVlX3VdXRqrruBN+/saruqao7q+rWqvqerY6p4wIA7LmqOpDk+iSvSHJRkiur6qJ1u30iycHu/r4kNyX5la2Oq+MCAIOoJNW9kNc2XJzkaHff392PJrkxyeVrd+juj3T3V2ebH0ty7lYH1XEBAHbirKo6suZ1zbrvz0nywJrtY7PPNnJ1kv+21UnNKgKAkaws7EyPdPfBTb6vE3x2wqimqv5pkoNJfnirk+q4AADzcCzJeWu2z03y4PqdquqlSf5Vkh/u7q9vdVAdFwAYyDbrTxbh9iQXVtUFST6b5Iok/3jtDlX1giS/meSy7n54OwdV4wIA7LnufizJtUluSXJvkvd3991V9ZaqetVst3+X5MlJ/nNVfbKqDm91XIkLAIziJNZYWYTuvjnJzes+e/Oa9y892WNKXACApSFxAYBhtKdDAwBMhcQFAAbi6dAAABOh4wIALA1DRQAwEsW5AADTIHEBgFF0Uot7yOK+kLgAAEtD4gIAI1HjAgAwDRIXABjJ2IGLxAUAWB4SFwAYSKlxAQCYBokLAIxE4gIAMA0SFwAYRSexci4AwDRIXABgEJU2qwgAYCp0XACApWGoCABGYqgIAGAaJC4AMBKJCwDANEhcAGAUFqADAJgOiQsADMQCdAAAEyFxAYCRSFwAAKZB4gIAw2iJCwDAVEhcAGAUHYkLAMBUSFwAYCRWzgUAmAYdFwBgaRgqAoCBWPIfAGAiJC4AMBKJCwDANEhcAGAUnWRF4gIAMAkSFwAYhocsAgBMhsQFAEYicQEAmAaJCwCMROICADANEhcAGIV1XAAApkPiAgDD6KRX9rsRcyVxAQCWho4LALA0DBUBwEhMhwYAmAaJCwCMwnRoAIDpkLgAwEjUuAAATIPEBQBGInEBAJgGiQsADKMlLgAAUyFxAYBRdJIVD1kEAJgEiQsAjESNCwDANEhcAGAkEhcAgGnQcQEAloahIgAYRicrhooAACZB4gIAo+ik2wJ0AACTIHEBgJGocQEAmAaJCwCMxAJ0AADTIHEBgFF0JytmFQEATILEBQBGosYFAGAaJC4AMJBW4wIAMA0SFwAYRqtxAQCYCh0XAGBpGCoCgFF0PGQRAGAqJC4AMJI2HRoAYBIkLgAwiE7SalwAAKZB4gIAo+hW4wIAMBUSFwAYiBoXAIAdqKrLquq+qjpaVded4PsnVtXvzr6/rarO3+qYOi4AMJJeWcxrC1V1IMn1SV6R5KIkV1bVRet2uzrJl7r77yR5W5Jf3uq4Oi4AwDxcnORod9/f3Y8muTHJ5ev2uTzJu2fvb0rykqqqzQ6qxgUABvGVfOmW/943nbWg051RVUfWbB/q7kNrts9J8sCa7WNJXrjuGH+9T3c/VlVfTvKMJI9sdFIdFwAYRHdftt9tWONEycn6yuHt7PMtDBUBAPNwLMl5a7bPTfLgRvtU1WlJvj3JFzc7qI4LADAPtye5sKouqKrTk1yR5PC6fQ4nuWr2/seT/FF3b5q4GCoCAPbcrGbl2iS3JDmQ5Ibuvruq3pLkSHcfTvLOJL9dVUezmrRcsdVxa4uODQDAZBgqAgCWho4LALA0dFwAgKWh4wIALA0dFwBgaei4AABLQ8cFAFga/x+DcfZN0oFOvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X,t = mock_rnn_data(seq_len=30,batch_size=100) #(seq_len, n_features, batch_size)\n",
    "X,t  = np.swapaxes(X,1,2),np.swapaxes(t,1,2) # (seq_len, batch, input_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUMLPClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    GRU then a MLP (flattens data output to easier use in NLLLoss)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(GRUMLPClassifier, self).__init__()\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)  # note batch first\n",
    "        self.lin1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.lin2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, h0=None):\n",
    "        if h0 is not None:\n",
    "            out, hn = self.gru(x, h0)\n",
    "        else:\n",
    "            out, hn = self.gru(x)  # hidden state start is zero\n",
    "        out = self.lin1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.lin2(out)\n",
    "\n",
    "        # Reshape output to (batch_size*seq_len, hidden_size)\n",
    "        out = out.contiguous().view(out.size(0) * out.size(1), out.size(2))\n",
    "\n",
    "        return out  # if we never send h its never detached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# epoch_loop - wrapper with checkpoint saving and logging\n",
    "# tmp is only per epoch. all is for all epoch\n",
    "# train_loop - use conf to get device?\n",
    "def train_epoch_fnn(model, optimiser, batch_loader, total_losses, device):\n",
    "    \"\"\"\n",
    "    Training the model for a single epoch\n",
    "    \"\"\"\n",
    "    epoch_losses = []\n",
    "    num_batches = batch_loader.num_batches\n",
    "    for indices, spc_feats, tmp_feats, env_feats, targets in batch_loader:\n",
    "        current_batch = batch_loader.current_batch\n",
    "\n",
    "        # Transfer to PyTorch Tensor and GPU\n",
    "        spc_feats = torch.Tensor(spc_feats[0]).to(device) # only taking [0] for fnn\n",
    "        tmp_feats = torch.Tensor(tmp_feats[0]).to(device) # only taking [0] for fnn\n",
    "        env_feats = torch.Tensor(env_feats[0]).to(device) # only taking [0] for fnn\n",
    "        targets = torch.LongTensor(targets[0,:,0]).to(device) # only taking [0] for fnn\n",
    "        out = model(spc_feats, tmp_feats, env_feats)\n",
    "        loss = loss_function(input=out, target=targets)\n",
    "        epoch_losses.append(loss.item())\n",
    "        total_losses.append(epoch_losses[-1])\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        log.debug(f\"Batch: {current_batch:04d}/{num_batches:04d} \\t Loss: {epoch_losses[-1]:.4f}\")\n",
    "    mean_epoch_loss = np.mean(epoch_losses)\n",
    "    return mean_epoch_loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.early_stopping = True\n",
    "conf.max_epochs = 20\n",
    "conf.dropout = 0.\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# SET MODEL PARAMS\n",
    "train_set = loaders.train_loader.dataset\n",
    "indices, spc_feats, tmp_feats, env_feats, target = train_set[train_set.min_index]\n",
    "\n",
    "# input_size = hidden_size = np.sum([spc_feats.shape[-1], tmp_feats.shape[-1], env_feats.shape[-1]])\n",
    "# model = SimpleFNN(input_size, hidden_size)\n",
    "\n",
    "spc_size, tmp_size, env_size = spc_feats.shape[-1], tmp_feats.shape[-1], env_feats.shape[-1]\n",
    "# model = KangFeedForwardNetwork(spc_size=spc_size, tmp_size=tmp_size, env_size=env_size, dropout_p=conf.dropout)\n",
    "model = SmallKangFNN(spc_size=spc_size, tmp_size=tmp_size, env_size=env_size, dropout_p=conf.dropout)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# parameters = model.parameters()\n",
    "\n",
    "parameters = [\n",
    "                {'params': model.spcNet.parameters(), 'lr': 1e-3},    \n",
    "                {'params': model.tmpNet.parameters(), 'lr': 1e-3},    \n",
    "                {'params': model.envNet.parameters(), 'lr': 1e-3},\n",
    "                {'params': model.finalNet.parameters(), 'lr': 1e-3}\n",
    "            ]\n",
    "\n",
    "\n",
    "# important note: using weight decay (l2 penalty) can prohibit long term memory in LSTM networks\n",
    "# - use gradient clipping instead\n",
    "optimiser = optim.Adam(params=parameters, lr=conf.lr, weight_decay=conf.weight_decay)\n",
    "\n",
    "# generic training loop\n",
    "def train_model(train_epoch_fn, model, optimiser, loaders, conf):\n",
    "    \"\"\"\n",
    "    Generic training loop that handles:\n",
    "    - early stopping\n",
    "    - timing\n",
    "    - logging\n",
    "    - model checkpoints\n",
    "    - saving epoch and batch losses\n",
    "    \"\"\"\n",
    "    trn_epoch_losses = []\n",
    "    val_epoch_losses = []\n",
    "    val_epoch_losses_best = float(\"inf\")\n",
    "\n",
    "    trn_batch_losses = [] \n",
    "    val_batch_losses = []\n",
    "    \n",
    "    for epoch in range(conf.max_epochs):\n",
    "        log.info(f\"Epoch: {(1+epoch):04d}/{conf.max_epochs:04d}\")\n",
    "        conf.timer.reset()\n",
    "        # Training loop\n",
    "        epoch_loss = train_epoch_fn(model=model, \n",
    "                                    optimiser=optimiser, \n",
    "                                    batch_loader=loaders.train_loader, \n",
    "                                    total_losses=trn_batch_losses, \n",
    "                                    device=conf.device)\n",
    "\n",
    "        trn_epoch_losses.append(epoch_loss)\n",
    "        log.debug(f\"Epoch {epoch} -> Training Loop Duration: {conf.timer.check()}\")\n",
    "        conf.timer.reset()\n",
    "\n",
    "        # Validation loop\n",
    "        tmp_val_epoch_losses = []\n",
    "        with torch.set_grad_enabled(False):\n",
    "            epoch_loss = train_epoch_fn(model=model, \n",
    "                                        optimiser=optimiser, \n",
    "                                        batch_loader=loaders.train_loader, \n",
    "                                        total_losses=val_batch_losses, \n",
    "                                        device=conf.device)        \n",
    "\n",
    "            val_epoch_losses.append(epoch_loss)\n",
    "            log.debug(f\"Epoch {epoch} -> Validation Loop Duration: {conf.timer.check()}\")\n",
    "\n",
    "        log.info(f\"\\tLoss (Trn): \\t{trn_epoch_losses[-1]:.5f}\")\n",
    "        log.info(f\"\\tLoss (Val): \\t{val_epoch_losses[-1]:.5f}\")\n",
    "        log.info(f\"\\tLoss (Dif): \\t{np.abs(val_epoch_losses[-1]-trn_epoch_losses[-1]):.5f}\\n\")        \n",
    "\n",
    "        # save best model\n",
    "        if val_epoch_losses[-1] < val_epoch_losses_best:\n",
    "            val_epoch_losses_best = val_epoch_losses[-1]\n",
    "            torch.save(model.state_dict(), model_path + \"model_best.pth\")\n",
    "            torch.save(optimiser.state_dict(), model_path + \"optimiser_best.pth\")\n",
    "\n",
    "    #     # model has been over-fitting stop maybe? # average of val_epoch_losses has increase - starting to over-fit\n",
    "    #     if conf.early_stopping and epoch > 5 and np.sum(np.diff(val_epoch_losses[-5:])) > 0:  # increasing moving average\n",
    "    #         log.warning(\"Early stopping: Over-fitting has taken place\")\n",
    "    #         break\n",
    "\n",
    "    #     if conf.early_stopping and epoch > 1 and np.abs(val_epoch_losses[-1]-val_epoch_losses[-2]) < conf.tolerance:\n",
    "    #         log.warning(\"Converged: Difference between the past two validation losses is within tolerance\")\n",
    "    #         break\n",
    "\n",
    "        # checkpoint - save models and loss values\n",
    "        torch.save(model.state_dict(), model_path + \"model.pth\")\n",
    "        torch.save(optimiser.state_dict(), model_path + \"optimiser.pth\")\n",
    "        np.savez_compressed(model_path + \"losses.npz\",\n",
    "                            val_batch_losses=val_batch_losses,\n",
    "                            val_epoch_losses=val_epoch_losses,\n",
    "                            trn_epoch_losses=trn_epoch_losses,\n",
    "                            trn_batch_losses=trn_batch_losses,\n",
    "                            val_epoch_losses_best=val_epoch_losses_best)\n",
    "    \n",
    "# Save training and validation plots\n",
    "skip = 0\n",
    "loss_plotter = LossPlotter(title=\"Cross Entropy Loss of Linear Regression Model\")\n",
    "loss_plotter.plot_losses(trn_epoch_losses, trn_batch_losses[skip:], val_epoch_losses, val_batch_losses[skip:])\n",
    "loss_plotter.savefig(model_path + \"plot_train_val_epoch_losses.png\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.early_stopping = True\n",
    "conf.max_epochs = 20\n",
    "conf.dropout = 0.\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "trn_loss = []  # epoch losses\n",
    "val_loss = []\n",
    "val_loss_best = float(\"inf\")\n",
    "\n",
    "all_trn_loss = []  # batch losses\n",
    "all_val_loss = []\n",
    "\n",
    "# SET MODEL PARAMS\n",
    "train_set = loaders.train_loader.dataset\n",
    "indices, spc_feats, tmp_feats, env_feats, target = train_set[train_set.min_index]\n",
    "\n",
    "# input_size = hidden_size = np.sum([spc_feats.shape[-1], tmp_feats.shape[-1], env_feats.shape[-1]])\n",
    "# model = SimpleFNN(input_size, hidden_size)\n",
    "\n",
    "spc_size, tmp_size, env_size = spc_feats.shape[-1], tmp_feats.shape[-1], env_feats.shape[-1]\n",
    "# model = KangFeedForwardNetwork(spc_size=spc_size, tmp_size=tmp_size, env_size=env_size, dropout_p=conf.dropout)\n",
    "model = SmallKangFNN(spc_size=spc_size, tmp_size=tmp_size, env_size=env_size, dropout_p=conf.dropout)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# parameters = model.parameters()\n",
    "\n",
    "parameters = [\n",
    "                {'params': model.spcNet.parameters(), 'lr': 1e-3},    \n",
    "                {'params': model.tmpNet.parameters(), 'lr': 1e-3},    \n",
    "                {'params': model.envNet.parameters(), 'lr': 1e-3},\n",
    "                {'params': model.finalNet.parameters(), 'lr': 1e-3}\n",
    "            ]\n",
    "\n",
    "\n",
    "# important note: using weight decay (l2 penalty) can prohibit long term memory in LSTM networks\n",
    "# - use gradient clipping instead\n",
    "optimiser = optim.Adam(params=parameters, lr=conf.lr, weight_decay=conf.weight_decay)\n",
    "\n",
    "for epoch in range(conf.max_epochs):\n",
    "    log.info(f\"Epoch: {(1+epoch):04d}/{conf.max_epochs:04d}\")\n",
    "    conf.timer.reset()\n",
    "    # Training loop\n",
    "    tmp_trn_loss = []\n",
    "    num_batches = loaders.train_loader.num_batches\n",
    "    for indices, spc_feats, tmp_feats, env_feats, targets in loaders.train_loader:\n",
    "        current_batch = loaders.train_loader.current_batch\n",
    "        \n",
    "        # Transfer to PyTorch Tensor and GPU\n",
    "        spc_feats = torch.Tensor(spc_feats[0]).to(device) # only taking [0] for fnn\n",
    "        tmp_feats = torch.Tensor(tmp_feats[0]).to(device) # only taking [0] for fnn\n",
    "        env_feats = torch.Tensor(env_feats[0]).to(device) # only taking [0] for fnn\n",
    "        targets = torch.LongTensor(targets[0,:,0]).to(device) # only taking [0] for fnn\n",
    "        out = model(spc_feats, tmp_feats, env_feats)\n",
    "        loss = loss_function(input=out, target=targets)\n",
    "        tmp_trn_loss.append(loss.item())\n",
    "        all_trn_loss.append(tmp_trn_loss[-1])\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        log.debug(f\"Batch: {current_batch:04d}/{num_batches:04d} \\t Loss: {tmp_trn_loss[-1]:.4f}\")\n",
    "\n",
    "    trn_loss.append(np.mean(tmp_trn_loss))\n",
    "    log.debug(f\"Epoch {epoch} -> Training Loop Duration: {conf.timer.check()}\")\n",
    "    conf.timer.reset()\n",
    "\n",
    "    # Validation loop\n",
    "    tmp_val_loss = []\n",
    "    with torch.set_grad_enabled(False):\n",
    "        # Transfer to GPU - todo put into a loop - then add wrapper\n",
    "        for indices, spc_feats, tmp_feats, env_feats, targets in loaders.validation_loader:\n",
    "            # Transfer to GPU\n",
    "            spc_feats = torch.Tensor(spc_feats[0]).to(device)  # only taking [0] for fnn\n",
    "            tmp_feats = torch.Tensor(tmp_feats[0]).to(device)  # only taking [0] for fnn\n",
    "            env_feats = torch.Tensor(env_feats[0]).to(device)  # only taking [0] for fnn\n",
    "            targets = torch.LongTensor(targets[0,:,0]).to(device)  # only taking [0] for fnn\n",
    "            out = model(spc_feats, tmp_feats, env_feats)\n",
    "\n",
    "            loss = loss_function(input=out, target=targets)\n",
    "            tmp_val_loss.append(loss.item())\n",
    "            all_val_loss.append(tmp_val_loss[-1])\n",
    "\n",
    "    val_loss.append(np.mean(tmp_val_loss))\n",
    "    log.debug(f\"Epoch {epoch} -> Validation Loop Duration: {conf.timer.check()}\")\n",
    "    \n",
    "    log.info(f\"\\tlearning rate: \\t{optimiser.param_groups[0]['lr']:.5f}\")\n",
    "    log.info(f\"\\tLoss (Trn): \\t{trn_loss[-1]:.5f}\")\n",
    "    log.info(f\"\\tLoss (Val): \\t{val_loss[-1]:.5f}\")\n",
    "    log.info(f\"\\tLoss (Dif): \\t{np.abs(val_loss[-1]-trn_loss[-1]):.5f}\\n\")        \n",
    "    \n",
    "    # save best model\n",
    "    if min(val_loss) < val_loss_best:\n",
    "        val_loss_best = min(val_loss)\n",
    "        torch.save(model.state_dict(), model_path + \"model_best.pth\")\n",
    "        torch.save(optimiser.state_dict(), model_path + \"optimiser_best.pth\")\n",
    "\n",
    "#     # model has been over-fitting stop maybe? # average of val_loss has increase - starting to over-fit\n",
    "#     if conf.early_stopping and epoch > 5 and np.sum(np.diff(val_loss[-5:])) > 0:  # increasing moving average\n",
    "#         log.warning(\"Early stopping: Over-fitting has taken place\")\n",
    "#         break\n",
    "        \n",
    "#     if conf.early_stopping and epoch > 1 and np.abs(val_loss[-1]-val_loss[-2]) < conf.tolerance:\n",
    "#         log.warning(\"Converged: Difference between the past two validation losses is within tolerance\")\n",
    "#         break\n",
    "\n",
    "    # checkpoint - save models and loss values\n",
    "    torch.save(model.state_dict(), model_path + \"model.pth\")\n",
    "    torch.save(optimiser.state_dict(), model_path + \"optimiser.pth\")\n",
    "    np.savez_compressed(model_path + \"losses.npz\",\n",
    "                        all_val_loss=all_val_loss,\n",
    "                        val_loss=val_loss,\n",
    "                        trn_loss=trn_loss,\n",
    "                        all_trn_loss=all_trn_loss,\n",
    "                        val_loss_best=val_loss_best)\n",
    "    \n",
    "# Save training and validation plots\n",
    "skip = 0\n",
    "loss_plotter = LossPlotter(title=\"Cross Entropy Loss of Linear Regression Model\")\n",
    "loss_plotter.plot_losses(trn_loss, all_trn_loss[skip:], val_loss, all_val_loss[skip:])\n",
    "loss_plotter.savefig(model_path + \"plot_train_val_loss.png\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of RNN training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.early_stopping = True\n",
    "conf.max_epochs = 20\n",
    "conf.dropout = 0.\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "trn_loss = []\n",
    "val_loss = []\n",
    "val_loss_best = float(\"inf\")\n",
    "\n",
    "all_trn_loss = []\n",
    "all_val_loss = []\n",
    "\n",
    "# SET MODEL PARAMS\n",
    "train_set = loaders.train_loader.dataset\n",
    "indices, spc_feats, tmp_feats, env_feats, target = train_set[train_set.min_index]\n",
    "\n",
    "# input_size = hidden_size = np.sum([spc_feats.shape[-1], tmp_feats.shape[-1], env_feats.shape[-1]])\n",
    "# model = SimpleFNN(input_size, hidden_size)\n",
    "\n",
    "spc_size, tmp_size, env_size = spc_feats.shape[-1], tmp_feats.shape[-1], env_feats.shape[-1]\n",
    "# model = KangFeedForwardNetwork(spc_size=spc_size, tmp_size=tmp_size, env_size=env_size, dropout_p=conf.dropout)\n",
    "model = SmallKangFNN(spc_size=spc_size, tmp_size=tmp_size, env_size=env_size, dropout_p=conf.dropout)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# parameters = model.parameters()\n",
    "\n",
    "parameters = [\n",
    "                {'params': model.spcNet.parameters(), 'lr': 1e-3},    \n",
    "                {'params': model.tmpNet.parameters(), 'lr': 1e-3},    \n",
    "                {'params': model.envNet.parameters(), 'lr': 1e-3},\n",
    "                {'params': model.finalNet.parameters(), 'lr': 1e-3}\n",
    "            ]\n",
    "\n",
    "\n",
    "# important note: using weight decay (l2 penalty) can prohibit long term memory in LSTM networks\n",
    "# - use gradient clipping instead\n",
    "optimiser = optim.Adam(params=parameters, lr=conf.lr, weight_decay=conf.weight_decay)\n",
    "\n",
    "for epoch in range(conf.max_epochs):\n",
    "    log.info(f\"Epoch: {(1+epoch):04d}/{conf.max_epochs:04d}\")\n",
    "    conf.timer.reset()\n",
    "    # Training loop\n",
    "    tmp_trn_loss = []\n",
    "    num_batches = loaders.train_loader.num_batches\n",
    "    for indices, spc_feats, tmp_feats, env_feats, targets in loaders.train_loader:\n",
    "        current_batch = loaders.train_loader.current_batch\n",
    "        \n",
    "        # Transfer to PyTorch Tensor and GPU\n",
    "        spc_feats = torch.Tensor(spc_feats[0]).to(device) # only taking [0] for fnn\n",
    "        tmp_feats = torch.Tensor(tmp_feats[0]).to(device) # only taking [0] for fnn\n",
    "        env_feats = torch.Tensor(env_feats[0]).to(device) # only taking [0] for fnn\n",
    "        targets = torch.LongTensor(targets[0,:,0]).to(device) # only taking [0] for fnn\n",
    "        out = model(spc_feats, tmp_feats, env_feats)\n",
    "        loss = loss_function(input=out, target=targets)\n",
    "        tmp_trn_loss.append(loss.item())\n",
    "        all_trn_loss.append(tmp_trn_loss[-1])\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        log.debug(f\"Batch: {current_batch:04d}/{num_batches:04d} \\t Loss: {tmp_trn_loss[-1]:.4f}\")\n",
    "\n",
    "    trn_loss.append(np.mean(tmp_trn_loss))\n",
    "    log.debug(f\"Epoch {epoch} -> Training Loop Duration: {conf.timer.check()}\")\n",
    "    conf.timer.reset()\n",
    "\n",
    "    # Validation loop\n",
    "    tmp_val_loss = []\n",
    "    with torch.set_grad_enabled(False):\n",
    "        # Transfer to GPU\n",
    "        for indices, spc_feats, tmp_feats, env_feats, targets in loaders.validation_loader:\n",
    "            # Transfer to GPU\n",
    "            spc_feats = torch.Tensor(spc_feats[0]).to(device)  # only taking [0] for fnn\n",
    "            tmp_feats = torch.Tensor(tmp_feats[0]).to(device)  # only taking [0] for fnn\n",
    "            env_feats = torch.Tensor(env_feats[0]).to(device)  # only taking [0] for fnn\n",
    "            targets = torch.LongTensor(targets[0,:,0]).to(device)  # only taking [0] for fnn\n",
    "            out = model(spc_feats, tmp_feats, env_feats)\n",
    "\n",
    "            loss = loss_function(input=out, target=targets)\n",
    "            tmp_val_loss.append(loss.item())\n",
    "            all_val_loss.append(tmp_val_loss[-1])\n",
    "\n",
    "    val_loss.append(np.mean(tmp_val_loss))\n",
    "    log.debug(f\"Epoch {epoch} -> Validation Loop Duration: {conf.timer.check()}\")\n",
    "\n",
    "    \n",
    "    log.info(f\"\\tlearning rate: \\t{optimiser.param_groups[0]['lr']:.5f}\")\n",
    "    log.info(f\"\\tLoss (Trn): \\t{trn_loss[-1]:.5f}\")\n",
    "    log.info(f\"\\tLoss (Val): \\t{val_loss[-1]:.5f}\")\n",
    "    log.info(f\"\\tLoss (Dif): \\t{np.abs(val_loss[-1]-trn_loss[-1]):.5f}\\n\")        \n",
    "    \n",
    "\n",
    "    # save best model\n",
    "    if min(val_loss) < val_loss_best:\n",
    "        val_loss_best = min(val_loss)\n",
    "        torch.save(model.state_dict(), model_path + \"model_best.pth\")\n",
    "        torch.save(optimiser.state_dict(), model_path + \"optimiser_best.pth\")\n",
    "\n",
    "#     # model has been over-fitting stop maybe? # average of val_loss has increase - starting to over-fit\n",
    "#     if conf.early_stopping and epoch > 5 and np.sum(np.diff(val_loss[-5:])) > 0:  # increasing moving average\n",
    "#         log.warning(\"Early stopping: Over-fitting has taken place\")\n",
    "#         break\n",
    "        \n",
    "#     if conf.early_stopping and epoch > 1 and np.abs(val_loss[-1]-val_loss[-2]) < conf.tolerance:\n",
    "#         log.warning(\"Converged: Difference between the past two validation losses is within tolerance\")\n",
    "#         break\n",
    "    \n",
    "    if epoch > 3:\n",
    "        model.dropout.p = ((conf.max_epochs - epoch)/conf.max_epochs)**2\n",
    "    \n",
    "    \n",
    "    # checkpoint - save models and loss values\n",
    "    torch.save(model.state_dict(), model_path + \"model.pth\")\n",
    "    torch.save(optimiser.state_dict(), model_path + \"optimiser.pth\")\n",
    "    np.savez_compressed(model_path + \"losses.npz\",\n",
    "                        all_val_loss=all_val_loss,\n",
    "                        val_loss=val_loss,\n",
    "                        trn_loss=trn_loss,\n",
    "                        all_trn_loss=all_trn_loss,\n",
    "                        val_loss_best=val_loss_best)\n",
    "    \n",
    "# Save training and validation plots\n",
    "skip = 0\n",
    "loss_plotter = LossPlotter(title=\"Cross Entropy Loss of Linear Regression Model\")\n",
    "loss_plotter.plot_losses(trn_loss, all_trn_loss[skip:], val_loss, all_val_loss[skip:])\n",
    "loss_plotter.savefig(model_path + \"plot_train_val_loss.png\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some part of the code was referenced from below.\n",
    "# https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/language_model\n",
    "# which was in part referenced from below.\n",
    "# https://github.com/pytorch/examples/tree/master/word_language_model \n",
    "# TODO: Add parsing capabilities\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "\n",
    "# Hyper Parameters\n",
    "embed_size = 100\n",
    "hidden_size = 1000\n",
    "num_layers = 1\n",
    "num_epochs = 1\n",
    "batch_size = 20\n",
    "seq_length = 20 # month history\n",
    "learning_rate = 0.002\n",
    "is_weighted_loss = False\n",
    "\n",
    "# Load Time Series\n",
    "data = np.load(\"./data/time_series.npy\")[:1000] # just select the centre square\n",
    "data = threshold(data) # treshold data to 0 and 1 values\n",
    "\n",
    "# Calculate the CrossEntropy weights for skew data (Rosenberg 2012)\n",
    "values, counts = np.unique(data,return_counts=True)\n",
    "weights = counts/np.sum(counts)\n",
    "# weights = Variable(torch.FloatTensor([weights[1], weights[0]])).cuda()\n",
    "weights = Variable(torch.FloatTensor([weights[1], weights[0]]))\n",
    "\n",
    "vocab_size = int(data.max() + 1) # only two types - crime or no crime\n",
    "\n",
    "n_trn_val_samps = int(len(data)*0.8)# 80:20 split data to train and test set\n",
    "n_trn_samps = int(n_trn_val_samps*0.8)# 80:20 split train to train and validation set\n",
    "train_and_validation = data[:n_trn_val_samps]\n",
    "train = train_and_validation[:n_trn_samps]\n",
    "validation = train_and_validation[n_trn_samps:]\n",
    "test = data[n_trn_val_samps:]\n",
    "\n",
    "# Setup train data\n",
    "train = batchify(train,batch_size) # segment the data into batches\n",
    "train = torch.LongTensor(train) #expects long tensor for the embedding\n",
    "\n",
    "# Setup validation data and starting hidden state\n",
    "validation = torch.LongTensor(validation)\n",
    "validation = validation.view(1,-1) # reshape validation => 1 batch , many samples\n",
    "# val_states = (Variable(torch.zeros(num_layers, 1, hidden_size)).cuda(), \n",
    "#                 Variable(torch.zeros(num_layers, 1, hidden_size)).cuda())\n",
    "val_states = (Variable(torch.zeros(num_layers, 1, hidden_size)), \n",
    "                Variable(torch.zeros(num_layers, 1, hidden_size)))\n",
    "# val_inputs = Variable(validation[:,:-1]).cuda()\n",
    "# val_targets = Variable(validation[:,1:]).cuda()\n",
    "val_inputs = Variable(validation[:,:-1])\n",
    "val_targets = Variable(validation[:,1:])\n",
    "min_val_los = 10000 #used to get early stopping parameters\n",
    "ideal_model_state = {}\n",
    "\n",
    "# Setup test data and starting hidden state\n",
    "test = torch.LongTensor(test)\n",
    "test = test.view(1,-1) # reshape test => 1 batch , many samples\n",
    "# tst_states = (Variable(torch.zeros(num_layers, 1, hidden_size)).cuda(), \n",
    "#                 Variable(torch.zeros(num_layers, 1, hidden_size)).cuda()) #batch_size is one in testing case\n",
    "tst_states = (Variable(torch.zeros(num_layers, 1, hidden_size)), \n",
    "                Variable(torch.zeros(num_layers, 1, hidden_size))) #batch_s\n",
    "# tst_inputs = Variable(test[:,:-1]).cuda()\n",
    "# tst_targets = Variable(test[:,1:]).cuda()\n",
    "tst_inputs = Variable(test[:,:-1])\n",
    "tst_targets = Variable(test[:,1:])\n",
    "\n",
    "num_batches = train.shape[1] // seq_length\n",
    "\n",
    "print(\"Hyper Parameters:\\n================\")\n",
    "print(\"embed_size:\\t\",embed_size)\n",
    "print(\"hidden_size:\\t\",hidden_size)\n",
    "print(\"num_layers:\\t\",num_layers)\n",
    "print(\"num_epochs:\\t\",num_epochs)\n",
    "print(\"batch_size:\\t\",batch_size)\n",
    "print(\"seq_length:\\t\",seq_length)\n",
    "print(\"learning_rate:\\t\",learning_rate)\n",
    "print(\"num_batches:\\t\",num_batches)\n",
    "print(\"is_weighted_loss:\\t\",is_weighted_loss)\n",
    "\n",
    "# RNN Based Crime Model\n",
    "class RNN_crime(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super(RNN_crime, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True) # note batch first\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        self.embed.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.linear.bias.data.fill_(0)\n",
    "        self.linear.weight.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "    def forward(self, x, h): # give seq_jump to know which hidden state to use for next sequence\n",
    "        # Embed word crimes to vectors\n",
    "        x = self.embed(x) \n",
    "\n",
    "        # Forward propagate RNN  \n",
    "        out, h = self.lstm(x, h) # Not saving hidden state because seq_jump # init lstm weight to 1 to make easier\n",
    "\n",
    "        # Reshape output to (batch_size*sequence_length, hidden_size)\n",
    "        out = out.contiguous().view(out.size(0)*out.size(1), out.size(2))\n",
    "\n",
    "        # Decode hidden states of all time step\n",
    "        out = self.linear(out)  \n",
    "        return out, h # if we never send h its never detached\n",
    "    \n",
    "    \n",
    "model = RNN_crime(vocab_size, embed_size, hidden_size, num_layers)\n",
    "# model.cuda()\n",
    "\n",
    "# Loss and Optimizer\n",
    "if is_weighted_loss:\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Truncated Backpropagation \n",
    "def detach(states):\n",
    "    return [state.detach() for state in states] \n",
    "\n",
    "print(\"Model Training Starting...\")\n",
    "\n",
    "# Training and validation\n",
    "for epoch in range(num_epochs): # TODO: Change to epoch length\n",
    "    \n",
    "    for start in range(1): #TODO: change 1 to seq length # this is done to ensure more available training data\n",
    "    \n",
    "        # Initial hidden and memory states\n",
    "        states = (Variable(torch.zeros(num_layers, batch_size, hidden_size)),\n",
    "                  Variable(torch.zeros(num_layers, batch_size, hidden_size)))\n",
    "    \n",
    "        for i in range(start, train.size(1) - seq_length, seq_length):\n",
    "            #Train model\n",
    "            model.train()\n",
    "            \n",
    "            # Get batch inputs and targets\n",
    "            # inputs = Variable(train[:, i:i+seq_length]).cuda()\n",
    "            # targets = Variable(train[:, (i+1):(i+1)+seq_length].contiguous()).cuda()\n",
    "            inputs = Variable(train[:, i:i+seq_length])\n",
    "            targets = Variable(train[:, (i+1):(i+1)+seq_length].contiguous())\n",
    "\n",
    "            # Forward + Backward + Optimize\n",
    "            model.zero_grad()\n",
    "\n",
    "            # hidden states not reinitialised - same h_state is propogated forward\n",
    "            # hidden states must be detached from history because the weights have been updated\n",
    "            states = detach(states) \n",
    "\n",
    "            outputs, states = model(inputs, states) \n",
    "            loss = criterion(outputs, targets.view(-1))\n",
    "            loss.backward() #no retain graph - work with set sequence lenght\n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "\n",
    "            print('{{\"metric\": \"train loss\", \"value\": {}}}'.format(loss.data[0]))\n",
    "\n",
    "            step = (i // seq_length) + 1\n",
    "            if step % 1 == 0:\n",
    "                print ('Epoch [%d/%d], Step[%d/%d], Loss: %.3f, Perplexity: %5.2f' %\n",
    "                       (epoch+1, num_epochs, step, num_batches, loss.data[0], np.exp(loss.data[0])))\n",
    "\n",
    "            # Validate model\n",
    "            # Calculate the evaluation metrics\n",
    "            model.eval()\n",
    "\n",
    "            val_outputs, _ = model(val_inputs, val_states)\n",
    "            val_loss = criterion(val_outputs, val_targets.view(-1))\n",
    "\n",
    "            # Save Ideal Model on Validation Set (Early Stopping)\n",
    "            if (val_loss.data[0] < min_val_los):\n",
    "                min_val_los = val_loss.data[0] \n",
    "                ideal_model_state = model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_collection = []\n",
    "val_collection = []\n",
    "best_model_val_collection = []\n",
    "best_model_trn_collection = []\n",
    "\n",
    "itrs = [5]\n",
    "\n",
    "for itr in itrs:\n",
    "    torch.manual_seed(itr)  # manual seed to test other params of the model and keep init weights constant\n",
    "\n",
    "    print('Start Time:', pd.datetime.now(), '\\n')\n",
    "\n",
    "    # data loader setup\n",
    "    n_epochs = 10\n",
    "    seq_len = 24 * 3\n",
    "    batch_size = 32\n",
    "    lr = 1e-3\n",
    "\n",
    "    S = Variable(torch.FloatTensor(subX)).view(-1, subX.shape[-1] ** 2)\n",
    "    #   S = Variable(torch.FloatTensor(grids)).view(-1,grid_size**2)\n",
    "    #   S = Variable(torch.FloatTensor(f[-500:]))\n",
    "    S[S > cap] = cap\n",
    "    S = S.cuda()\n",
    "    #   S = S.mm(trans_mat_d2s)\n",
    "\n",
    "    loader = DataLoader(S, batch_size, seq_len, shuffle=True)\n",
    "    trnT, trnX, trnTimes = loader.getTrainBatch()\n",
    "    loader.reset_current_t()\n",
    "    trnT = trnT[:, :, 12:12 + 1]\n",
    "    #   trnX = trnX.view(batch_size,seq_len,-1)\n",
    "\n",
    "    # model setup\n",
    "    input_size = trnX.shape[-1]\n",
    "    output_size = trnT.shape[-1]\n",
    "    hidden_size = 10 * trnX.shape[-1]\n",
    "    num_layers = 1\n",
    "\n",
    "    #   model = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "    model = GRU_MLPRegressor(input_size, hidden_size, output_size, num_layers=num_layers)\n",
    "    model.cuda()\n",
    "    print('\\nMODEL\\n', model)\n",
    "\n",
    "    params = list(model.parameters())  # + list(h0) + list(c0)\n",
    "    optimizer = optim.Adam(params=params, lr=lr, weight_decay=0)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    n_steps = (loader.getTrainDataLength() // batch_size) + 1\n",
    "    print(\"\\nSteps per epoch\", n_steps)\n",
    "\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "    min_val_loss = np.inf  # used for early stopping TODO: IMPLEMENT MOVING AVERAGE AND STOP IF VAL LOSS IS MOVING UP, IE OVERFITTING\n",
    "\n",
    "    valT, valX, valTimes = loader.getValidationSet()\n",
    "    valT = valT[:, :, 12:12 + 1]\n",
    "\n",
    "    for epoch in range(n_epochs):  # epoch is one iteration over the entire input data\n",
    "        loader.reset_current_t()\n",
    "        print(\"\\nEpoch:\", epoch)\n",
    "        for step in range(n_steps - 1):\n",
    "            # Train Evaluation and Optimization Step\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            trnT, trnX, trnTimes = loader.getTrainBatch()\n",
    "            trnT = trnT[:, :, 12:12 + 1]  # choosing only center square\n",
    "            #       trnY, (hn, cn) = model.forward(trnX, (h0, c0))\n",
    "            trnY = model.forward(trnX)\n",
    "\n",
    "            trnLoss = torch.sqrt(criterion(trnY[-1], trnT[-1]))  # SQRT MSE not same as MAE\n",
    "            trnLoss.backward()\n",
    "            #       if itr == 0:\n",
    "            #         torch.nn.utils.clip_grad_norm(model.parameters(), 0.5) # Figure out fitting clip value\n",
    "            optimizer.step()\n",
    "            train_losses.append(trnLoss.cpu().item())\n",
    "\n",
    "            # Validation Evaluation\n",
    "            model.eval()\n",
    "            valY = model.forward(valX)\n",
    "\n",
    "            valLoss = torch.sqrt(criterion(valY[-1], valT[-1]))\n",
    "            validation_losses.append(valLoss.cpu().item())\n",
    "\n",
    "            if validation_losses[-1] < min_val_loss:\n",
    "                min_val_loss = validation_losses[-1]\n",
    "                best_model_val = model.state_dict()\n",
    "\n",
    "            if len(validation_losses) % 50 == 0:\n",
    "                print(\"Iteration:\", len(validation_losses))\n",
    "\n",
    "        print(\"Last Train Loss of Epoch:\", train_losses[-1])\n",
    "        print(\"Last Validation Loss of Epoch:\", validation_losses[-1])\n",
    "        print(\"Current Best Validation Loss:\", min_val_loss)\n",
    "    best_model_trn = model.state_dict()\n",
    "    trn_collection.append(train_losses)\n",
    "    val_collection.append(validation_losses)\n",
    "    best_model_trn_collection.append(best_model_trn)\n",
    "    best_model_val_collection.append(best_model_val)\n",
    "    print('Stop Time:', pd.datetime.now(), '\\n')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"RMSE Loss of Model over Itterations\")\n",
    "for i, _ in enumerate(trn_collection):\n",
    "    plt.plot(trn_collection[i], label='Training: ' + str(itrs[i]))\n",
    "    plt.plot(val_collection[i], label='Validation: ' + str(itrs[i]))\n",
    "    plt.scatter(np.argmin(val_collection[i]), np.min(val_collection[i]), marker='X', c='r')\n",
    "plt.xlabel(\"Itteraion\")\n",
    "plt.ylabel(\"RMSE Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
