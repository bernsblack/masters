{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33098,
     "status": "ok",
     "timestamp": 1566466020661,
     "user": {
      "displayName": "Bernard Swart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDulTxFaVYZ27_n_Ds4qquFn-4Ri8HUURRyOqf4WUo=s64",
      "userId": "00293673988406756138"
     },
     "user_tz": -120
    },
    "id": "EIP3ykajpZPk",
    "outputId": "bedf1f00-e9b6-4ddd-ada8-5a47cc2a8707"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd /content/gdrive/My\\ Drive/masters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3676,
     "status": "ok",
     "timestamp": 1566466057313,
     "user": {
      "displayName": "Bernard Swart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDulTxFaVYZ27_n_Ds4qquFn-4Ri8HUURRyOqf4WUo=s64",
      "userId": "00293673988406756138"
     },
     "user_tz": -120
    },
    "id": "kICfj6YOpffj",
    "outputId": "cf73f62a-a2bc-49e7-cc50-0a3becd8b92b"
   },
   "outputs": [],
   "source": [
    "%ls ./data/processed\n",
    "\n",
    "# T1H-X1700M-Y1760M/  T24H-X850M-Y880M/  T3H-X850M-Y880M/\n",
    "# T12H-X850M-Y880M/  T24H-X425M-Y440M/   T24H-X85M-Y110M/   T6H-X850M-Y880M/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to test indexing of loaders\n",
    "# have model that does nothing and make input and targets equal should show if there are any discrepancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNulAac9o8gl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging as log\n",
    "from time import strftime\n",
    "from copy import deepcopy\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from utils.data_processing import *\n",
    "from logger.logger import setup_logging\n",
    "from utils.configs import BaseConf\n",
    "from utils.utils import write_json, Timer\n",
    "from models.kangkang_fnn_models import KangFeedForwardNetwork, SmallKangFNN\n",
    "from dataloaders.flat_loader import FlatDataLoaders, MockLoader, MockLoaders\n",
    "from datasets.flat_dataset import FlatDataGroup\n",
    "from utils.metrics import PRCurvePlotter, ROCCurvePlotter, LossPlotter, PerTimeStepPlotter\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score\n",
    "from models.model_result import ModelResult, ModelMetrics\n",
    "from utils.mock_data import mock_fnn_data_classification\n",
    "from utils.plots import im\n",
    "from utils.utils import pshape\n",
    "from trainers.generic_trainer import train_model\n",
    "from models.kangkang_fnn_models import train_epoch_for_fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6860,
     "status": "ok",
     "timestamp": 1566466592307,
     "user": {
      "displayName": "Bernard Swart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDulTxFaVYZ27_n_Ds4qquFn-4Ri8HUURRyOqf4WUo=s64",
      "userId": "00293673988406756138"
     },
     "user_tz": -120
    },
    "id": "-TBN_1gYo8go",
    "outputId": "4d4f5037-e665-46e2-df61-928a6a22cb09",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_date = \"2013-01-01\"\n",
    "end_date = \"2015-01-01\" \n",
    "\n",
    "data_dim_str = \"T24H-X850M-Y880M\"  #\"T1H-X1700M-Y1760M\"  # needs to exist\n",
    "model_name = \"FNN-CRIME-MODEL\"  # needs to be created\n",
    "data_path = f\"./data/processed/{data_dim_str}_{start_date}_{end_date}/\"\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    raise Exception(f\"Directory ({data_path}) needs to exist.\")\n",
    "\n",
    "model_path = data_path + f\"models/{model_name}/\"\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# logging config is set globally thus we only need to call this in this file\n",
    "# imported function logs will follow the configuration\n",
    "setup_logging(save_dir=model_path, log_config='./logger/standard_logger_config.json', default_level=log.INFO)\n",
    "log.info(\"=====================================BEGIN=====================================\")\n",
    "\n",
    "timer = Timer()\n",
    "# manually set the config\n",
    "# manually set the config\n",
    "conf_dict = {\n",
    "    \"seed\": 3,\n",
    "    \"use_cuda\": False,\n",
    "    \n",
    "    \"use_crime_types\": False,\n",
    "    \n",
    "    # data group/data set related\n",
    "    \"val_ratio\": 0.1,  # ratio of the total dataset\n",
    "    \"tst_ratio\": 0.3,# ratio of the total dataset\n",
    "    \"seq_len\": 1,\n",
    "    \"flatten_grid\": True,  # if the shaper should be used to squeeze the data\n",
    "    \n",
    "    # shaper related \n",
    "    \"shaper_top_k\": -1,  # if less then 0, top_k will not be applied\n",
    "    \"shaper_threshold\": 0,\n",
    "\n",
    "    \n",
    "    # data loader related\n",
    "    \"sub_sample_train_set\": True,\n",
    "    \"sub_sample_validation_set\": True,\n",
    "    \"sub_sample_test_set\": False,\n",
    "    \n",
    "    # training parameters\n",
    "    \"resume\": False,\n",
    "    \"early_stopping\": False,\n",
    "    \"tolerance\": 1e-8,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-8,\n",
    "    \"max_epochs\": 1,\n",
    "    \"batch_size\": 64,\n",
    "    \"dropout\": 0.2,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 6,\n",
    "    \n",
    "    # attached global variables - bad practice -find alternative\n",
    "    \"device\": None,  # pytorch device object [CPU|GPU]\n",
    "    \"timer\": Timer(),\n",
    "    \"model_name\": model_name,\n",
    "    \"model_path\": model_path,\n",
    "    \"checkpoint\": \"best\",\n",
    "    \n",
    "    \"use_seq_loss\": True,\n",
    "}\n",
    "conf = BaseConf(conf_dict=conf_dict)\n",
    "\n",
    "info = deepcopy(conf.__dict__)\n",
    "info[\"start_time\"] = strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "# DATA LOADER SETUP\n",
    "np.random.seed(conf.seed)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed( conf.seed)\n",
    "else:\n",
    "    torch.manual_seed(conf.seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "log.info(f\"Device: {device}\")\n",
    "info[\"device\"] = device.type\n",
    "conf.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.getLogger().setLevel(\"WARNING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.getLogger().setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SET THE HYPER PARAMETERS\n",
    "conf.early_stopping = False\n",
    "conf.max_epochs = 4\n",
    "conf.dropout = 0 #1e-3\n",
    "conf.weight_decay = 0\n",
    "conf.resume = False\n",
    "conf.checkpoint = \"best\" # [\"best\"|\"latest\"]\n",
    "conf.lr = 1e-2\n",
    "conf.shaper_top_k = -1\n",
    "\n",
    "MOCK = False\n",
    "\n",
    "if MOCK:\n",
    "    # MOCK THE DATA\n",
    "    vector_size= [5,5,5]#[37,65,512]\n",
    "    batch_size = 100    \n",
    "    class_split=0.5\n",
    "    train_loader = MockLoader(vector_size, conf.batch_size, n_samples=1000, class_split=class_split)\n",
    "    validation_loader = MockLoader(vector_size, conf.batch_size, n_samples=200, class_split=class_split)\n",
    "    test_loader = MockLoader(vector_size, conf.batch_size, n_samples=300, class_split=class_split)\n",
    "    loaders = MockLoaders(train_loader,validation_loader,test_loader)\n",
    "else:\n",
    "    # CRIME DATA\n",
    "    data_group = FlatDataGroup(data_path=data_path, conf=conf)\n",
    "    loaders = FlatDataLoaders(data_group=data_group, conf=conf)\n",
    "\n",
    "conf.freqstr = data_group.t_range.freqstr    \n",
    "\n",
    "# SET LOSS FUNCTION\n",
    "# size averaged - so more epochs or larger lr for smaller batches\n",
    "loss_function = nn.CrossEntropyLoss()  \n",
    "\n",
    "# SETUP MODEL\n",
    "train_set = loaders.train_loader.dataset\n",
    "indices, spc_feats, tmp_feats, env_feats, target = train_set[train_set.min_index]\n",
    "spc_size, tmp_size, env_size = spc_feats.shape[-1], tmp_feats.shape[-1], env_feats.shape[-1]\n",
    "\n",
    "\n",
    "model_arch = {\n",
    "    \"h_size0\": 100,\n",
    "    \"h_size1\": 100,\n",
    "    \"h_size2\": 100,\n",
    "}\n",
    "model = SmallKangFNN(spc_size=spc_size,\n",
    "                     tmp_size=tmp_size,\n",
    "                     env_size=env_size,\n",
    "                     dropout_p=conf.dropout,\n",
    "                     model_arch=model_arch)\n",
    "\n",
    "# model_arch = {\n",
    "#     \"scp_net_h0\": 64,\n",
    "#     \"scp_net_h1\": 32,\n",
    "#     \"tmp_net_h0\": 64,\n",
    "#     \"tmp_net_h1\": 32,\n",
    "#     \"env_net_h0\": 64,\n",
    "#     \"env_net_h1\": 32,\n",
    "#     \"final_net_h1\": 64,\n",
    "# }\n",
    "# model = KangFeedForwardNetwork(spc_size=spc_size,\n",
    "#                                  tmp_size=tmp_size,\n",
    "#                                  env_size=env_size,\n",
    "#                                  dropout_p=conf.dropout,\n",
    "#                                  model_arch=model_arch)\n",
    "\n",
    "model.to(conf.device)\n",
    "\n",
    "# SETUP OPTIMISER\n",
    "parameters = model.parameters()\n",
    "\n",
    "# important note: using weight decay (l2 penalty) can prohibit long term memory in LSTM networks\n",
    "# - use gradient clipping instead\n",
    "optimiser = optim.Adam(params=parameters, lr=conf.lr, weight_decay=conf.weight_decay)\n",
    "\n",
    "##### RESUME LOGIC\n",
    "if conf.resume:  # todo check if the files actually exist\n",
    "    try:\n",
    "        # resume from previous check point or resume from best validaton score checkpoint\n",
    "        # load model state\n",
    "        model_state_dict = torch.load(f\"{conf.model_path}model_{conf.checkpoint}.pth\",\n",
    "                                      map_location=conf.device.type)\n",
    "        model.load_state_dict(model_state_dict)\n",
    "        \n",
    "        # load optimiser state\n",
    "        optimiser_state_dict = torch.load(f\"{conf.model_path}optimiser_{conf.checkpoint}.pth\",\n",
    "                                          map_location=conf.device.type)\n",
    "        optimiser.load_state_dict(optimiser_state_dict) \n",
    "\n",
    "        # new optimiser hyper-parameters\n",
    "        optimiser.param_groups[0]['lr'] = conf.lr\n",
    "        optimiser.param_groups[0]['weight_decay'] = conf.weight_decay\n",
    "\n",
    "        # new model hyper-parameters\n",
    "        model.dropout.p = conf.dropout # note that drop out is not part of the saved state dict\n",
    "\n",
    "    except Exception as e:\n",
    "        log.error(f\"Nothing to resume from, training from scratch \\n\\t-> {e}\")\n",
    "\n",
    "best_val_loss, stopped_early = train_model(model=model,\n",
    "                                            optimiser=optimiser,\n",
    "                                            loaders=loaders,\n",
    "                                            train_epoch_fn=train_epoch_for_fnn,\n",
    "                                            loss_fn=loss_function,\n",
    "                                            conf=conf)    \n",
    "\n",
    "print(f\"best_val_loss: {best_val_loss}, stopped_early: {stopped_early}\") # use the current epoch instead\n",
    "# if stopped_early -> continue with best_model - new hyper-parameters -> no n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.getLogger().setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.metrics import best_threshold\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_fnn(model, batch_loader, conf):    \n",
    "    \"\"\"\n",
    "    Only used to get probas in a time and location based format. The hard predictions should be done outside \n",
    "    this function where the threshold is determined using only the training data\n",
    "    \"\"\"\n",
    "    probas_pred = np.zeros(batch_loader.dataset.target_shape,dtype=np.float)\n",
    "    y_true = batch_loader.dataset.targets[-len(probas_pred):]\n",
    "    t_range = batch_loader.dataset.t_range[-len(probas_pred):]\n",
    "    \n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        model.eval()\n",
    "            \n",
    "        num_batches = batch_loader.num_batches\n",
    "        for indices, spc_feats, tmp_feats, env_feats, targets in batch_loader:\n",
    "            current_batch = batch_loader.current_batch\n",
    "\n",
    "            # Transfer to PyTorch Tensor and GPU\n",
    "            spc_feats = torch.Tensor(spc_feats[0]).to(conf.device) # only taking [0] for fnn\n",
    "            tmp_feats = torch.Tensor(tmp_feats[0]).to(conf.device) # only taking [0] for fnn\n",
    "            env_feats = torch.Tensor(env_feats[0]).to(conf.device) # only taking [0] for fnn\n",
    "            targets = torch.LongTensor(targets[0,:,0]).to(conf.device) # only taking [0] for fnn\n",
    "            out = model(spc_feats, tmp_feats, env_feats)\n",
    "\n",
    "            batch_probas_pred = F.softmax(out,dim=-1)[:,1].numpy() # select class1 prediction\n",
    "            \n",
    "            for i, p in zip(indices,batch_probas_pred):\n",
    "                n,c,l = i   \n",
    "                probas_pred[n,c,l] = p\n",
    "\n",
    "    y_pred = np.copy(probas_pred)\n",
    "    \n",
    "    # best_threshold - should be determined on the training data not the evaluation test data\n",
    "#     thresh = best_threshold(y_true, probas_pred)\n",
    "#     y_pred[y_pred >= thresh] = 1\n",
    "#     y_pred[y_pred < thresh] = 0\n",
    "    \n",
    "    return y_true, y_pred, probas_pred, t_range\n",
    "\n",
    "\n",
    "def save_metrics(y_true, y_pred, probas_pred, t_range, shaper, conf):\n",
    "    \"\"\"\n",
    "    Training the model for a single epoch\n",
    "    \"\"\"\n",
    "    # save result\n",
    "    # only saves the result of the metrics not the predicted values\n",
    "    model_metrics = ModelMetrics(model_name=conf.model_name,\n",
    "                                 y_true=y_true,\n",
    "                                 y_pred=y_pred,\n",
    "                                 probas_pred=probas_pred)\n",
    "    log.info(model_metrics)\n",
    "\n",
    "    # saves the actual target and predicted values to be visualised later on\n",
    "    model_result = ModelResult(model_name=conf.model_name,\n",
    "                               y_true=y_true,\n",
    "                               y_pred=y_pred,\n",
    "                               probas_pred=probas_pred,\n",
    "                               t_range=t_range,\n",
    "                               shaper=shaper)\n",
    "    log.info(model_result)\n",
    "\n",
    "    # do result plotting and saving\n",
    "    pr_plotter = PRCurvePlotter()\n",
    "    pr_plotter.add_curve(y_true.flatten(), probas_pred.flatten(), label_name=conf.model_name)\n",
    "    pr_plotter.savefig(f\"{conf.model_path}plot_pr_curve.png\")\n",
    "\n",
    "    roc_plotter = ROCCurvePlotter()\n",
    "    roc_plotter.add_curve(y_true.flatten(), probas_pred.flatten(), label_name=conf.model_name)\n",
    "    roc_plotter.savefig(f\"{conf.model_path}plot_roc_curve.png\")\n",
    "        \n",
    "    total_crime_plot = PerTimeStepPlotter(time_step=t_range.freqstr,ylabel=\"Total Crimes\")\n",
    "    total_crime_plot.plot(probas_pred.sum(-1)[:,0],label=\"Predicted\")\n",
    "    total_crime_plot.plot(y_true.sum(-1)[:,0],label=\"Predicted\")\n",
    "    total_crime_plot.savefig(f\"{conf.model_path}plot_total_crimes.png\")\n",
    "    \n",
    "    \n",
    "y_true, y_pred, probas_pred, t_range = evaluate_fnn(model=model,\n",
    "                                                    batch_loader=loaders.test_loader,\n",
    "                                                    conf=conf)    \n",
    "    \n",
    "save_metrics(y_true=y_true,\n",
    "             y_pred=y_pred,\n",
    "             probas_pred=probas_pred,\n",
    "             t_range=t_range,\n",
    "             shaper=None,#data_group.shaper,                \n",
    "             conf=conf)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "im(data_group.shaper.unsqueeze(probas_pred).mean(0)[0])\n",
    "im(data_group.shaper.unsqueeze(data_group.targets).mean(0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision_score_per_cell(y_true, probas_pred):\n",
    "    \"\"\"\n",
    "    y_true: shape (N,1,L)\n",
    "    probas_pred: (N,1,L)\n",
    "    \"\"\"\n",
    "    N,_,L = y_true.shape\n",
    "    result = np.zeros(L)\n",
    "    \n",
    "    for i in range(L):\n",
    "        result[i] = average_precision_score(y_true=y_true[:,:,i].flatten()\n",
    "                                            , y_score=probas_pred[:,:,i].flatten())\n",
    "        \n",
    "    return result\n",
    "\n",
    "def roc_auc_score_per_cell(y_true, probas_pred):\n",
    "    \"\"\"\n",
    "    y_true: shape (N,1,L)\n",
    "    probas_pred: (N,1,L)\n",
    "    \"\"\"\n",
    "    N,_,L = y_true.shape\n",
    "    result = np.zeros(L)\n",
    "    \n",
    "    for i in range(L):\n",
    "        result[i] = average_precision_score(y_true=y_true[:,:,i].flatten(),\n",
    "                                            y_score=probas_pred[:,:,i].flatten())\n",
    "        \n",
    "    return result\n",
    "    \n",
    "    \n",
    "def average_precision_score_per_time_slot(y_true, probas_pred):\n",
    "    \"\"\"\n",
    "    y_true: shape (N,1,L)\n",
    "    probas_pred: (N,1,L)\n",
    "    \"\"\"\n",
    "    N,_,L = y_true.shape\n",
    "    result = np.zeros(N)\n",
    "    \n",
    "    for i in range(N):\n",
    "        result[i] = average_precision_score(y_true=y_true[:,:,i].flatten(),\n",
    "                                            y_score=probas_pred[:,:,i].flatten())\n",
    "        \n",
    "    return result\n",
    "\n",
    "def roc_auc_score_per_time_slot(y_true, probas_pred):\n",
    "    \"\"\"\n",
    "    y_true: shape (N,1,L)\n",
    "    probas_pred: (N,1,L)\n",
    "    \"\"\"\n",
    "    N,_,L = y_true.shape\n",
    "    result = np.zeros(N)\n",
    "    \n",
    "    for i in range(N):\n",
    "        result[i] = average_precision_score(y_true=y_true[i,:,:].flatten(),\n",
    "                                            y_score=probas_pred[i,:,:].flatten())\n",
    "        \n",
    "    return result    \n",
    "    \n",
    "\n",
    "# metric_per_time_step - get the auc or ap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im(data_group.shaper.unsqueeze(probas_pred)[40][0])\n",
    "im(data_group.shaper.unsqueeze(loaders.test_loader.dataset.targets)[40][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders.test_loader.dataset.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = loaders.data_group.testing_set.targets\n",
    "\n",
    "# todo get better name\n",
    "probas_grid = np.zeros_like(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###### testing ###### torch outputs to see if we're actually getting valuable things out\n",
    "out = torch.Tensor([[-3,2],[2,-1],[0.5,0.4]])\n",
    "print(out.shape)\n",
    "print(out)\n",
    "out_soft = F.softmax(out, dim=-1)\n",
    "print(out_soft)\n",
    "out_label = torch.argmax(out_soft, dim=-1)\n",
    "print(out_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 79852,
     "status": "ok",
     "timestamp": 1566466668518,
     "user": {
      "displayName": "Bernard Swart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDulTxFaVYZ27_n_Ds4qquFn-4Ri8HUURRyOqf4WUo=s64",
      "userId": "00293673988406756138"
     },
     "user_tz": -120
    },
    "id": "SfZh9USWo8g2",
    "outputId": "13490f4e-83ab-4b20-cd91-7edc68ee9ad8"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_path + \"model_best.pth\"))\n",
    "conf = BaseConf(conf_dict=conf_dict)\n",
    "conf.batch_size = 4\n",
    "loaders = FlatDataLoaders(data_path=data_path, conf=conf)\n",
    "\n",
    "# EVALUATE MODEL\n",
    "with torch.set_grad_enabled(False):\n",
    "    # Transfer to GPU\n",
    "    testing_losses = []\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    probas_pred = []\n",
    "    \n",
    "    \n",
    "    # loop through is set does not fit in batch\n",
    "    for indices, spc_feats, tmp_feats, env_feats, targets in loaders.test_loader: \n",
    "        \"\"\"\n",
    "        IMPORTNANT NOTE: WHEN DOING LSTM - ONLY FEED THE TEMPORAL VECTORS IN THE LSTM\n",
    "        FEED THE REST INTO THE NORMAL LINEAR NETWORKS\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # Transfer to GPU\n",
    "        spc_feats = torch.Tensor(spc_feats).to(conf.device)\n",
    "        tmp_feats = torch.Tensor(tmp_feats).to(conf.device)\n",
    "        env_feats = torch.Tensor(env_feats).to(conf.device)\n",
    "        targets = torch.LongTensor(targets).to(conf.device)\n",
    "        \n",
    "        y_true.extend(targets.tolist())\n",
    "        out = model(spc_feats, tmp_feats, env_feats)\n",
    "                        \n",
    "        out = F.softmax(out, dim=-1)\n",
    "        \n",
    "        log.info(f\"out: {out}\")\n",
    "        log.info(f\"indices: {indices}\")\n",
    "        log.info(f\"indices: {targets}\")\n",
    "    \n",
    "        out_label = torch.argmax(out, dim=-1)\n",
    "        log.info(f\"out_label: {out_label}\")\n",
    "        y_pred.extend(out_label.tolist())\n",
    "        out_proba = out[:, 1]  # likelihood of crime is more general form - when comparing to moving averages\n",
    "        probas_pred.extend(out_proba.tolist())\n",
    "        \n",
    "        break  # !! remove\n",
    "\n",
    "\n",
    "# todo change to be the shape (N,L) of the original prediction.        \n",
    "model_result = ModelResult(model_name=\"FNN (Kang and Kang)\",\n",
    "                            y_true=y_true,\n",
    "                            y_pred=y_pred,\n",
    "                            probas_pred=probas_pred,\n",
    "                            t_range=loaders.test_loader.dataset.t_range,\n",
    "                            shaper=loaders.data_group.shaper)\n",
    "                        \n",
    "# log.info(model_result)\n",
    "\n",
    "np.savez_compressed(model_path + \"evaluation_results.npz\", model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-DRCri5po8g3"
   },
   "outputs": [],
   "source": [
    "pr_plotter = PRCurvePlotter()\n",
    "pr_plotter.add_curve(y_true, probas_pred, label_name=\"FNN (Kang and Kang)\")\n",
    "pr_plotter.savefig(model_path + \"plot_pr_curve.png\")\n",
    "\n",
    "roc_plotter = ROCCurvePlotter()\n",
    "roc_plotter.add_curve(y_true, probas_pred, label_name=\"FNN (Kang and Kang)\")\n",
    "roc_plotter.savefig(model_path + \"plot_roc_curve.png\")\n",
    "\n",
    "info[\"stop_time\"] = strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "write_json(info, model_path + \"info.json\")\n",
    "\n",
    "log.info(\"=====================================END=====================================\")targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K17LWEnyo8g5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0hpqNyfVo8g7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "run_kang_fnn_model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
