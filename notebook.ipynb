{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging as log\n",
    "from time import strftime\n",
    "from copy import deepcopy\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from utils.data_processing import *\n",
    "from logger.logger import setup_logging\n",
    "from utils.configs import BaseConf\n",
    "from utils.utils import write_json, Timer\n",
    "from models.kangkang_fnn_models import KangFeedForwardNetwork, SmallKangFNN\n",
    "from dataloaders.flat_loader import FlatDataLoaders, MockLoader, MockLoaders\n",
    "from datasets.flat_dataset import FlatDataGroup\n",
    "from utils.metrics import PRCurvePlotter, ROCCurvePlotter, LossPlotter, PerTimeStepPlotter\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score\n",
    "from models.model_result import ModelResult, ModelMetrics, save_metrics\n",
    "from utils.mock_data import mock_fnn_data_classification\n",
    "from utils.plots import im\n",
    "from utils.utils import pshape\n",
    "from trainers.generic_trainer import train_model\n",
    "from models.kangkang_fnn_models import train_epoch_for_fnn\n",
    "\n",
    "from utils.metrics import best_threshold, get_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-03T11:35:19 | root | INFO | =====================================BEGIN=====================================\n",
      "2019-11-03T11:35:19 | root | INFO | Device: cpu\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2013-01-01\"\n",
    "end_date = \"2015-01-01\" \n",
    "\n",
    "data_dim_str = \"T24H-X850M-Y880M\"  #\"T1H-X1700M-Y1760M\"  # needs to exist\n",
    "model_name = \"NOTE-BOOK-MODEL\"  # needs to be created\n",
    "data_path = f\"./data/processed/{data_dim_str}_{start_date}_{end_date}/\"\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    raise Exception(f\"Directory ({data_path}) needs to exist.\")\n",
    "\n",
    "model_path = data_path + f\"models/{model_name}/\"\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# logging config is set globally thus we only need to call this in this file\n",
    "# imported function logs will follow the configuration\n",
    "setup_logging(save_dir=model_path, log_config='./logger/standard_logger_config.json', default_level=log.INFO)\n",
    "log.info(\"=====================================BEGIN=====================================\")\n",
    "\n",
    "timer = Timer()\n",
    "# manually set the config\n",
    "# manually set the config\n",
    "conf_dict = {\n",
    "    \"seed\": 3,\n",
    "    \"use_cuda\": True,\n",
    "    \n",
    "    \"use_crime_types\": False,\n",
    "    \n",
    "    # data group/data set related\n",
    "    \"val_ratio\": 0.1,  # ratio of the total dataset\n",
    "    \"tst_ratio\": 0.3,# ratio of the total dataset\n",
    "    \"seq_len\": 1,\n",
    "    \"flatten_grid\": True,  # if the shaper should be used to squeeze the data\n",
    "    \n",
    "    # shaper related \n",
    "    \"shaper_top_k\": -1,  # if less then 0, top_k will not be applied\n",
    "    \"shaper_threshold\": 0,\n",
    "\n",
    "    \n",
    "    # data loader related\n",
    "    \"sub_sample_train_set\": True,\n",
    "    \"sub_sample_validation_set\": True,\n",
    "    \"sub_sample_test_set\": False,\n",
    "    \n",
    "    # training parameters\n",
    "    \"resume\": False,\n",
    "    \"early_stopping\": False,\n",
    "    \"tolerance\": 1e-8,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-8,\n",
    "    \"max_epochs\": 1,\n",
    "    \"batch_size\": 64,\n",
    "    \"dropout\": 0.2,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 6,\n",
    "    \n",
    "    # attached global variables - bad practice -find alternative\n",
    "    \"device\": None,  # pytorch device object [CPU|GPU]\n",
    "    \"timer\": Timer(),\n",
    "    \"model_name\": model_name,\n",
    "    \"model_path\": model_path,\n",
    "    \"checkpoint\": \"best\",\n",
    "    \n",
    "    \"use_seq_loss\": True,\n",
    "}\n",
    "conf = BaseConf(conf_dict=conf_dict)\n",
    "\n",
    "info = deepcopy(conf.__dict__)\n",
    "info[\"start_time\"] = strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "# DATA LOADER SETUP\n",
    "np.random.seed(conf.seed)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed( conf.seed)\n",
    "else:\n",
    "    torch.manual_seed(conf.seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "log.info(f\"Device: {device}\")\n",
    "info[\"device\"] = device.type\n",
    "conf.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-03T11:35:21 | root | INFO | \tt_range shape (731,)\n"
     ]
    }
   ],
   "source": [
    "conf.sub_sample_test_set = False\n",
    "conf.sub_sample_train_set = True\n",
    "conf.sub_sample_validation_set = True\n",
    "\n",
    "data_group = FlatDataGroup(data_path=data_path, conf=conf)\n",
    "loaders = FlatDataLoaders(data_group=data_group, conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729, 2, 9043)\n",
      "(585, 2, 9043)\n",
      "(474, 2, 9043)\n",
      "(402, 2, 9043)\n"
     ]
    }
   ],
   "source": [
    "pshape(data_group.crimes,\n",
    "       data_group.training_set.crimes,\n",
    "       data_group.testing_set.crimes,\n",
    "       data_group.validation_set.crimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9]],\n",
       "\n",
       "       [[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]],\n",
       "\n",
       "       [[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]],\n",
       "\n",
       "       [[30, 31, 32, 33, 34, 35, 36, 37, 38, 39]],\n",
       "\n",
       "       [[40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n",
       "\n",
       "       [[50, 51, 52, 53, 54, 55, 56, 57, 58, 59]],\n",
       "\n",
       "       [[60, 61, 62, 63, 64, 65, 66, 67, 68, 69]],\n",
       "\n",
       "       [[70, 71, 72, 73, 74, 75, 76, 77, 78, 79]],\n",
       "\n",
       "       [[80, 81, 82, 83, 84, 85, 86, 87, 88, 89]],\n",
       "\n",
       "       [[90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N,L = 10, 10\n",
    "\n",
    "np.arange(N*L).reshape(N,1,L)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
