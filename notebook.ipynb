{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging as log\n",
    "from time import strftime\n",
    "from copy import deepcopy\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from utils.data_processing import *\n",
    "from logger.logger import setup_logging\n",
    "from utils.configs import BaseConf\n",
    "from utils.utils import write_json, Timer\n",
    "from models.st_resnet_models import STResNet, STResNetExtra\n",
    "from dataloaders.grid_loader import GridDataLoaders\n",
    "from datasets.grid_dataset import GridDataGroup\n",
    "from utils.metrics import PRCurvePlotter, ROCCurvePlotter, LossPlotter\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score\n",
    "from models.model_result import ModelResult, ModelMetrics\n",
    "from utils.mock_data import mock_fnn_data_classification\n",
    "from utils.plots import im\n",
    "from utils.utils import pshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-28T02:59:03 | root | INFO | =====================================BEGIN=====================================\n",
      "2019-10-28T02:59:03 | root | INFO | Device: cpu\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2013-01-01\"\n",
    "end_date = \"2015-01-01\" \n",
    "\n",
    "data_dim_str = \"T1H-X1700M-Y1760M\"  # needs to exist\n",
    "model_name = \"ST-RESNET\"  # needs to be created\n",
    "data_path = f\"./data/processed/{data_dim_str}_{start_date}_{end_date}/\"\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    raise Exception(f\"Directory ({data_path}) needs to exist.\")\n",
    "\n",
    "model_path = data_path + f\"models/{model_name}/\"\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# logging config is set globally thus we only need to call this in this file\n",
    "# imported function logs will follow the configuration\n",
    "setup_logging(save_dir=model_path, log_config='./logger/standard_logger_config.json', default_level=log.INFO)\n",
    "log.info(\"=====================================BEGIN=====================================\")\n",
    "\n",
    "timer = Timer()\n",
    "# manually set the config\n",
    "# manually set the config\n",
    "conf_dict = {\n",
    "    \"seed\": 3,\n",
    "    \"use_cuda\": False,\n",
    "    \n",
    "    \"use_crime_types\": False,\n",
    "    \n",
    "    # data group/data set related\n",
    "    \"val_ratio\": 0.1,  # ratio of the total dataset\n",
    "    \"tst_ratio\": 0.2,# ratio of the total dataset\n",
    "    \"seq_len\": 1,\n",
    "    \"flatten_grid\": True,  # if the shaper should be used to squeeze the data\n",
    "    \n",
    "    # shaper related \n",
    "    \"shaper_top_k\": -1,  # if less then 0, top_k will not be applied\n",
    "    \"shaper_threshold\": 0,\n",
    "\n",
    "    \n",
    "    # data loader related\n",
    "    \"sub_sample_train_set\": True,\n",
    "    \"sub_sample_validation_set\": True,\n",
    "    \"sub_sample_test_set\": False,\n",
    "    \n",
    "    # training parameters\n",
    "    \"resume\": False,\n",
    "    \"early_stopping\": False,\n",
    "    \"tolerance\": 1e-8,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-8,\n",
    "    \"max_epochs\": 1,\n",
    "    \"batch_size\": 64,\n",
    "    \"dropout\": 0.2,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 6,\n",
    "    \n",
    "    # attached global variables - bad practice -find alternative\n",
    "    \"device\": None,  # pytorch device object [CPU|GPU]\n",
    "    \"timer\": Timer(),\n",
    "    \"model_name\": model_name,\n",
    "    \"model_path\": model_path,\n",
    "    \"checkpoint\": \"best\",\n",
    "    \n",
    "    \"use_seq_loss\": True,\n",
    "}\n",
    "conf = BaseConf(conf_dict=conf_dict)\n",
    "\n",
    "info = deepcopy(conf.__dict__)\n",
    "info[\"start_time\"] = strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "# DATA LOADER SETUP\n",
    "np.random.seed(conf.seed)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed( conf.seed)\n",
    "else:\n",
    "    torch.manual_seed(conf.seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "log.info(f\"Device: {device}\")\n",
    "info[\"device\"] = device.type\n",
    "conf.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-28T02:59:03 | root | INFO | Data shapes of files in generated_data.npz\n",
      "2019-10-28T02:59:03 | root | INFO | \tcrime_feature_indices shape (10,)\n",
      "2019-10-28T02:59:04 | root | INFO | \tcrime_types_grids shape (17520, 10, 24, 16)\n",
      "2019-10-28T02:59:04 | root | INFO | \tcrime_grids shape (17520, 1, 24, 16)\n",
      "2019-10-28T02:59:05 | root | INFO | \ttract_count_grids shape (17520, 1, 24, 16)\n",
      "2019-10-28T02:59:05 | root | INFO | \tdemog_grid shape (1, 37, 24, 16)\n",
      "2019-10-28T02:59:05 | root | INFO | \tstreet_grid shape (1, 512, 24, 16)\n",
      "2019-10-28T02:59:05 | root | INFO | \ttime_vectors shape (17521, 66)\n",
      "2019-10-28T02:59:05 | root | INFO | \tweather_vectors shape (8760, 11)\n",
      "2019-10-28T02:59:05 | root | INFO | \tx_range shape (16,)\n",
      "2019-10-28T02:59:05 | root | INFO | \ty_range shape (24,)\n",
      "2019-10-28T02:59:05 | root | INFO | \tt_range shape (17521,)\n"
     ]
    }
   ],
   "source": [
    "conf.batch_size = 3\n",
    "data_group = GridDataGroup(data_path=data_path, conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = GridDataLoaders(data_group=data_group,conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3403, 24, 16)\n",
      "(3403, 24, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loader = loaders.test_loader\n",
    "\n",
    "\n",
    "probas_pred = np.zeros(batch_loader.dataset.target_shape,dtype=np.float)\n",
    "# new_targets = np.ones_like(batch_loader.dataset.targets,dtype=np.float)\n",
    "# new_targets = new_targets * np.arange(len(new_targets)).reshape(-1,1,1)\n",
    "# batch_loader.dataset.targets = new_targets\n",
    "\n",
    "y_true = batch_loader.dataset.crimes[-len(probas_pred):]\n",
    "pshape(y_true,probas_pred)\n",
    "for batch_indices, batch_seq_c, batch_seq_p, batch_seq_q, batch_seq_e, batch_seq_t in batch_loader:\n",
    "#     pshape(batch_indices, batch_seq_c, batch_seq_p, batch_seq_q, batch_seq_e, batch_seq_t)\n",
    "#     break\n",
    "    \n",
    "    for i,t in zip(batch_indices, batch_seq_c):\n",
    "        probas_pred[i] = t[-1]\n",
    "        \n",
    "\n",
    "        \n",
    "np.equal(probas_pred, y_true).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 3, 24, 16)\n",
      "(3, 3, 24, 16)\n",
      "(3, 3, 24, 16)\n",
      "(3, 1, 66)\n",
      "(3, 1, 24, 16)\n",
      "torch.Size([3, 1, 24, 16])\n"
     ]
    }
   ],
   "source": [
    "batch_loader = loaders.test_loader  # currently looking at the test data\n",
    "\n",
    "dataset = batch_loader.dataset\n",
    "\n",
    "_, h_size, w_size = dataset.crimes.shape\n",
    "_, n_ext_features = dataset.time_vectors.shape\n",
    "\n",
    "# model = STResNet(n_layers=3,\n",
    "#                  n_channels=1,\n",
    "#                  y_size=h_size,\n",
    "#                  x_size=w_size,\n",
    "    \n",
    "#                  lc=dataset.n_steps_c,\n",
    "#                  lp=dataset.n_steps_p,\n",
    "#                  lq=dataset.n_steps_q,\n",
    "\n",
    "#                  n_ext_features=n_ext_features)\n",
    "\n",
    "\n",
    "model = STResNetExtra(n_layers=3,\n",
    "                      n_channels=1, y_size=h_size,\n",
    "                      x_size=w_size,\n",
    "\n",
    "                      lc=dataset.n_steps_c,\n",
    "                      lp=dataset.n_steps_p,\n",
    "                      lq=dataset.n_steps_q,\n",
    "\n",
    "                      n_ext_features=n_ext_features,\n",
    "                      n_demog_features=37,\n",
    "                      n_demog_channels=10,\n",
    "                      n_demog_layers=3,\n",
    "\n",
    "                      n_gsv_features=512,\n",
    "                      n_gsv_channels=10,\n",
    "                      n_gsv_layers=3)\n",
    "\n",
    "demog_grid = torch.Tensor(dataset.demog_grid).to(conf.device)\n",
    "street_grid = torch.Tensor(dataset.street_grid).to(conf.device)\n",
    "\n",
    "for batch_indices, batch_seq_c, batch_seq_p, batch_seq_q, batch_seq_e, batch_seq_t in batch_loader:\n",
    "    pshape(batch_indices, batch_seq_c, batch_seq_p, batch_seq_q, batch_seq_e, batch_seq_t)\n",
    "    \n",
    "    batch_seq_c = torch.Tensor(batch_seq_c).to(conf.device)\n",
    "    batch_seq_p = torch.Tensor(batch_seq_p).to(conf.device)\n",
    "    batch_seq_q = torch.Tensor(batch_seq_q).to(conf.device)\n",
    "    batch_seq_e = torch.Tensor(batch_seq_e).to(conf.device)\n",
    "    batch_seq_t = torch.Tensor(batch_seq_t).to(conf.device)\n",
    "    \n",
    "    probas_pred = model(seq_c=batch_seq_c,\n",
    "                        seq_p=batch_seq_p,\n",
    "                        seq_q=batch_seq_q,\n",
    "                        seq_e=batch_seq_e,\n",
    "                        seq_demog=demog_grid,  # TODO MOVE TO LOADER AND MAKE BATCHES OF THE SAME THING\n",
    "                        seq_gsv=street_grid,\n",
    "                       )\n",
    "    \n",
    "    print(probas_pred.size())\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "demog_grid = torch.Tensor(dataset.demog_grid).to(conf.device)\n",
    "street_grid = torch.Tensor(dataset.street_grid).to(conf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 37, 24, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.demog_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
