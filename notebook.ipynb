{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from models.baseline_models import UniformMovingAverage, TriangularMovingAverage, ExponentialMovingAverage\n",
    "from utils.plots import plot\n",
    "import pandas as pd\n",
    "from utils.plots import plot_time_signals\n",
    "from utils.utils import shift\n",
    "import scipy as sp\n",
    "from utils.rolling import periodic_rolling\n",
    "from IPython.display import display\n",
    "from utils.data_processing import to_percentile\n",
    "from utils.mutual_information_plots import plot_mi \n",
    "from utils.plots import plot_autocorr\n",
    "from utils.utils import cut\n",
    "from pandas.io import clipboard\n",
    "import os\n",
    "from utils.rolling import rolling_norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pprint import pformat\n",
    "\n",
    "def size_of(thing):\n",
    "    byte_size = sys.getsizeof(thing)\n",
    "    i = int(np.log(byte_size)/np.log(1024))\n",
    "    \n",
    "    byte_size = byte_size / (1024)**i\n",
    "    \n",
    "    units = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\"]\n",
    "    \n",
    "    if i >= len(units):\n",
    "        unit = units[-1]\n",
    "    else:\n",
    "        unit = units[i]\n",
    "    \n",
    "    return f\"{byte_size:.3f} {unit}\"\n",
    "\n",
    "def date_range_to_kwargs(date_range):\n",
    "    assert date_range.freq != None, \"date_range argument must have a fixed frequency. date_range.freq == None\"\n",
    "    return dict(start=date_range[0], end=date_range[-1], freq=date_range.freq)\n",
    "\n",
    "\n",
    "class DateRangeInfo:\n",
    "    \n",
    "    def __init__(self, date_range):\n",
    "        self.kwargs = date_range_to_kwargs(date_range)\n",
    "        \n",
    "    def date_range(self):\n",
    "        return pd.date_range(**self.kwargs)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        for k,v in self.kwargs.items():\n",
    "            if other.kwargs.get(k) != v:\n",
    "                print(f\"DateRangeInfo values for '{k}' field do not match\")\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return pformat(self.kwargs)\n",
    "\n",
    "\n",
    "# TODO ON EACH METRIC SAVE THE DATE RANGE META\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('48.000 B', '884.594 KB')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_of(dri1), size_of(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing EWM EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.baseline_models import ExponentialMovingAverage as EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing if dataerange with conbstant freq size is small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pd.date_range('1902', '2212')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'884.594 KB'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_of(tr) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'232.000 B'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_of(date_range_to_kwargs(tr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.085 MB'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_info = dict(start=tr[0], end=tr[-1], freq=tr.freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.date_range(**tr_info)==tr).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thesis document figures copy pasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_files = [\n",
    "    name for \n",
    "    name in os.listdir('./data/processed/Totals_T168H_2001-01-04_2019-01-10_LAT41.641_42.024_'+\n",
    "                       'LON-87.821_-87.525/plots')\n",
    "    if name.endswith('png')\n",
    "]\n",
    "clipboard.copy('''\n",
    "'''.join([f'''\n",
    "\\\\begin{{figure}}\n",
    "    \\centering\n",
    "    \\includegraphics[width=0.95\\\\textwidth]{{\\plotsweekly{{{file}}}}}\n",
    "    %TODO: ADD FIGURE NAME\n",
    "    \\caption{{TODO: ADD FIGURE NAME}}\n",
    "    \\label{{fig:{file[:-4].lower()}}}\n",
    "\\end{{figure}}''' for file in weekly_files]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_files = [\n",
    "    name for \n",
    "    name in os.listdir('./data/processed/Totals_T24H_2001-01-01_2019-01-02_LAT41.641_42.024_'+\n",
    "                       'LON-87.821_-87.525/plots')\n",
    "    if name.endswith('png')\n",
    "]\n",
    "clipboard.copy('''\n",
    "'''.join([f'''\n",
    "\\\\begin{{figure}}\n",
    "    \\centering\n",
    "    \\includegraphics[width=0.95\\\\textwidth]{{\\plotsweekly{{{file}}}}}\n",
    "    %TODO: ADD FIGURE NAME\n",
    "    \\caption{{TODO: ADD FIGURE NAME}}\n",
    "    \\label{{fig:{file[:-4].lower()}}}\n",
    "\\end{{figure}}''' for file in daily_files]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_files = [\n",
    "    name for \n",
    "    name in os.listdir('./data/processed/Totals_T1H_2014-01-01_2019-01-01_LAT41.641_42.024_'+\n",
    "                       'LON-87.821_-87.525/plots')\n",
    "    if name.endswith('png')\n",
    "]\n",
    "clipboard.copy('''\n",
    "'''.join([f'''\n",
    "\\\\begin{{figure}}\n",
    "    \\centering\n",
    "    \\includegraphics[width=0.95\\\\textwidth]{{\\plotsweekly{{{file}}}}}\n",
    "    %TODO: ADD FIGURE NAME\n",
    "    \\caption{{TODO: ADD FIGURE NAME}}\n",
    "    \\label{{fig:{file[:-4].lower()}}}\n",
    "\\end{{figure}}''' for file in hourly_files]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence datasets subset selections\n",
    "\n",
    "combined_train_valid_set = torch.utils.data.ConcatDataset([\n",
    "    train_loader.dataset.dataset, \n",
    "    valid_loader.dataset.dataset,\n",
    "])\n",
    "combined_train_valid_loader = torch.utils.data.DataLoader(\n",
    "    combined_train_valid_set, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentile ranking/binning to make MI calculation more robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 24\n",
    "a = np.sin(2*np.pi*(np.arange(24*100)%24)/24)\n",
    "a[0] = np.max(a)*6\n",
    "a_pct = to_percentile(a)\n",
    "a_cut = cut(x=a,bins=10)\n",
    "print(a_cut)\n",
    "\n",
    "plot(\n",
    "    a=a,\n",
    "    a_pct=a_pct,\n",
    "    a_cut=a_cut,\n",
    ").show()\n",
    "\n",
    "for bins in [0,5,100,len(np.unique(a))]:\n",
    "    plot_mi(a_cut=a_cut,a_pct=a_pct,a=a, bins=bins, title=f\"Auto MI ({bins})\").show()\n",
    "plot_autocorr(a_cut=a_cut,a_pct=a_pct,a=a).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sp.stats.expon.rvs(.1*np.ones(100))\n",
    "# data = sp.stats.norm.rvs(.1*np.ones(100))\n",
    "data[0] = np.max(data)**2\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=data, columns=['x'])\n",
    "df['pct'] = df.rank(pct=True)\n",
    "display(df)\n",
    "\n",
    "X = np.unique(df.values, axis=0)\n",
    "val, perc = X[:,0], X[:,1]\n",
    "\n",
    "plt.bar(x=val,height=perc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated Maximum Prediction Gain\n",
    "Periodic signals - signal can be predicted with constant accuracy regardless of interval\n",
    "\n",
    "Normalise gaussian process\n",
    "Normalise poisson process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Example of periodic poisson process and how well periodic average estimates the mu of the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_bins(a):\n",
    "    # flag anomalies of the data and set bin limits to everything withn the limits\n",
    "    window =51\n",
    "    period = {\n",
    "        \"24H\":7,\n",
    "        \"1H\": 24,\n",
    "        \"168H\":1,\n",
    "    }.get(FREQ, 1)\n",
    "    thresh = 3\n",
    "    period = 1\n",
    "    \n",
    "    anoms = flag_anomalies(\n",
    "        data=a, \n",
    "        thresh=thresh,\n",
    "        window=window, \n",
    "        period=period, \n",
    "        center=True,\n",
    "        mode='reflect',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 24\n",
    "n = period*500\n",
    "window = 10\n",
    "center = True\n",
    "lambdas = np.ones(n)*.3\n",
    "lambdas = .1*(np.sin(2*np.pi*(np.arange(n)%period)/period) + 1) \n",
    "# lambdas = 1*(np.arange(n)%period)/period\n",
    "\n",
    "decay = np.exp(-1*np.linspace(0.1,1,n))\n",
    "# lambdas = decay*(lambdas + 1)\n",
    "\n",
    "date_range = pd.date_range('2020',freq='H', periods=n)\n",
    "\n",
    "# generate sampels\n",
    "summed_data = []\n",
    "summed_lambdas = []\n",
    "num_samples = 1\n",
    "\n",
    "rand_w = np.random.rand(num_samples)\n",
    "for i in range(num_samples):\n",
    "    summed_lambdas.append(rand_w[i]*lambdas)\n",
    "    data = sp.stats.poisson.rvs(rand_w[i]*lambdas)\n",
    "#     data =  data + .2*(sp.stats.poisson.rvs(np.roll(data,1)) +\n",
    "#                        sp.stats.poisson.rvs(np.roll(data,13)) +\n",
    "#                        sp.stats.poisson.rvs(np.roll(data,19)))\n",
    "    \n",
    "    summed_data.append(data)\n",
    "    \n",
    "data = np.array(summed_data).sum(0)\n",
    "lambdas = np.array(summed_lambdas).sum(0)\n",
    "\n",
    "# data = np.cumsum(np.random.randn(n))\n",
    "# data = lambdas\n",
    "\n",
    "mu = periodic_rolling(\n",
    "    func=np.mean,\n",
    "    data=data,\n",
    "    window=window,\n",
    "    period=period,\n",
    "    center=center,\n",
    "    fill=np.nan,\n",
    ")\n",
    "\n",
    "std = periodic_rolling(\n",
    "    func=np.std,\n",
    "    data=data,\n",
    "    window=window,\n",
    "    period=period,\n",
    "    center=center,\n",
    ")\n",
    "\n",
    "plot_time_signals(\n",
    "    t_range=date_range,\n",
    "    data=data, \n",
    "    lambdas=lambdas,\n",
    "    mu=mu,\n",
    ").show()\n",
    "\n",
    "# test if data is normal depending on the number of underlying point process\n",
    "normed_data = pd.DataFrame(data=(data-lambdas),columns=[f'Normed Data (N={num_samples})'])\n",
    "normed_data = normed_data / normed_data.std()\n",
    "normed_data.plot(kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mutual_information_plots import plot_mi_curves\n",
    "from utils.plots import plot_autocorr\n",
    "from statsmodels.tsa.stattools import acf, pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mutual_information_plots import plot_mi_curves\n",
    "from utils.plots import plot_autocorr\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "nlags = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mutual_information_plots import plot_mi_curves\n",
    "from utils.plots import plot_autocorr\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "nlags = 130\n",
    "\n",
    "plot_autocorr(data=data, max_offset=nlags).show()\n",
    "plot_autocorr(data=data, max_offset=nlags, partial=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_bins = int(np.ceil(np.max(data)+1))\n",
    "\n",
    "plot_mi_curves(\n",
    "    t_range=date_range,\n",
    "    a=data,\n",
    "    max_offset=nlags,\n",
    "    norm=True,\n",
    "    log_norm=False,\n",
    "    bins=int(np.ceil(np.max(data)+1)),\n",
    "    temporal_variables=['Hour'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomoly Detection in Time series\n",
    "- Low-pass filter: moving average\n",
    "- Minus from original signal to get residuals\n",
    "- Find outliers in residual signal outside of 3 standard deviations and mark indices\n",
    "- Filter out the outliers\n",
    "\n",
    "\n",
    "Have periodic moving average and std and normalise the data to detect anomolies - feeling is that std window should be longer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.rolling import flag_anomalies, rolling_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2000\n",
    "var = (np.sin(np.linspace(1,15,n)) + 1.5)\n",
    "\n",
    "anoms = np.random.binomial(n=1,p=.1,size=n)\n",
    "anoms[[0,-1]] = 1 # ensures we have anomalies near start and end - don't want to lose these\n",
    "\n",
    "noise = np.random.randn(n)\n",
    "process = np.cumsum(np.random.randn(n))\n",
    "\n",
    "data = (process + noise*.1 + np.sign(np.random.randn(len(anoms)))*anoms*6)*var\n",
    "data = pd.Series(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.rolling import rolling_norm\n",
    "window = 21\n",
    "center=True\n",
    "mode='reflect'\n",
    "\n",
    "data_normed = rolling_norm(data=data,window=window,center=center, mode=mode)\n",
    "\n",
    "plot(\n",
    "    data_normed=data_normed,\n",
    "    data=data,\n",
    ").show()\n",
    "\n",
    "pd.Series(data_normed).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_thresh = 1.7\n",
    "detected = flag_anomalies(\n",
    "    data=data.values,\n",
    "    thresh=sigma_thresh,\n",
    "    window=window,\n",
    "    center=center,\n",
    "    mode=mode,\n",
    ")\n",
    "\n",
    "xs = np.arange(len(data))\n",
    "\n",
    "go.Figure(\n",
    "    data=[\n",
    "        go.Scatter(name='pred',x=detected,y=data[detected],  mode='markers', marker={\n",
    "            'symbol':3,\n",
    "            'size': 10,\n",
    "        }, opacity=0.5),\n",
    "        go.Scatter(name='true',x=xs[anoms > 0],y=data[anoms > 0],  mode='markers', marker={\n",
    "            'symbol':4,\n",
    "            'size': 10,\n",
    "        }, opacity=0.5),\n",
    "        go.Scatter(name='data',y=data, opacity=0.5),\n",
    "        go.Scatter(name='process*var',y=process*var, opacity=0.5),\n",
    "    ]\n",
    ").show()\n",
    "\n",
    "\n",
    "go.Figure(\n",
    "    data=[\n",
    "        go.Scatter(name='pred',x=detected,y=data_normed[detected],  mode='markers', marker={\n",
    "            'symbol':3,\n",
    "            'size': 15,\n",
    "        }, opacity=0.5),\n",
    "        go.Scatter(name='true',x=xs[anoms > 0],y=data_normed[anoms > 0],  mode='markers', marker={\n",
    "            'symbol':4,\n",
    "            'size': 15,\n",
    "        }, opacity=0.5),\n",
    "        go.Scatter(name='data_normed',y=data_normed, opacity=0.5),\n",
    "    ],\n",
    ").show()\n",
    "\n",
    "y_pred = np.zeros_like(anoms)\n",
    "y_pred[detected] = 1\n",
    "y_true = anoms\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(\n",
    "    y_true=y_true,\n",
    "    y_pred=y_pred,\n",
    ")\n",
    "\n",
    "print(f\"f1 => {f1:.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive Time Series Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from ipywidgets import Layout, widgets\n",
    "from utils.interactive import State\n",
    "from utils.interactive import interactive_crime_prediction_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,10,200)\n",
    "y = np.sin(x)*4 + 4\n",
    "y = np.reshape(y, (len(y),1,1))\n",
    "y_score = np.ones((len(y),7,5))\n",
    "y_score = y_score*y + np.random.randn(*np.shape(y_score))\n",
    "\n",
    "y_class = np.random.rand(*np.shape(y_score))\n",
    "y_class[y_class > .9] = 1\n",
    "y_class[y_class <= .9] = 0\n",
    "\n",
    "t_range = pd.date_range(start='2012',periods=len(x), freq='1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_crime_prediction_comparison(y_class=y_class,\n",
    "                                        y_score=y_score,\n",
    "                                        t_range=t_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DET Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.metrics import det_curve, plot_det_curve, DETCurvePlotter\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_det_curve(y_class, y_score):    \n",
    "    rcParams[\"mathtext.fontset\"] = \"stix\"\n",
    "    rcParams[\"font.family\"] = \"STIXGeneral\"\n",
    "    rcParams[\"font.size\"] = \"18\"\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    \n",
    "    fpr, fnr, thresholds = det_curve(y_class, y_score)\n",
    "\n",
    "    ax.plot(\n",
    "        sp.stats.norm.ppf(fpr),\n",
    "        sp.stats.norm.ppf(fnr),\n",
    "    )\n",
    "    \n",
    "    ticks = [0.001, 0.01, 0.05, 0.20, 0.5, 0.80, 0.95, 0.99, 0.999]\n",
    "    tick_locations = sp.stats.norm.ppf(ticks)\n",
    "    tick_labels = [\n",
    "        '{:.0%}'.format(s) if (100*s).is_integer() else '{:.1%}'.format(s)\n",
    "        for s in ticks\n",
    "    ]\n",
    "    \n",
    "    ax.set_title(\"Detection Error Tradeoff (DET) Curve\")\n",
    "    \n",
    "    ax.set_ylabel('False Negative Rate (Miss Probability)')\n",
    "    ax.set_xlabel('False Positive Rate (False Alarm Probability)')\n",
    "    \n",
    "    ax.set_xticks(tick_locations)\n",
    "    ax.set_xticklabels(tick_labels)\n",
    "    ax.set_xlim(-3, 3)\n",
    "    ax.set_yticks(tick_locations)\n",
    "    ax.set_yticklabels(tick_labels)\n",
    "    ax.set_ylim(-3, 3)\n",
    "    \n",
    "    ax.grid()\n",
    "    \n",
    "    \n",
    "    return fig, ax\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_det_curve(y_class=np.random.randint(0,2,100),\n",
    "                    y_score=np.random.rand(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppf = sp.stats.norm.ppf\n",
    "cdf = sp.stats.norm.cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model_result import get_models_metrics\n",
    "\n",
    "\n",
    "data_path = './data/processed/T24H-X850M-Y880M_2012-01-01_2019-01-01_#826/'\n",
    "\n",
    "metrics = get_models_metrics(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import plot_det_curve_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_plot = DETCurvePlotter()\n",
    "for metric in metrics:\n",
    "    det_plot.add_curve_(fpr=metric.det_curve.fpr,\n",
    "                        fnr=metric.det_curve.fnr,\n",
    "                        eer=metric.det_curve.eer,  # note this is the mean roc_score not this curves score\n",
    "                        label_name=metric.model_name)\n",
    "det_plot.show()  # todo - save somewhere?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_det_curve_(fpr=metric.det_curve.fpr,\n",
    "                          fnr=metric.det_curve.fnr, \n",
    "                          thresholds=metric.det_curve.thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = get_models_metrics(data_path)\n",
    "fig = go.Figure(\n",
    "    layout=dict(\n",
    "        title_text=\"Detection Error Tradeoff (DET) Curve\",\n",
    "        title_x=0.5,\n",
    "        height=650,\n",
    "        #         width=650,\n",
    "        #         yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "        yaxis_title='False Negative Rate',\n",
    "        xaxis_title='False Positive Rate',\n",
    "        yaxis=dict(range=[-3,3], scaleanchor=\"x\", scaleratio=1),\n",
    "        xaxis=dict(range=[-3, 3]), #, type=\"log\"),\n",
    "        \n",
    "#         yaxis=dict(type=\"log\"),\n",
    "#         xaxis=dict(type=\"log\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "for metric in metrics:\n",
    "    fnr_scaled = sp.stats.norm.ppf(metric.det_curve.fnr)\n",
    "    fpr_scaled = sp.stats.norm.ppf(metric.det_curve.fpr)\n",
    "#     fnr_scaled = metric.det_curve.fnr*100\n",
    "#     fpr_scaled = metric.det_curve.fpr*100\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            y=fnr_scaled,\n",
    "            x=fpr_scaled,\n",
    "            name=f\"{metric.model_name} (EER={metric.det_curve.eer:.3f})\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import by_ref, get_data_sub_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_paths = by_ref(\"826\")\n",
    "sub_path = sub_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"data/processed/{sub_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cell distributions and cells\n",
    "\n",
    "\n",
    "def plot_data_dist(data):\n",
    "    data = np.flatten(data)\n",
    "    values, counts = np.unique(data, return_counts=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.data.tips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.configs import BaseConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = BaseConf()\n",
    "conf.data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available(), torch.cuda.is_initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.rand(10,1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(tt.T,tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_slider = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description='Month:',\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "\n",
    "gvalue = None\n",
    "def widget_callback(change):\n",
    "    global gvalue\n",
    "    gvalue = change\n",
    "\n",
    "    \n",
    "int_slider.observe(widget_callback, names=\"value\")\n",
    "\n",
    "play_button = widgets.Play(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    interval=500,\n",
    "    description=\"Press play\",\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "widgets.jslink((play_button, 'value'), (int_slider, 'value'))\n",
    "\n",
    "widgets.VBox([\n",
    "    play_button,\n",
    "    int_slider,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.plots import im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub_path = \"T24H-X850M-Y880M_2012-01-01_2019-01-01\"\n",
    "file_location = f\"./data/processed/{data_sub_path}/generated_data.npz\"\n",
    "if os.path.exists(file_location):\n",
    "    with np.load(file_location) as zip_file:  # context helper ensures zip_file is closed\n",
    "        print(list(zip_file.keys()))\n",
    "        crime_grids = zip_file[\"crime_grids\"]\n",
    "        x_range = zip_file[\"x_range\"]\n",
    "        y_range = zip_file[\"y_range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = crime_grids.mean(axis=(0,1))\n",
    "\n",
    "grid = np.flipud(mean)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "xx, yy = np.meshgrid(x_range, y_range)\n",
    "plt.pcolormesh(xx, yy, grid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = x_range[0], x_range[-1]\n",
    "y_min, y_max = y_range[0], y_range[-1]\n",
    "\n",
    "y_ticks = np.linspace(y_min, y_max, len(y_range))\n",
    "x_ticks = np.linspace(x_min, x_max, len(x_range))\n",
    "\n",
    "coords = list(map(tuple,zip(x_range, y_range)))\n",
    "plt.figure(figsize=(15,15))\n",
    "c = np.linspace(0.5,0.9,len(yy.flatten())) \n",
    "plt.scatter(x=xx.flatten(), y=yy.flatten(), c=c, marker='x')\n",
    "\n",
    "plt.xticks(x_ticks,rotation=90)\n",
    "plt.yticks(y_ticks,rotation=0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance as geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((y_min,x_min),(y_max,x_max))\n",
    "\n",
    "origin=(y_min,x_min)\n",
    "def distance_meters(point1, point2):\n",
    "    \"\"\"\n",
    "    point is a tuple of coordinates in degrees: (y,x) or (lat, lon)\n",
    "    \"\"\"\n",
    "    distance = geo.distance(point1,point2)\n",
    "    return distance.meters\n",
    "\n",
    "def distance_manhattan(point):\n",
    "    \"\"\"\n",
    "    point is a tuple of coordinates in degrees: (y,x) or (lat, lon)\n",
    "    \"\"\"\n",
    "    y_point, x_point = point\n",
    "    y_origin, x_origin = origin\n",
    "    \n",
    "    x_meters = geo.distance(point,(y_point,x_origin)).meters\n",
    "    y_meters = geo.distance(point,(y_origin,x_point)).meters\n",
    "    \n",
    "    return (y_meters,x_meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(x_range, y_range)\n",
    "yyxx = list(map(tuple,zip(yy.flatten(),xx.flatten())))\n",
    "yyxx = list(map(distance_manhattan,yyxx))\n",
    "y = coords[:,0]\n",
    "x = coords[:,1]\n",
    "coords = np.array(yyxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.axis('equal')\n",
    "plt.scatter(x,y,c=np.linspace(0,1,len(coords[:,1])),marker=\"+\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36889,
     "status": "ok",
     "timestamp": 1573553850760,
     "user": {
      "displayName": "Bernard Swart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA7uSA62RDxMrL_HdFxD2SxWswIX97G3OjMRiFvmMU=s64",
      "userId": "00293673988406756138"
     },
     "user_tz": -120
    },
    "id": "yLgwkH0gHZeT",
    "outputId": "20a351d6-06bb-4fd1-c625-c928bf01dafd"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd /content/gdrive/My\\ Drive/masters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XW9pG3xUGVWK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging as log\n",
    "from time import strftime\n",
    "from copy import deepcopy\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from utils.data_processing import *\n",
    "from logger.logger import setup_logging\n",
    "from utils.configs import BaseConf\n",
    "from utils.utils import write_json, get_data_sub_paths\n",
    "from models.kangkang_fnn_models import KangFeedForwardNetwork, SimpleKangFNN\n",
    "from dataloaders.flat_loader import FlatDataLoaders, MockLoader, MockLoaders\n",
    "from datasets.flat_dataset import FlatDataGroup\n",
    "from utils.metrics import PRCurvePlotter, ROCCurvePlotter, LossPlotter, PerTimeStepPlotter\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score\n",
    "from models.model_result import ModelResult, ModelMetrics, save_metrics\n",
    "from utils.mock_data import mock_fnn_data_classification\n",
    "from utils.plots import im\n",
    "from utils.utils import pshape\n",
    "from trainers.generic_trainer import train_model\n",
    "from models.kangkang_fnn_models import train_epoch_for_fnn\n",
    "from utils.configs import BaseConf\n",
    "from utils.metrics import best_threshold, get_y_pred\n",
    "from dataloaders.grid_loader import GridDataLoaders\n",
    "from datasets.grid_dataset import GridDataGroup\n",
    "%matplotlib inline\n",
    "from utils.mock_data import mock_fnn_data_classification\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from utils.plots import im\n",
    "from utils.metrics import best_threshold, get_y_pred, get_y_pred_by_thresholds, best_thresholds\n",
    "from models.model_result import ModelResult, ModelMetrics, save_metrics, compare_all_models,\\\n",
    "                                get_models_metrics, get_models_results\n",
    "from models.baseline_models import ExponentialMovingAverage, UniformMovingAverage, \\\n",
    "                                    TriangularMovingAverage, HistoricAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(get_data_sub_paths())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'T24H-X255M-Y220M_2013-01-01_2015-01-01',\n",
    "'T24H-X425M-Y440M_2013-01-01_2015-01-01',\n",
    "'T24H-X850M-Y880M_2013-01-01_2015-01-01',\n",
    "'T24H-X850M-Y880M_2013-01-01_2017-01-01',\n",
    "'T24H-X85M-Y110M_2013-01-01_2015-01-01',\n",
    "'T12H-X850M-Y880M_2013-01-01_2015-01-01',\n",
    "'T3H-X850M-Y880M_2013-01-01_2015-01-01',\n",
    "'T6H-X850M-Y880M_2013-01-01_2015-01-01'\n",
    "'T1H-X850M-Y880M_2013-01-01_2015-01-01',\n",
    "'T1H-X1700M-Y1760M_2013-01-01_2015-01-01',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUFNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(GRUFNN, self).__init__()\n",
    "\n",
    "        self.name = \"GRUFNN\"\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers)  # (seq_len, batch_size, n_features) format\n",
    "        self.lin1 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, h0=None):\n",
    "        # Forward propagate RNN\n",
    "        if h0 is not None:\n",
    "            out, hn = self.gru(x, h0)\n",
    "        else:\n",
    "            out, hn = self.gru(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.lin1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(100)\n",
    "y = 1+ np.sin(2*np.pi*x/30) #+ np.sin(2*np.pi*x/100)\n",
    "t = np.copy(y)\n",
    "t = t[1:]\n",
    "y = y[:-1]\n",
    "x = x[1:]\n",
    "plt.plot(x,y)\n",
    "plt.plot(x,t)\n",
    "\n",
    "y = np.expand_dims(y,-1)\n",
    "y = np.expand_dims(y,-1)\n",
    "\n",
    "\n",
    "t = np.expand_dims(t,-1)\n",
    "t = np.expand_dims(t,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.Tensor(y)\n",
    "trg = torch.Tensor(t)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "model = GRUFNN(input_size=1, hidden_size=10, output_size=1)  # seq_len, batch_size, \n",
    "parameters = model.parameters()\n",
    "optimiser = optim.Adam(params=parameters,\n",
    "                       lr=1e-3,\n",
    "                       weight_decay=0)\n",
    "out = model(inp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xsF9y43qGVWh"
   },
   "outputs": [],
   "source": [
    "x = np.arange(100)\n",
    "y = 1+ np.sin(2*np.pi*x/30) #+ np.sin(2*np.pi*x/100)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(x,y)\n",
    "plt.scatter(x,y,s=10,marker='|')\n",
    "plt.grid()\n",
    "for time_step in [1]:\n",
    "    uno = UniformMovingAverage(window_len=3)\n",
    "    ha = HistoricAverage(step=time_step)\n",
    "    o = ha(y)\n",
    "    plt.plot(x,o)\n",
    "    plt.scatter(x,o,s=10,marker='|',label=\"ha\"+str(time_step))\n",
    "    \n",
    "    o = uno(y)\n",
    "    \n",
    "    plt.plot(x,o)\n",
    "    plt.scatter(x,o,s=10,marker='|',label=\"un\"+str(time_step))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z31GGHUpGVWm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z7JUf3F0GVWr"
   },
   "source": [
    "#### Ensure data_group for the grid and the . flat dataset are both working with the same data and same shaper and same dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub_paths = get_data_sub_paths()\n",
    "np.sort(data_sub_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub_paths = get_data_sub_paths()\n",
    "pprint(np.sort(data_sub_paths))\n",
    "data_sub_path = 'T24H-X425M-Y440M_2013-01-01_2015-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54KLYlQCGVWs"
   },
   "outputs": [],
   "source": [
    "conf = BaseConf()\n",
    "conf.data_path = f\"./data/processed/{data_sub_path}/\"\n",
    "conf.model_name = \"dev-model\"\n",
    "conf.model_path = f\"{conf.data_path}models/{conf.model_name}\"\n",
    "\n",
    "flat_group = FlatDataGroup(data_path=conf.data_path, conf=conf)\n",
    "flat_loaders = FlatDataLoaders(data_group=flat_group, conf=conf)\n",
    "\n",
    "# grid_group = GridDataGroup(data_path=conf.data_path, conf=conf)\n",
    "# grid_loaders = GridDataLoaders(data_group=grid_group, conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_group.crimes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(101)\n",
    "a[0] *= .4\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time step in this context is used for \n",
    "freqstr = flat_group.t_range.freqstr\n",
    "if freqstr == \"H\":\n",
    "    freqstr = \"1H\"\n",
    "time_step = int(24 / int(freqstr[:freqstr.find(\"H\")]))\n",
    "time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = flat_group.crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[:,0].mean(-1),label=\"crimes\")\n",
    "plt.plot(data[:,1].mean(-1),label=\"tract\")\n",
    "plt.plot(data[:,2].mean(-1),label=\"historic average\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.baseline_models import historic_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historic_average(data, step, max_steps):\n",
    "    \"\"\"\n",
    "    historic_average get's the historic average of the following time step without including that time step.\n",
    "    it get's the the historic average of each cell and then moves it one time step forward.\n",
    "    We do not want to use the input cell's historic average because it's less related to the target cell\n",
    "\n",
    "    :param data: (N, ...) shape\n",
    "    :param step: interval used to calculate the average\n",
    "    :param max_steps: number of intervals to sample\n",
    "    :return: historic average of the next time steps\n",
    "    \"\"\"\n",
    "    r = np.zeros(data.shape)  # so that calculation can still be done on the first few cells\n",
    "    # r = np.empty(data.shape)\n",
    "    # r.fill(np.nan)\n",
    "    for i in range(step + 1, len(r)):\n",
    "        a_subset = data[i - step + 1:0:-step]  # +1 to take the historic average of the next time step\n",
    "        if max_steps > 0:\n",
    "            a_subset = a_subset[:max_steps]\n",
    "\n",
    "        x = np.mean(a_subset, axis=0)\n",
    "        r[i] = x\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trgs.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_fn(y_true, y_score):\n",
    "    y_true, y_score = y_true.flatten(), y_score.flatten()\n",
    "    return np.mean(np.abs(y_true-y_score))  # mae\n",
    "    y_true = np.copy(y_true)\n",
    "    y_true[y_true > 0 ] = 1\n",
    "    return np.mean(np.abs(y_true-y_score))  # mae\n",
    "#     return average_precision_score(y_true,y_score)\n",
    "    return roc_auc_score(y_true,y_score)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = np.copy(flat_group.crimes[:,0])\n",
    "trgs = np.copy(inpt)\n",
    "trgs = trgs[1:]\n",
    "inpt = inpt[:-1]\n",
    "\n",
    "tst_len = int(0.3*len(inpt))\n",
    "\n",
    "results = {}\n",
    "for step in [1]:\n",
    "    for max_steps in range(10):\n",
    "        out = historic_average(inpt,step=step,max_steps=max_steps)\n",
    "        \n",
    "#         mae = np.mean(np.abs(trgs[tst_len:]-out[tst_len:]))\n",
    "        mae = score_fn(trgs[tst_len:],out[tst_len:])\n",
    "        \n",
    "        results[mae] = max_steps\n",
    "        print(mae,max_steps)\n",
    "best = results[min(list(results.keys()))]        \n",
    "print(f\"best -> {best}\")        \n",
    "print(\"----------------------------------------------------\")        \n",
    "score, param = np.array(list(results.keys())), np.array(list(results.values()))\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.scatter(param, score,s=50,marker=\"D\",alpha=.3)\n",
    "best_arg = np.argmin(score)\n",
    "print(\"best param:\",param[best_arg])\n",
    "plt.scatter(param[best_arg], score[best_arg],s=50,marker=\"D\",alpha=.3)\n",
    "plt.ylim(np.min(score),np.max(score))\n",
    "plt.xticks(param)\n",
    "plt.yticks(score)\n",
    "plt.grid(True,alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4264,
     "status": "ok",
     "timestamp": 1573554721902,
     "user": {
      "displayName": "Bernard Swart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA7uSA62RDxMrL_HdFxD2SxWswIX97G3OjMRiFvmMU=s64",
      "userId": "00293673988406756138"
     },
     "user_tz": -120
    },
    "id": "wKWTgDA_IkkU",
    "outputId": "4ae7f240-e9df-4c4c-c8b6-0a8c6c6b4df3"
   },
   "outputs": [],
   "source": [
    "im(grid_group.crimes.mean(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GGexk-rvGVWw"
   },
   "source": [
    "# mock data ensures the models work as they should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZsCOaCTGVWx"
   },
   "outputs": [],
   "source": [
    "# compare results and new thresh per cell vs original metric\n",
    "metrics = get_models_metrics(conf.data_path)\n",
    "results = get_models_results(conf.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3jchEzAqGVWz"
   },
   "outputs": [],
   "source": [
    "probas_pred = results[0].probas_pred\n",
    "y_pred = results[0].y_pred\n",
    "y_true = results[0].y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pR2IMnZ5GVW1"
   },
   "outputs": [],
   "source": [
    "thresholds = best_thresholds(y_true=y_true,\n",
    "                             probas_pred=probas_pred)\n",
    "best_t = best_threshold(y_class=y_true,\n",
    "                             y_score=probas_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "olyK4lysGVW5"
   },
   "outputs": [],
   "source": [
    "t = y_true.sum(0)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9vijy2gAGVW7"
   },
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    x -= x.min()\n",
    "    x /= x.max()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i0bVVXmBGVW_"
   },
   "outputs": [],
   "source": [
    "model_metrics = ModelMetrics(model_name=conf.model_name,\n",
    "                             y_true=y_true,\n",
    "                             y_pred=y_pred_new,\n",
    "                             probas_pred=probas_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "395jMdtEGVXF",
    "outputId": "fdeb2fcd-aa48-49b5-e3e6-687bd2ea6254"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(norm(thresholds))\n",
    "# plt.plot(norm(t))\n",
    "plt.plot(norm(norm(t)*norm(thresholds)))\n",
    "plt.plot(np.ones(thresholds.shape)*best_t)\n",
    "mean = np.mean(norm(t))\n",
    "plt.plot(np.ones(thresholds.shape)*mean)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ujxHbvAGVXJ",
    "outputId": "d94564e1-77b1-4797-fc86-d696005978a7"
   },
   "outputs": [],
   "source": [
    "\n",
    "class0_args = np.zeros(10)\n",
    "class1_args = np.ones(10)\n",
    "a = np.arange(10)#np.array(list(zip(class0_args, class1_args))).flatten()\n",
    "print(a)\n",
    "np.random.shuffle(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4__GsnWYGVXN"
   },
   "outputs": [],
   "source": [
    "# ensure all model weights are parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7CVdpwi8GVXP"
   },
   "outputs": [],
   "source": [
    "# Kang FNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-biAKXWGVXT"
   },
   "outputs": [],
   "source": [
    "# ResNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXdroem4GVXW"
   },
   "outputs": [],
   "source": [
    "# ResNet-Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udZqsDhGGVXZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tH0pc5WUGVXc"
   },
   "outputs": [],
   "source": [
    "# Kang RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hQvXz_y-GVXh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Btq_uAV6GVXn",
    "outputId": "30516065-b618-4afc-c06c-ceebc768c4f3"
   },
   "outputs": [],
   "source": [
    "grid_group.shaper.l, flat_group.shaper.l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6I66qjm3GVXz",
    "outputId": "5f42c64c-7581-4c3f-fca4-ccce08bffe7f"
   },
   "outputs": [],
   "source": [
    "def f(*xx):\n",
    "    for y in xx:        \n",
    "        x = y.testing_set.t_range\n",
    "        print(\"tst: \",len(x), x[0],\" -> \",x[-1],y.testing_set.target_shape)\n",
    "    print()    \n",
    "    for y in xx:          \n",
    "        x = y.validation_set.t_range\n",
    "        print(\"val: \",len(x), x[0],\" -> \",x[-1],y.validation_set.target_shape)\n",
    "    print()\n",
    "    for y in xx:          \n",
    "        x = y.training_set.t_range\n",
    "        print(\"trn: \",len(x), x[0],\" -> \",x[-1],'\\t',y.training_set.target_shape)\n",
    "    print()\n",
    "\n",
    "f(grid_group, flat_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SRZV1AfUGVX2",
    "outputId": "a0aee31b-29a0-40ba-9355-e5fa43e44263"
   },
   "outputs": [],
   "source": [
    "grid_group.training_set.target_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0A2HV29JGVX4",
    "outputId": "0765ee19-646c-4330-97ac-82c127e6a304"
   },
   "outputs": [],
   "source": [
    "(365-30)*0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2cO0KPzGVX8"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R4B6x3qZGVX-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_vxl9LxzGVYA",
    "outputId": "7a1cd345-a594-46b7-d601-0cfd29a42065"
   },
   "outputs": [],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzfKTnCTGVYE"
   },
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hbkU-8o0GVYE"
   },
   "outputs": [],
   "source": [
    "# plot the per time metrics for data folders\n",
    "start_date = \"2013-01-01\"\n",
    "end_date = \"2015-01-01\" \n",
    "\n",
    "data_dim_str = \"T24H-X850M-Y880M\"  #\"T1H-X1700M-Y1760M\"  # needs to exist\n",
    "data_path = f\"./data/processed/{data_dim_str}_{start_date}_{end_date}/\"\n",
    "# metrics = get_models_metrics(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGdyG4dEGVYH",
    "outputId": "660fec77-211e-485b-ede7-9a4aa5ea7313"
   },
   "outputs": [],
   "source": [
    "list(map(lambda x: plt.plot(), metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPpSZDDAGVYK",
    "outputId": "21bff983-551e-44c7-b549-046595c4d322"
   },
   "outputs": [],
   "source": [
    "data_group  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0DYBSGzxGVYM",
    "outputId": "3331a0cc-d3b6-4213-dd5f-10e1afb9c9e4"
   },
   "outputs": [],
   "source": [
    "conf = BaseConf()\n",
    "\n",
    "data_group = FlatDataGroup(data_path=data_path, conf=conf)\n",
    "loaders = FlatDataLoaders(data_group=data_group, conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fLboa2lzGVYQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EiVYJdN3GVYT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jg4pbZKyGVYV",
    "outputId": "adacbafa-6722-4822-f674-00d5beea1ee4"
   },
   "outputs": [],
   "source": [
    "start_date = \"2013-01-01\"\n",
    "end_date = \"2015-01-01\" \n",
    "\n",
    "data_dim_str = \"T24H-X850M-Y880M\"  #\"T1H-X1700M-Y1760M\"  # needs to exist\n",
    "model_name = \"NOTE-BOOK-MODEL\"  # needs to be created\n",
    "data_path = f\"./data/processed/{data_dim_str}_{start_date}_{end_date}/\"\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    raise Exception(f\"Directory ({data_path}) needs to exist.\")\n",
    "\n",
    "model_path = data_path + f\"models/{model_name}/\"\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# logging config is set globally thus we only need to call this in this file\n",
    "# imported function logs will follow the configuration\n",
    "setup_logging(save_dir=model_path, log_config='./logger/standard_logger_config.json', default_level=log.INFO)\n",
    "log.info(\"=====================================BEGIN=====================================\")\n",
    "\n",
    "timer = Timer()\n",
    "# manually set the config\n",
    "# manually set the config\n",
    "conf_dict = {\n",
    "    \"seed\": 3,\n",
    "    \"use_cuda\": True,\n",
    "    \n",
    "    \"use_crime_types\": False,\n",
    "    \n",
    "    # data group/data set related\n",
    "    \"val_ratio\": 0.1,  # ratio of the total dataset\n",
    "    \"tst_ratio\": 0.3,# ratio of the total dataset\n",
    "    \"seq_len\": 1,\n",
    "    \"flatten_grid\": True,  # if the shaper should be used to squeeze the data\n",
    "    \n",
    "    # shaper related \n",
    "    \"shaper_top_k\": -1,  # if less then 0, top_k will not be applied\n",
    "    \"shaper_threshold\": 0,\n",
    "\n",
    "    \n",
    "    # data loader related\n",
    "    \"sub_sample_train_set\": 1,\n",
    "    \"sub_sample_validation_set\": 1,\n",
    "    \"sub_sample_validation_set\": 0,\n",
    "    \n",
    "    # training parameters\n",
    "    \"resume\": False,\n",
    "    \"early_stopping\": False,\n",
    "    \"tolerance\": 1e-8,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-8,\n",
    "    \"max_epochs\": 1,\n",
    "    \"batch_size\": 64,\n",
    "    \"dropout\": 0.2,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 6,\n",
    "    \n",
    "    # attached global variables - bad practice -find alternative\n",
    "    \"device\": None,  # pytorch device object [CPU|GPU]\n",
    "    \"timer\": Timer(),\n",
    "    \"model_name\": model_name,\n",
    "    \"model_path\": model_path,\n",
    "    \"checkpoint\": \"best\",\n",
    "    \n",
    "    \"use_seq_loss\": True,\n",
    "}\n",
    "conf = BaseConf(conf_dict=conf_dict)\n",
    "\n",
    "info = deepcopy(conf.__dict__)\n",
    "info[\"start_time\"] = strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "# DATA LOADER SETUP\n",
    "np.random.seed(conf.seed)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed( conf.seed)\n",
    "else:\n",
    "    torch.manual_seed(conf.seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "log.info(f\"Device: {device}\")\n",
    "info[\"device\"] = device.type\n",
    "conf.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XWsvdKu8GVYX",
    "outputId": "3c7926b2-c155-4078-efe2-8174819862a4"
   },
   "outputs": [],
   "source": [
    "conf.sub_sample_test_set = 0\n",
    "conf.sub_sample_train_set = 1\n",
    "conf.sub_sample_validation_set = 1\n",
    "\n",
    "data_group = FlatDataGroup(data_path=data_path, conf=conf)\n",
    "loaders = FlatDataLoaders(data_group=data_group, conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WyW98wZAGVYZ",
    "outputId": "fdc05241-f50f-479e-af02-d032f1e30a31"
   },
   "outputs": [],
   "source": [
    "pshape(data_group.crimes,\n",
    "       data_group.training_set.crimes,\n",
    "       data_group.testing_set.crimes,\n",
    "       data_group.validation_set.crimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AX-pRqFuGVYc",
    "outputId": "63ab926b-18f2-4cbe-dba2-7eaefce93727"
   },
   "outputs": [],
   "source": [
    "N,L = 10, 10\n",
    "\n",
    "np.arange(N*L).reshape(N,1,L)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
