{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging as log\n",
    "from time import strftime\n",
    "from copy import deepcopy\n",
    "from torch import nn, optim\n",
    "from utils.data_processing import *\n",
    "from logger.logger import setup_logging\n",
    "from utils.configs import BaseConf\n",
    "from dataloaders.flat_loader import FlatDataLoaders\n",
    "from datasets.flat_dataset import FlatDataGroup\n",
    "from models.model_result import ModelResult, ModelMetrics, save_metrics, compare_all_models, get_models_metrics\n",
    "from utils.utils import pshape, get_data_sub_paths, by_ref\n",
    "from trainers.generic_trainer import train_model\n",
    "from models.rnn_models import train_epoch_for_rfnn, evaluate_rfnn, \\\n",
    "    SimpleRecurrentFeedForwardNetwork, RecurrentFeedForwardNetwork\n",
    "from utils.metrics import best_threshold, get_y_pred, get_y_pred_by_thresholds, best_thresholds\n",
    "from time import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub_paths = get_data_sub_paths()\n",
    "pprint(sorted(data_sub_paths))\n",
    "\n",
    "data_sub_path = by_ref(\"7cd\")[0]\n",
    "print(f\"using: {data_sub_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually set\n",
    "conf = BaseConf()\n",
    "conf.seed = int(time())  # 3\n",
    "\n",
    "conf.model_name = \"RFNN\"  # needs to be created\n",
    "conf.data_path = f\"./data/processed/{data_sub_path}/\"\n",
    "\n",
    "# compare_all_models(data_path=conf.data_path)\n",
    "\n",
    "if not os.path.exists(conf.data_path):\n",
    "    raise Exception(f\"Directory ({conf.data_path}) needs to exist.\")\n",
    "\n",
    "conf.model_path = f\"{conf.data_path}models/{conf.model_name}/\"\n",
    "os.makedirs(conf.data_path, exist_ok=True)\n",
    "os.makedirs(conf.model_path, exist_ok=True)\n",
    "\n",
    "# logging config is set globally thus we only need to call this in this file\n",
    "# imported function logs will follow the configuration\n",
    "setup_logging(save_dir=conf.model_path,\n",
    "              log_config='./logger/standard_logger_config.json',\n",
    "              default_level=log.INFO)\n",
    "log.info(\"=====================================BEGIN=====================================\")\n",
    "\n",
    "info = deepcopy(conf.__dict__)\n",
    "info[\"start_time\"] = strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "# DATA LOADER SETUP\n",
    "np.random.seed(conf.seed)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(conf.seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(conf.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "log.info(f\"Device: {device}\")\n",
    "info[\"device\"] = device.type\n",
    "conf.device = device\n",
    "\n",
    "log.getLogger().setLevel(\"INFO\")\n",
    "\n",
    "# SET THE HYPER PARAMETERS\n",
    "conf.resume = False\n",
    "conf.early_stopping = False\n",
    "conf.max_epochs = 2\n",
    "conf.dropout = 0  # 0.5 # if using dropout choose between 0.5 and 0.8 values\n",
    "conf.weight_decay = 0  # 1e-6\n",
    "conf.checkpoint = \"best\"  # [\"best\"|\"latest\"]\n",
    "conf.lr = 1e-3\n",
    "conf.batch_size = 64\n",
    "conf.seq_len = 30  # connect as hyper parameter to\n",
    "\n",
    "# CRIME DATA\n",
    "conf.sub_sample_test_set = 0\n",
    "conf.sub_sample_train_set = 1\n",
    "conf.sub_sample_validation_set = 1\n",
    "\n",
    "data_group = FlatDataGroup(data_path=conf.data_path, conf=conf)\n",
    "loaders = FlatDataLoaders(data_group=data_group, conf=conf)\n",
    "\n",
    "conf.freqstr = data_group.t_range.freqstr\n",
    "\n",
    "# SET LOSS FUNCTION\n",
    "# size averaged - so more epochs or larger lr for smaller batches\n",
    "if conf.use_classification:\n",
    "    output_size = 2\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    log.info(\"model setup for binary classification\")\n",
    "    log.info(\"loss function: cross entropy loss\")\n",
    "else:\n",
    "    output_size = 1\n",
    "    loss_function = nn.MSELoss()\n",
    "    log.info(\"model setup for regression\")\n",
    "    log.info(\"loss function: mean square error loss\")\n",
    "\n",
    "# SETUP MODEL\n",
    "train_set = loaders.train_loader.dataset\n",
    "indices, spc_feats, tmp_feats, env_feats, targets, labels = train_set[train_set.min_index]\n",
    "spc_size, tmp_size, env_size = spc_feats.shape[-1], tmp_feats.shape[-1], env_feats.shape[-1]\n",
    "\n",
    "model_arch = {\n",
    "    \"h_size0\": 100,\n",
    "    \"h_size1\": 100,\n",
    "    \"h_size2\": 100,\n",
    "}\n",
    "model = SimpleRecurrentFeedForwardNetwork(spc_size=spc_size,\n",
    "                                          tmp_size=tmp_size,\n",
    "                                          env_size=env_size,\n",
    "                                          output_size=output_size,\n",
    "                                          dropout_p=conf.dropout,\n",
    "                                          model_arch=model_arch)\n",
    "\n",
    "# model_arch = {\n",
    "#     \"scp_net_h0\": 64,\n",
    "#     \"scp_net_h1\": 32,\n",
    "#     \"tmp_net_h0\": 64,\n",
    "#     \"tmp_net_h1\": 32,\n",
    "#     \"env_net_h0\": 64,\n",
    "#     \"env_net_h1\": 32,\n",
    "#     \"final_net_h1\": 64,\n",
    "# }\n",
    "# model = RecurrentFeedForwardNetwork(spc_size=spc_size,\n",
    "#                                  tmp_size=tmp_size,\n",
    "#                                  env_size=env_size,\n",
    "#                                  dropout_p=conf.dropout,\n",
    "#                                  model_arch=model_arch)\n",
    "\n",
    "model.to(conf.device)\n",
    "\n",
    "# SETUP OPTIMISER\n",
    "parameters = model.parameters()\n",
    "\n",
    "# important note: using weight decay (l2 penalty) can prohibit long term memory in LSTM networks\n",
    "# - use gradient clipping instead\n",
    "optimiser = optim.Adam(params=parameters, lr=conf.lr, weight_decay=conf.weight_decay)\n",
    "\n",
    "##### RESUME LOGIC\n",
    "if conf.resume:  # todo check if the files actually exist\n",
    "    try:\n",
    "        # resume from previous check point or resume from best validaton score checkpoint\n",
    "        # load model state\n",
    "        model_state_dict = torch.load(f\"{conf.model_path}model_{conf.checkpoint}.pth\",\n",
    "                                      map_location=conf.device.type)\n",
    "        model.load_state_dict(model_state_dict)\n",
    "\n",
    "        # load optimiser state\n",
    "        optimiser_state_dict = torch.load(f\"{conf.model_path}optimiser_{conf.checkpoint}.pth\",\n",
    "                                          map_location=conf.device.type)\n",
    "        optimiser.load_state_dict(optimiser_state_dict)\n",
    "\n",
    "        # new optimiser hyper-parameters\n",
    "        optimiser.param_groups[0]['lr'] = conf.lr\n",
    "        optimiser.param_groups[0]['weight_decay'] = conf.weight_decay\n",
    "\n",
    "        # new model hyper-parameters\n",
    "        model.dropout.p = conf.dropout  # note that drop out is not part of the saved state dict\n",
    "\n",
    "    except Exception as e:\n",
    "        log.error(f\"Nothing to resume from, training from scratch \\n\\t-> {e}\")\n",
    "\n",
    "trn_epoch_losses, val_epoch_losses, stopped_early = train_model(model=model,\n",
    "                                                                optimiser=optimiser,\n",
    "                                                                loaders=loaders,\n",
    "                                                                train_epoch_fn=train_epoch_for_rfnn,\n",
    "                                                                loss_fn=loss_function,\n",
    "                                                                conf=conf)\n",
    "\n",
    "print(f\"stopped_early: {stopped_early}\")  # use the current epoch instead\n",
    "# if stopped_early -> continue with best_model - new hyper-parameters -> no n\n",
    "\n",
    "# Load latest or best validation model\n",
    "# conf.checkpoint = \"latest_val\"\n",
    "# conf.checkpoint = \"latest_trn\"\n",
    "# conf.checkpoint = \"best_trn\"\n",
    "conf.checkpoint = \"best_val\"\n",
    "\n",
    "log.info(f\"Loading model from checkpoint ({conf.checkpoint}) for evaluation\")\n",
    "\n",
    "# resume from previous check point or resume from best validation score checkpoint\n",
    "# load model state\n",
    "model_state_dict = torch.load(f\"{conf.model_path}model_{conf.checkpoint}.pth\",\n",
    "                              map_location=conf.device.type)\n",
    "\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "conf.sub_sample_test_set = 0\n",
    "conf.sub_sample_train_set = 0\n",
    "conf.sub_sample_validation_set = 0\n",
    "\n",
    "loaders = FlatDataLoaders(data_group=data_group, conf=conf)\n",
    "\n",
    "# todo set the train_loader to eval so that it does not subsample\n",
    "trn_y_count, trn_y_class, trn_y_score, trn_t_range = evaluate_rfnn(model=model,\n",
    "                                                                   batch_loader=loaders.train_loader,\n",
    "                                                                   conf=conf)\n",
    "\n",
    "thresh = best_threshold(y_class=trn_y_class,\n",
    "                        y_score=trn_y_score)\n",
    "\n",
    "tst_y_count, tst_y_class, tst_y_score, tst_t_range = evaluate_rfnn(model=model,\n",
    "                                                                   batch_loader=loaders.test_loader,\n",
    "                                                                   conf=conf)\n",
    "\n",
    "tst_y_pred = get_y_pred(thresh=thresh,\n",
    "                        y_score=tst_y_score)\n",
    "\n",
    "tst_y_count = loaders.data_group.to_counts(dense_data=tst_y_count)\n",
    "\n",
    "save_metrics(y_count=tst_y_count,\n",
    "             y_pred=tst_y_pred,\n",
    "             y_score=tst_y_score,\n",
    "             t_range=tst_t_range,\n",
    "             shaper=data_group.shaper,\n",
    "             conf=conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "run_rfnn_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
