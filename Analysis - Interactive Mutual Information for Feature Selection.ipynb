{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information Feature Selection\n",
    "\n",
    "The aim of this notebook:\n",
    "- Look at column features and how they influence a cell's self-exciting property (mutual info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why conditional mutual information is larger than mutual information\n",
    "The conditional variable has more possible states and therfore the join has a higher entropy - the maximum value it can take on can therefore be higher - to make plots easier to read we can normalize the mutual information with the mutual information of the target signal with itself.\n",
    "\n",
    "$I(X;Y) = H(X) + H(Y) - H(X,Y)$\n",
    "\n",
    "\n",
    "$I(X;Y|Z) = H(X,Z) + H(Y,Z) - H(X,Y,Z) - H(Z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Plotly Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sparse_discrete_table import SparseDiscreteTable, build_discrete_table\n",
    "from ipywidgets import widgets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from utils.data_processing import time_series_to_time_index\n",
    "from pprint import pprint\n",
    "from sparse_discrete_table import quick_mutual_info, quick_cond_mutual_info\n",
    "from sparse_discrete_table import mutual_info_over_time, conditional_mutual_info_over_time\n",
    "from utils.interactive import filter_frame, get_total_counts, new_bins, new_int_bins\n",
    "from utils.interactive import get_mean_map, bin_data_frame, State\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['mathtext.fontset'] = 'stix'\n",
    "rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Just for reference where Crimes_Chicago_2001_to_2019_datetime_fmt came from:`\n",
    "```python\n",
    "# was used to convert original csv to dataframe and string dates to datetime format\n",
    "df = pd.read_csv(\"data/original/Crimes_Chicago_2001_to_2019.csv\")\n",
    "df['Date'] = pd.DatetimeIndex(pd.to_datetime(df['Date']))\n",
    "df = df[[\n",
    "    'ID',\n",
    "    'Date',\n",
    "    'Primary Type',\n",
    "    'Arrest',\n",
    "    'Latitude',\n",
    "    'Longitude',\n",
    "]].dropna()\n",
    "df.to_pickle(\"data/raw/Crimes_Chicago_2001_to_2019_datetime_fmt.pkl\") # Dates are type datetime not string\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_processing import encode_category\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "df = pd.read_pickle(\"data/raw/Crimes_Chicago_2001_to_2019_datetime_fmt.pkl\")\n",
    "\n",
    "crime_categories = [\n",
    "        \"THEFT\",\n",
    "        \"BATTERY\",\n",
    "        \"CRIMINAL DAMAGE\",\n",
    "        \"NARCOTICS\",\n",
    "        \"ASSAULT\",\n",
    "        \"BURGLARY\",\n",
    "        \"MOTOR VEHICLE THEFT\",\n",
    "        \"ROBBERY\",\n",
    "]\n",
    "\n",
    "category_mask = df['Primary Type'].isin(crime_categories)\n",
    "\n",
    "# used to remove the anomalies\n",
    "LAT_MIN, LAT_MAX = 41.641, 42.024 # 41.645, 42.022\n",
    "\n",
    "LON_MIN, LON_MAX = -87.821, -87.525 # -87.934, -87.525\n",
    "\n",
    "FREQ = '1H' # '1H' # '168H' # '24H' # \n",
    "\n",
    "freq_title = {\n",
    "    \"1H\": \"Hourly\",\n",
    "    \"24H\":\"Daily\",\n",
    "    \"168H\":\"Weekly\",\n",
    "}.get(FREQ, \"Hourly\")\n",
    "\n",
    "DATE_MIN, DATE_MAX = {\n",
    "    \"1H\":   ('2014-01-01', '2019-01-01'),\n",
    "    \"24H\":  ('2001-01-01', '2019-01-01'),\n",
    "    \"168H\": ('2001-01-01', '2019-01-01'),\n",
    "}.get(FREQ, ('2014-01-01', '2019-01-01'),)\n",
    "\n",
    "\n",
    "lon_mask = (df.Longitude > LON_MIN) & (df.Longitude < LON_MAX)\n",
    "lat_mask = (df.Latitude > LAT_MIN) & (df.Latitude < LAT_MAX)\n",
    "date_mask = (df.Date >= DATE_MIN) & (df.Date < DATE_MAX)\n",
    "\n",
    "\n",
    "df = df[lon_mask & lat_mask & date_mask & category_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "pd.to_pickle(\n",
    "    df,\n",
    "    f\"data/raw/crimes_{DATE_MIN}_{DATE_MAX}_min{LAT_MIN}{LON_MIN}_max{LAT_MAX}{LON_MAX}.pkl\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode the crime catgegories - makes histograms faster\n",
    "# CrimeType = CategoricalDtype(categories=crime_categories, ordered=True)\n",
    "# df['Primary Type'] = df['Primary Type'].astype(CrimeType)\n",
    "\n",
    "# df['c'] = df['Primary Type'].cat.codes\n",
    "\n",
    "df['t'] = time_series_to_time_index(t_series=df.Date, t_step=FREQ, floor=True)\n",
    "df['c'] = encode_category(series=df['Primary Type'],categories=crime_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date selectors\n",
    "date_range = pd.date_range(df.Date.min().ceil(FREQ), df.Date.max().ceil(FREQ), freq=FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.interactive import get_ratio_xy\n",
    "    \n",
    "ratio_xy = get_ratio_xy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very important  - all the meta data is mapped from intervals of 0.001 in the lat and lon space with ratios of 8 and 11 to ensure that the grids cels are square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm the make_grid technique and hist product the same output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dlat': 0.012,\n",
      " 'dlon': 0.015,\n",
      " 'x in metres': 1275.0,\n",
      " 'x_scale': 15,\n",
      " 'y in metres': 1320.0,\n",
      " 'y_scale': 12}\n"
     ]
    }
   ],
   "source": [
    "# [20,16] - [10,8] - [5,4] - [3,2] - [1,1]\n",
    "x_scale, y_scale = 15,12 # 10,8 #3,2\n",
    "xy_scale = np.lusters are 4 with std of 0.9956201216array([x_scale, y_scale])  # must be integer so that we can easily sample demographic data\n",
    "dlon, dlat = xy_scale * np.array([0.001, 0.001])\n",
    "meta_info = {}\n",
    "meta_info[\"x_scale\"] = x_scale\n",
    "meta_info[\"y_scale\"] = y_scale\n",
    "meta_info[\"dlon\"] = float(dlon)\n",
    "meta_info[\"dlat\"] = float(dlat)\n",
    "meta_info[\"x in metres\"] = 85000 * float(dlon)\n",
    "meta_info[\"y in metres\"] = 110000 * float(dlat)\n",
    "\n",
    "pprint(meta_info)\n",
    "\n",
    "# use perfect squares perfect squares\n",
    "\n",
    "# all the meta data is mapped from intervals of 0.001 in \n",
    "# the lat and lon space with ratios of 8 and 11 to ensure that the grids cels are square\n",
    "\n",
    "# cell_size_m = 430\n",
    "# dlat = cell_size_m*lat_per_metre\n",
    "# dlon = cell_size_m*lon_per_metre\n",
    " \n",
    "# use increments of 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pformat        \n",
    "        \n",
    "def default_state():\n",
    "    return  State(\n",
    "        dlon=dlon,\n",
    "        dlat=dlat,\n",
    "        lon_max = LON_MAX,\n",
    "        lon_min = LON_MIN,\n",
    "        lat_max = LAT_MAX,\n",
    "        lat_min = LAT_MIN,     \n",
    "        total_lon_max = LON_MAX,\n",
    "        total_lon_min = LON_MIN,\n",
    "        total_lat_max = LAT_MAX,\n",
    "        total_lat_min = LAT_MIN,         \n",
    "        date_min = DATE_MIN,\n",
    "        date_max = DATE_MAX,                \n",
    "        time_index = 0,\n",
    "        date_indices = (0,len(date_range)-1),\n",
    "        date_range = pd.date_range(df.Date.min().ceil(FREQ), df.Date.max().floor(FREQ), freq=FREQ),\n",
    "        freq=FREQ,\n",
    "        crime_types = [*crime_categories],    \n",
    "        mi_max_offset = 35,\n",
    "        block_size_index=2,    \n",
    "        conditional_temporal_variables= [\"Day of Week\"],# [\"Hour\", \"Day of Week\", \"Time of Month\", \"Time of Year\"],\n",
    "        mutual_info_bins=10,\n",
    "        log_norm=False,\n",
    "    )\n",
    "    \n",
    "state = default_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'block_size_index': 2,\n",
       " 'callbacks': [],\n",
       " 'conditional_temporal_variables': ['Day of Week'],\n",
       " 'crime_types': ['THEFT',\n",
       "                 'BATTERY',\n",
       "                 'CRIMINAL DAMAGE',\n",
       "                 'NARCOTICS',\n",
       "                 'ASSAULT',\n",
       "                 'BURGLARY',\n",
       "                 'MOTOR VEHICLE THEFT',\n",
       "                 'ROBBERY'],\n",
       " 'date_indices': (0, 43824),\n",
       " 'date_max': '2019-01-01',\n",
       " 'date_min': '2014-01-01',\n",
       " 'date_range': DatetimeIndex(['2014-01-01 00:00:00', '2014-01-01 01:00:00',\n",
       "               '2014-01-01 02:00:00', '2014-01-01 03:00:00',\n",
       "               '2014-01-01 04:00:00', '2014-01-01 05:00:00',\n",
       "               '2014-01-01 06:00:00', '2014-01-01 07:00:00',\n",
       "               '2014-01-01 08:00:00', '2014-01-01 09:00:00',\n",
       "               ...\n",
       "               '2018-12-31 14:00:00', '2018-12-31 15:00:00',\n",
       "               '2018-12-31 16:00:00', '2018-12-31 17:00:00',\n",
       "               '2018-12-31 18:00:00', '2018-12-31 19:00:00',\n",
       "               '2018-12-31 20:00:00', '2018-12-31 21:00:00',\n",
       "               '2018-12-31 22:00:00', '2018-12-31 23:00:00'],\n",
       "              dtype='datetime64[ns]', length=43824, freq='H'),\n",
       " 'dlat': 0.012,\n",
       " 'dlon': 0.015,\n",
       " 'freq': '1H',\n",
       " 'lat_max': 42.024,\n",
       " 'lat_min': 41.641,\n",
       " 'log_norm': False,\n",
       " 'lon_max': -87.525,\n",
       " 'lon_min': -87.821,\n",
       " 'mi_max_offset': 35,\n",
       " 'mutual_info_bins': 10,\n",
       " 'time_index': 0,\n",
       " 'total_lat_max': 42.024,\n",
       " 'total_lat_min': 41.641,\n",
       " 'total_lon_max': -87.525,\n",
       " 'total_lon_min': -87.821}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Reference for code to compare grids with previous generation techniques:`\n",
    "```python\n",
    "file_location = \"data/processed/T24H-X425M-Y440M_2013-01-01_2017-01-01/\"\n",
    "\n",
    "generated_data = np.load(file_location + \"generated_data.npz\")\n",
    "x_range = generated_data['x_range']\n",
    "y_range = generated_data['y_range']\n",
    "t_range = pd.read_pickle(file_location + \"t_range.pkl\")\n",
    "\n",
    "crime_types_grids = generated_data['crime_types_grids'] \n",
    "\n",
    "xbins  = x_range - dlon/2\n",
    "xbins = np.array([*xbins,xbins[-1]+dlon])\n",
    "\n",
    "ybins  = y_range - dlat/2\n",
    "ybins = np.array([*ybins,ybins[-1]+dlat])\n",
    "\n",
    "import json\n",
    "\n",
    "with open(file_location + \"info.json\", \"r\") as f:\n",
    "    meta_info = json.load(f)\n",
    "         \n",
    "meta_info\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Widget Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset state\n",
    "state.crime_types = [*crime_categories]\n",
    "\n",
    "state.date_indices = (0,len(date_range)-1)\n",
    "state.date_min, state.date_max = date_range[[*state.date_indices]]\n",
    "\n",
    "state.date_range = pd.date_range(\n",
    "    state.date_min.ceil(state.freq), \n",
    "    state.date_max.floor(state.freq), \n",
    "    freq=state.freq, \n",
    ")\n",
    "\n",
    "tbins, cbins, ybins, xbins = new_bins(df, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick plotly plot builders\n",
    "def new_scatter(title, ylabel, xlabel):\n",
    "    return go.FigureWidget(\n",
    "        data=go.Scatter(),\n",
    "        layout=dict(\n",
    "            font=dict(family=\"STIXGeneral\"),\n",
    "            title_text=title,\n",
    "            title_x=0.5,        \n",
    "            xaxis_title=xlabel,\n",
    "            yaxis_title=ylabel,\n",
    "            legend_title=\"Legend Title\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def new_heatmap(z):\n",
    "    return go.Figure(\n",
    "        data=go.Heatmap(z=z),\n",
    "        layout=dict(\n",
    "            font=dict(family=\"STIXGeneral\"),\n",
    "            height=600,\n",
    "#             width=ratio_xy*fig_height,\n",
    "            yaxis=dict(scaleanchor=\"x\", scaleratio=1/ratio_xy),\n",
    "        ),    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_total_counts = new_scatter(title=f\"{freq_title} Total Crimes\",\n",
    "                               ylabel=\"Count\",xlabel=\"Date Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MI Plots on a single curve\n",
    "fig_mi_cmi = go.FigureWidget(\n",
    "        data=[\n",
    "            go.Scatter(\n",
    "                name=\"$I(C_t;C_{t-k})$\",#\"Mutual Information\",\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                name=\"$I(C_t;C_{t-k}|D_t)$\", #\"Condtional Mutual Information\",\n",
    "            ),\n",
    "        ],\n",
    "        layout=dict(\n",
    "            title_text=\"Mutual and Condtional Mutual Information\",\n",
    "            title_x=0.5,        \n",
    "            xaxis_title=\"Offest in days (k)\",\n",
    "            yaxis_title=\"Normalised Score [0,1]\",\n",
    "            legend_title=\"Curves\",\n",
    "            font=dict(family=\"STIXGeneral\"),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "line_mi, line_cmi = fig_mi_cmi.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_mean = get_mean_map(df, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scattergl = go.Scattergl(\n",
    "    hoverinfo='skip',\n",
    "    mode='markers',\n",
    "    name='scattergl',\n",
    "    marker_color='red',\n",
    ")\n",
    "\n",
    "heatmapgl = go.Heatmap(\n",
    "    z=counts_mean,\n",
    "    x=xbins,\n",
    "    y=ybins, \n",
    "    hoverinfo='skip',\n",
    "    colorscale='viridis',\n",
    "    opacity=1,\n",
    "    name='heatmapgl',\n",
    ")\n",
    "\n",
    "fig_height = 600\n",
    "fig_app = go.FigureWidget(\n",
    "    data=[heatmapgl, scattergl],\n",
    "    layout=dict(\n",
    "        margin={\"r\":50,\"t\":30,\"l\":0,\"b\":0},\n",
    "        height=fig_height,\n",
    "#         width=fig_height*ratio_xy,\n",
    "        yaxis=dict(scaleanchor=\"x\", scaleratio=1/ratio_xy),\n",
    "        clickmode='event+select',\n",
    "        title_x=0.5,\n",
    "        title=f'{freq_title} Scatter Plot of Crimes with Mean Crime Count Heatmap',\n",
    "        font=dict(family=\"STIXGeneral\"),\n",
    "        yaxis_title='Latitude',\n",
    "        xaxis_title='Longitude',\n",
    "    ),\n",
    ")\n",
    "\n",
    "scattergl = fig_app.data[1]\n",
    "heatmapgl = fig_app.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update figures based on state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size_changed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_temporal_information(\n",
    "    date_range,\n",
    "    temporal_variables=[\"Hour\", \"Day of Week\", \"Time of Month\", \"Time of Year\"],\n",
    "    month_divisions=4,\n",
    "    year_divisions=4,\n",
    "):\n",
    "    df_dict = dict(Date=date_range)\n",
    "    \n",
    "    if \"Hour\" in temporal_variables:\n",
    "        df_dict[\"Hour\"] = date_range.hour\n",
    "                \n",
    "    if \"Day of Week\" in temporal_variables:\n",
    "        df_dict[\"Day of Week\"] = date_range.dayofweek\n",
    "\n",
    "    if \"Time of Month\" in temporal_variables:\n",
    "        df_dict[\"Time of Month\"] = cut(date_range.day/date_range.days_in_month, month_divisions)\n",
    "\n",
    "    if \"Time of Year\" in temporal_variables:\n",
    "        df_dict[\"Time of Year\"] = cut(date_range.dayofyear/(366), year_divisions)\n",
    "    \n",
    "    temp_info = pd.DataFrame(df_dict).set_index('Date')\n",
    "    \n",
    "    return temp_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DoW_t'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_var_map = {\n",
    "    'Hour': 'H_t',\n",
    "    'Day of Week': 'DoW_t',\n",
    "    'Time of Month': 'ToM_t',\n",
    "    'Time of Year': 'ToY_t',\n",
    "}\n",
    "\n",
    "def cmi_name(temporal_variables):\n",
    "    return \",\".join([cond_var_map[k] for k in temporal_variables])\n",
    "\n",
    "cmi_name(state.conditional_temporal_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if FREQ == '24H':\n",
    "#     cycles = 7,\n",
    "# elif FREQ == '1H':\n",
    "#     cycles = 7,7*24\n",
    "# elif FREQ == '168H' or '1W':\n",
    "#     cycles = 52\n",
    "# else:\n",
    "#     raise Exception(f\"FREQ={FREQ} is not a valid value: 24H\")\n",
    "\n",
    "# global updater\n",
    "def draw(state):  \n",
    "    global block_size_changed\n",
    "    if len(state.crime_types) == 0:\n",
    "        return\n",
    "    \n",
    "    sub = filter_frame(df, state)\n",
    "    sub_dt = date_range[sub.t.min():sub.t.max()+1]\n",
    "    \n",
    "    total_counts_y, total_counts_x = get_total_counts(sub, state, date_range)\n",
    "  \n",
    "    conds = construct_temporal_information(\n",
    "        date_range=sub_dt,\n",
    "        temporal_variables=state.conditional_temporal_variables,\n",
    "        month_divisions=10,\n",
    "        year_divisions=12,\n",
    "    ).values\n",
    "    \n",
    "    mi_y, mi_x = mutual_info_over_time(\n",
    "        a=total_counts_y, \n",
    "        max_offset=state.mi_max_offset,\n",
    "        norm=True, \n",
    "        log_norm=state.log_norm,\n",
    "        include_self=False,\n",
    "        bins=state.mutual_info_bins,\n",
    "    )\n",
    "    cmi_y, cmi_x = conditional_mutual_info_over_time(\n",
    "        a=total_counts_y,\n",
    "        max_offset=state.mi_max_offset,\n",
    "        norm=True, \n",
    "        log_norm=state.log_norm,\n",
    "        include_self=False,\n",
    "        #cycles=cycles,\n",
    "        conds=conds,\n",
    "        bins=state.mutual_info_bins,\n",
    "    )\n",
    "    \n",
    "    slide = sub[sub.t == state.time_index]\n",
    "    \n",
    "    \n",
    "    \n",
    "    state.conditional_temporal_variables\n",
    "    \n",
    "    \n",
    "    cond_names = cmi_name(state.conditional_temporal_variables)\n",
    "    \n",
    "    with fig_app.batch_update():\n",
    "        if block_size_changed:\n",
    "            mean_map, xbins, ybins = get_mean_map(df, state)\n",
    "            block_size_changed = False\n",
    "            \n",
    "            heatmapgl.x = xbins\n",
    "            heatmapgl.y = ybins\n",
    "            heatmapgl.z = mean_map\n",
    "        \n",
    "        \n",
    "        scattergl.x=slide.Longitude\n",
    "        scattergl.y=slide.Latitude\n",
    "        \n",
    "        fig_total_counts.data[0].x = total_counts_x\n",
    "        fig_total_counts.data[0].y = total_counts_y\n",
    "        \n",
    "        line_mi.x = mi_x\n",
    "        line_mi.y = mi_y\n",
    "        \n",
    "        line_cmi.x = cmi_x\n",
    "        line_cmi.y = cmi_y\n",
    "        \n",
    "        line_cmi.name=f\"$I(C_t;C_{{t-k}}|{cond_names})$\"\n",
    "        \n",
    "        \n",
    "        fig_mi_cmi.update_layout(\n",
    "            title_text=f\"Mutual and Condtional Mutual Information\\nconditioned on {state.conditional_temporal_variables}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scattergl_on_select(trace,points,selector):\n",
    "    global lat_filter, lon_filter\n",
    "    if trace.name == 'scattergl':                \n",
    "        state.lon_min, state.lon_max = selector.xrange\n",
    "        state.lat_min, state.lat_max = selector.yrange\n",
    "        \n",
    "        draw(state)\n",
    "            \n",
    "scattergl.on_selection(scattergl_on_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# widget setup\n",
    "from ipywidgets import Layout, widgets\n",
    "\n",
    "# helper functions\n",
    "def get_widget_index(change):\n",
    "    if isinstance(change, dict) and change.get('name') == 'index':\n",
    "        return change.get('new')\n",
    "    return None\n",
    "\n",
    "def get_widget_value(change):\n",
    "    if isinstance(change, dict) and change.get('name') == 'value':\n",
    "        return change.get('new')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Widgets and how they should update state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time index date display label\n",
    "current_date_label = widgets.Label(f'Date: {date_range[state.time_index].strftime(\"%c\")}')\n",
    "\n",
    "# time index selector\n",
    "time_index_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(date_range)-1,\n",
    "    step=1,\n",
    "    description='Time Index:',\n",
    "    continuous_update=False,\n",
    "    layout=Layout(width='80%'),\n",
    ")\n",
    "\n",
    "def on_change_time_index(change):\n",
    "    global current_date_label, state\n",
    "    time_index = get_widget_value(change)\n",
    "    if time_index is not None:\n",
    "        current_date_label.value = f'Date: {date_range[time_index].strftime(\"%c\")}'\n",
    "        state.time_index = time_index\n",
    "        draw(state)\n",
    "        \n",
    "time_index_slider.observe(on_change_time_index)\n",
    "\n",
    "play_button = widgets.Play(\n",
    "    value=0,\n",
    "    min=time_index_slider.min,\n",
    "    max=time_index_slider.max,\n",
    "    step=1,\n",
    "    interval=800,\n",
    "    description=\"Press play\",\n",
    "    disabled=False\n",
    ")\n",
    "widgets.jslink((play_button, 'value'), (time_index_slider, 'value'))\n",
    "\n",
    "\n",
    "# Date Slider\n",
    "date_range_slider = widgets.SelectionRangeSlider(\n",
    "    options=[d.strftime('%y/%m/%d') for d in date_range],\n",
    "    index=(0, len(date_range)-1),\n",
    "    description='Date Range:',\n",
    "    disabled=False,\n",
    "    orientation = 'horizontal',\n",
    "    layout=Layout(width='95%'),\n",
    "    continuous_update=False,\n",
    ")\n",
    "\n",
    "def on_change_date_range_slider(change):\n",
    "    global state, time_index_slider\n",
    "    \n",
    "    index = get_widget_index(change)\n",
    "    if index is not None:        \n",
    "        i, j = index\n",
    "        \n",
    "        time_index_slider.value = i \n",
    "        time_index_slider.min = i\n",
    "        time_index_slider.max = j\n",
    "                \n",
    "        state.update(\n",
    "            date_range_indices=(i,j),  \n",
    "            date_min=date_range[i],\n",
    "            date_max=date_range[j],        \n",
    "        )\n",
    "        draw(state)\n",
    "\n",
    "date_range_slider.observe(on_change_date_range_slider)\n",
    "\n",
    "\n",
    "# crime type selector\n",
    "def on_change_crime_types(button):\n",
    "    global state\n",
    "    if button.button_style == \"\":\n",
    "        button.button_style = \"success\"\n",
    "        state.crime_types.append(button.description)\n",
    "    else:\n",
    "        button.button_style = \"\"\n",
    "        state.crime_types.remove(button.description)\n",
    "        \n",
    "    \n",
    "    draw(state)\n",
    "    \n",
    "def new_buttons(names,all_selected=False):\n",
    "    global state\n",
    "    buttons = []\n",
    "    \n",
    "    if all_selected:\n",
    "        state.crime_types = [*names]\n",
    "        button_style = \"success\"\n",
    "    else:\n",
    "        state.crime_types = []\n",
    "        button_style = \"\"\n",
    "        \n",
    "    for name in names:\n",
    "        button = widgets.Button(\n",
    "            description=name,\n",
    "            tooltip=name,\n",
    "            disabled=False,\n",
    "            button_style=button_style, # 'success', 'info', 'warning', 'danger' or ''\n",
    "        )\n",
    "        \n",
    "        button.on_click(on_change_crime_types)\n",
    "        \n",
    "        buttons.append(button)\n",
    "    return buttons\n",
    "    \n",
    "    \n",
    "time_selectors = widgets.VBox([\n",
    "    widgets.HBox([date_range_slider]),\n",
    "    widgets.HBox([time_index_slider])    \n",
    "])    \n",
    "\n",
    "buttons = new_buttons(names=crime_categories, all_selected=True)\n",
    "crime_selectors = widgets.VBox([\n",
    "    widgets.HBox(buttons[:4]),\n",
    "    widgets.HBox(buttons[4:]),\n",
    "])\n",
    "\n",
    "# Spatial block size selection widget\n",
    "dlon_dlat_opts = list(map(tuple,(\n",
    "    np.array([[40,32], [20,16],[15,12],[10,8], [5,4], [3,2], [1,1]]) * np.array([0.001, 0.001]))))\n",
    "dx_dly_opts = list(map(tuple,(\n",
    "    np.array([[40,32], [20,16],[15,12],[10,8], [5,4], [3,2], [1,1]]) * np.array([85, 110]))))\n",
    "\n",
    "dropdown_block_size = widgets.Dropdown(\n",
    "    options=[(v, i) for i,v in enumerate(dx_dly_opts)],\n",
    "    value=state.block_size_index,\n",
    "    description='dx, dy:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def on_change_dropdown_block_size(change):\n",
    "    global state, block_size_changed\n",
    "    value = get_widget_value(change)\n",
    "    if value is not None:  \n",
    "        state.block_size_index = value\n",
    "        state.dlon, state.dlat = dlon_dlat_opts[value]\n",
    "        block_size_changed = True\n",
    "        draw(state)\n",
    "        \n",
    "dropdown_block_size.observe(on_change_dropdown_block_size)\n",
    "\n",
    "\n",
    "# widgets combinations and setup\n",
    "row0 = widgets.HBox([play_button, crime_selectors, dropdown_block_size])\n",
    "row1 = time_selectors\n",
    "\n",
    "controller = widgets.VBox([row0, row1, current_date_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.conditional_temporal_variables = {\n",
    "    \"1H\":[\"Hour\", \"Day of Week\", \"Time of Month\", \"Time of Year\"],\n",
    "    \"24H\":[\"Day of Week\", \"Time of Month\", \"Time of Year\"],\n",
    "    \"168H\":[\"Time of Month\", \"Time of Year\"],\n",
    "}.get(FREQ, [\"Time of Month\", \"Time of Year\"])\n",
    "\n",
    "# state.conditional_temporal_variables = [\"Hour\", \"Day of Week\", \"Time of Month\", \"Time of Year\"]\n",
    "# state.conditional_temporal_variables = [\"Day of Week\", \"Time of Month\", \"Time of Year\"]\n",
    "# state.conditional_temporal_variables = [ \"Time of Month\", \"Time of Year\"]\n",
    "# state.conditional_temporal_variables = [\"Day of Week\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_processing import sincos_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cutting data into 10 bins: dangerous when data is exponentially distributed\n",
      "WARNING:root:cutting data into 10 bins: dangerous when data is exponentially distributed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ff51768d9e4ea9bb7d63d65f4d2551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'name': '$I(C_t;C_{t-k})$',\n",
       "              'type': 'scatter',\n",
       "     …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state.mi_max_offset = 10\n",
    "state.mutual_info_bins = 10\n",
    "state.log_norm = False\n",
    "draw(state)\n",
    "widgets.VBox([fig_mi_cmi, fig_total_counts, controller, fig_app])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_date': '2014-01-01',\n",
       " 'end_date': '2019-01-01',\n",
       " 'dT': '1H',\n",
       " 'x_scale': 15,\n",
       " 'y_scale': 12,\n",
       " 'lat_max': 42.024,\n",
       " 'lat_min': 41.641,\n",
       " 'lon_max': -87.525,\n",
       " 'lon_min': -87.821,\n",
       " 'root': './',\n",
       " 'crime_types': ['THEFT',\n",
       "  'BATTERY',\n",
       "  'CRIMINAL DAMAGE',\n",
       "  'NARCOTICS',\n",
       "  'ASSAULT',\n",
       "  'BURGLARY',\n",
       "  'MOTOR VEHICLE THEFT',\n",
       "  'ROBBERY']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from utils.interactive import state_to_conf\n",
    "from utils.utils import write_json\n",
    "from os import makedirs\n",
    "state_to_conf(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.interactive import get_total_counts_by_type, get_total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = filter_frame(df, state)\n",
    "sub_dt = date_range[sub.t.min():sub.t.max()+1]\n",
    "\n",
    "total_counts_y, total_counts_x = get_total_counts(sub, state, date_range)\n",
    "total_counts_by_type = get_total_counts_by_type(sub, state, date_range)\n",
    "\n",
    "# test to see we get the same values\n",
    "assert len(total_counts_by_type.sum(1)) == len(total_counts_y)\n",
    "assert len(total_counts_x) == len(total_counts_y)\n",
    "assert np.sum(total_counts_by_type.sum(1) - total_counts_y) == 0\n",
    "\n",
    "\n",
    "from IPython.core.display import display\n",
    "display(total_counts_by_type)\n",
    "\n",
    "from utils.plots import plot_time_signals\n",
    "\n",
    "fig_total_counts_type = plot_time_signals(t_range=total_counts_x,\n",
    "                  **{col.title(): total_counts_by_type[col] for col in total_counts_by_type.columns}, \n",
    "                  title=f'{freq_title} City Wide Counts by Type',\n",
    "                  xlabel='Date',\n",
    "                  ylabel='Count',\n",
    "                  rangeslider_visible=False)\n",
    "fig_total_counts_type.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save selected subset limits to json file to be generated at later stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_TOTAL_COUNTS = True\n",
    "if SAVE_TOTAL_COUNTS:\n",
    "    conf = state_to_conf(state)\n",
    "    save_folder = f\"./data/processed/Totals_T{conf['dT']}_{conf['start_date']}_{conf['end_date']}\" \\\n",
    "    f\"_LAT{conf['lat_min']}_{conf['lat_max']}_LON{conf['lon_min']}_{conf['lon_max']}/\"\n",
    "    \n",
    "    makedirs(save_folder, exist_ok=True)\n",
    "    \n",
    "    pd.to_pickle(total_counts_by_type, f\"{save_folder}total_counts_by_type.pkl\")\n",
    "    write_json(\n",
    "        data=conf,\n",
    "        file_name=f\"{save_folder}config.json\",\n",
    "    )\n",
    "    \n",
    "    fig_total_counts_type.write_image(\n",
    "        f\"{save_folder}time_series_T{conf['dT']}_{conf['start_date']}_{conf['end_date']}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "DONE!!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-db5c8e4cf48d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DONE!!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: DONE!!"
     ]
    }
   ],
   "source": [
    "raise Exception(\"STOP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_SELECTION = False\n",
    "if SAVE_SELECTION:\n",
    "    conf = state_to_conf(state)\n",
    "#     ref = datetime.now().isoformat().split('.')[0]\n",
    "    ref = hex((hash(conf.__repr__()) % 3000) + 300).split('x')[1]\n",
    "    \n",
    "    print(f\"Saving file with ref: {ref}\")\n",
    "    write_json(\n",
    "        data=conf,\n",
    "        file_name=f\"./config/generate_data_{ref}.json\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics on selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub = filter_frame(df, state)\n",
    "print(f\"Number of crime occurences: {len(sub)}\")\n",
    "\n",
    "binned_data, (tbins_sub, cbins_sub, ybins_sub, xbins_sub) = bin_data_frame(sub, state)\n",
    "\n",
    "sub_dt = date_range[sub.t.min():sub.t.max()+1]\n",
    "counts_sum = binned_data.sum(-1).sum(-1)\n",
    "\n",
    "assert len(counts_sum) == len(sub_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import scale_per_time_slot\n",
    "from utils.plots import im_sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grids = np.concatenate([np.sum(binned_data, axis=1, keepdims=True), binned_data], axis=1)\n",
    "assert (grids[:,1:] == binned_data).all() == True\n",
    "assert (grids[:,0:1] == np.sum(binned_data, axis=1, keepdims=True)).all() == True\n",
    "\n",
    "from utils.preprocessing import Shaper\n",
    "\n",
    "shaper = Shaper(grids)\n",
    "sqz = shaper.squeeze(grids)\n",
    "\n",
    "# from utils.plots import im_sns\n",
    "\n",
    "# args = np.argsort(sqz.sum(0).sum(0))[::-1]\n",
    "\n",
    "\n",
    "topn = 200\n",
    "for i,k in enumerate(state.crime_types):\n",
    "    args = np.argsort(sqz[:,i].sum(0))[::-1][:topn]\n",
    "    sqz_over_time = sqz[:100,i,args]\n",
    "    \n",
    "    im_sns(sqz_over_time,title=k.title(), figsize=(16,9),\n",
    "           xlabel=f'Top {topn} Active Cells',\n",
    "           ylabel='Time Step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.interactive import InteractiveHeatmapsWithLines\n",
    "\n",
    "grid_dict = dict()\n",
    "grid_dict['Total'] = np.sum(binned_data, axis=1)\n",
    "for i,k in enumerate(state.crime_types):\n",
    "    grid_dict[k.title()] = binned_data[:,i]\n",
    "\n",
    "InteractiveHeatmapsWithLines(\n",
    "    date_range=sub_dt, \n",
    "    col_wrap=3,\n",
    "    **grid_dict,\n",
    ").app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {k: counts_sum[:,i]   for i,k in enumerate(state.crime_types)}\n",
    "# data_dict['Date'] = sub_dt\n",
    "# data_dict['Hour'] = sub_dt.hour\n",
    "# data_dict['Weekday'] = sub_dt.dayofweek\n",
    "\n",
    "total_counts_by_type = pd.DataFrame(data_dict, index=sub_dt)\n",
    "total_counts_by_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display distribution of a sample of the data\n",
    "fig_height=800\n",
    "px.density_heatmap(\n",
    "    data_frame=sub, #.sample(10000),\n",
    "    x=\"Longitude\",\n",
    "    y=\"Latitude\", \n",
    "    marginal_x=\"histogram\",\n",
    "    marginal_y=\"histogram\",\n",
    "    height=fig_height,\n",
    "    width=ratio_xy*fig_height,\n",
    "    nbinsx=len(xbins_sub),\n",
    "    nbinsy=len(ybins_sub),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit MI-regression vs Our MI-discrete table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression, mutual_info_classif\n",
    "\n",
    "series = counts_sum.sum(-1)\n",
    "\n",
    "# series = cut(series, 10)\n",
    "# series = np.round(np.log2(1 + series))\n",
    "\n",
    "max_offset = 370\n",
    "n = len(series) - max_offset\n",
    "l = []\n",
    "for i in range(max_offset+1):\n",
    "    l.append(series[i:n+i])\n",
    "data = np.array(l).T    \n",
    "\n",
    "X, y = data[:,:], data[:,-1]    \n",
    "\n",
    "mi = mutual_info_classif(X,y,discrete_features=True)\n",
    "mi_rest, mi_max = mi[:-1], mi[-1]\n",
    "mi_clf = (mi_rest/mi_max)[::-1]\n",
    "\n",
    "mi = mutual_info_regression(X,y,discrete_features=True)\n",
    "mi_rest, mi_max = mi[:-1], mi[-1]\n",
    "mi_reg = (mi_rest/mi_max)[::-1]\n",
    "\n",
    "\n",
    "shape_ = data.shape\n",
    "data = cut(data.flatten(),10).reshape(shape_)\n",
    "\n",
    "X, y = data[:,:], data[:,-1]   \n",
    "\n",
    "mis = []\n",
    "for i in range(max_offset+1):\n",
    "    mis.append(quick_mutual_info(X[:,i], y,norm=True))\n",
    "mi_rest, mi_max = mis[:-1], mis[-1]\n",
    "mi_our = (mi_rest/mi_max)[::-1]\n",
    "\n",
    "\n",
    "px.line(pd.DataFrame({\"mi_our\":mi_our, \"mi_reg\":mi_reg, \"mi_clf\": mi_clf}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D decomposition of the signals by crime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traces = []\n",
    "\n",
    "for i,k in enumerate(state.crime_types):\n",
    "    trace = go.Scatter(\n",
    "        x=sub_dt,\n",
    "        y=counts_sum[:,i], \n",
    "        mode='lines',\n",
    "        name=k,\n",
    "        opacity=0.5,\n",
    "    )\n",
    "    traces.append(trace)\n",
    "    \n",
    "trace = go.Scatter(\n",
    "    x=sub_dt,\n",
    "    y=counts_sum.sum(1),\n",
    "    mode='lines',\n",
    "    name='TOTAL',\n",
    "    opacity=0.1,\n",
    ")\n",
    "traces.append(trace)\n",
    "    \n",
    "fig = go.Figure(traces)\n",
    "\n",
    "fig.update_layout(\n",
    "    width=900,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D decomposition of the signals by crime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "\n",
    "for i,k in enumerate(state.crime_types):\n",
    "    trace = go.Scatter3d(\n",
    "        x=sub_dt,\n",
    "        y=np.ones(len(counts_sum))*(i+1),\n",
    "        z=counts_sum[:,i], \n",
    "        mode='lines',\n",
    "        name=k,\n",
    "        opacity=0.5,\n",
    "    )\n",
    "    traces.append(trace)\n",
    "    \n",
    "trace = go.Scatter3d(\n",
    "    x=sub_dt,\n",
    "    y=np.ones(len(counts_sum))*0,\n",
    "    z=counts_sum.sum(1),\n",
    "    mode='lines',\n",
    "    name='TOTAL',\n",
    "    opacity=0.1,\n",
    ")\n",
    "traces.append(trace)\n",
    "    \n",
    "fig = go.Figure(traces)\n",
    "\n",
    "fig.update_layout(\n",
    "    width=900,\n",
    "    height=700,\n",
    "    autosize=False,\n",
    "    scene=dict(\n",
    "        camera=dict(\n",
    "            up=dict(\n",
    "                x=0,\n",
    "                y=0,\n",
    "                z=1\n",
    "            ),\n",
    "            eye=dict(\n",
    "                x=0,\n",
    "                y=1.0707,\n",
    "                z=1,\n",
    "            )\n",
    "        ),\n",
    "        aspectratio = dict( x=1, y=1, z=0.7 ),\n",
    "        aspectmode = 'manual'\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Counts by Crime Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts_sum = np.round(np.log2(1 + counts_sum))\n",
    "\n",
    "# cap = 33\n",
    "# counts_sum[counts_sum > cap] = cap\n",
    "\n",
    "traces = []\n",
    "traces.append(\n",
    "    go.Histogram(\n",
    "        x=counts_sum.sum(1),\n",
    "        name='TOTAL',\n",
    "        opacity=0.4,\n",
    "        histnorm='probability density',\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "for i,k in enumerate(state.crime_types):\n",
    "    traces.append(\n",
    "        go.Histogram(\n",
    "            x=counts_sum[:,i],\n",
    "            name=k,\n",
    "            opacity=0.4,\n",
    "            histnorm='probability density',\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "fig = go.Figure(traces, layout=dict(height=600, title=\"Crime Count Distribution by Type\"))\n",
    "fig.update_layout(\n",
    "    barmode='overlay', \n",
    "    title_x=0.5,\n",
    "    yaxis_title=\"Probability\",\n",
    "    xaxis_title=\"Count\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {k: counts_sum[:,i]   for i,k in enumerate(state.crime_types)}\n",
    "# data_dict['Date'] = sub_dt\n",
    "# data_dict['Hour'] = sub_dt.hour\n",
    "# data_dict['Weekday'] = sub_dt.dayofweek\n",
    "\n",
    "total_counts_by_type = pd.DataFrame(data_dict)\n",
    "total_counts_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of selection counts\n",
    "fig = px.histogram(\n",
    "    total_counts_by_type.melt(),\n",
    "    histnorm='probability density',\n",
    "    title=\"Crime Count Distribution by Type\",\n",
    "#     color=\"variable\",\n",
    "    facet_col=\"variable\",\n",
    "    facet_col_wrap=1,\n",
    "    opacity=.3,\n",
    ")\n",
    "\n",
    "fig.update_layout(barmode='overlay', height=1200, width=300, showlegend=False)\n",
    "fig.update_layout(title={'x':0.5}, font=dict(family=\"STIXGeneral\"))\n",
    "fig.update_yaxes(title_text='Probability')\n",
    "fig.update_xaxes(title_text='Crime Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts_y, total_counts_x = get_total_counts(sub, state, date_range)\n",
    "fig = px.histogram(pd.DataFrame({\"Crime Count\":total_counts_y}),\n",
    "             histnorm='probability density',title=\"Crime Count Distribution\")\n",
    "fig.update_layout(title={'x':0.5}, font=dict(family=\"STIXGeneral\"))\n",
    "fig.update_yaxes(title_text='Probability')\n",
    "fig.update_xaxes(title_text='Crime Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub_dow_name = pd.DataFrame({'day of week name': sub.Date.dt.day_name()})\n",
    "sub_dow = pd.DataFrame({'day of week': sub.Date.dt.dayofweek})\n",
    "sub_hour = pd.DataFrame({'hour of day': sub.Date.dt.hour})\n",
    "sub_cat = pd.concat([sub, sub_dow, sub_dow_name, sub_hour], axis=1)\n",
    "sub_cat['crimes'] = np.ones(len(sub))\n",
    "\n",
    "\n",
    "# distribution of selection counts\n",
    "total_counts_y, total_counts_x = get_total_counts(sub, state, date_range)\n",
    "\n",
    "fig = px.histogram(pd.DataFrame({\"Crime Count\":total_counts_y}),\n",
    "             histnorm='probability density',title=\"Crime Count Distribution\")\n",
    "fig.update_yaxes(title_text='Probability')\n",
    "fig.update_xaxes(title_text='Crime Count')\n",
    "fig.update_layout(title={'x':0.5}, font=dict(family=\"STIXGeneral\"))\n",
    "fig.show()\n",
    "\n",
    "# log normed distribution\n",
    "log_scaled_counts_y = np.round(np.log2(1+ total_counts_y))\n",
    "fig = px.histogram(pd.DataFrame({\"Log Scaled Crime Count\":log_scaled_counts_y}),\n",
    "             histnorm='probability density',title=\"Log Crime Count Distribution log2(1+x)\")\n",
    "fig.update_yaxes(title_text='Probability')\n",
    "fig.update_xaxes(title_text='Log Crime Count')\n",
    "fig.update_layout(title={'x':0.5}, font=dict(family=\"STIXGeneral\"))\n",
    "fig.show()\n",
    "\n",
    "# distribution of crime type\n",
    "fig = px.histogram(\n",
    "    data_frame=sub_cat,\n",
    "    x='Primary Type',\n",
    "    y='crimes', \n",
    "    histnorm='probability density',\n",
    "    title=\"Crime Type Distribution\",\n",
    ")\n",
    "fig.update_layout(title={'x':0.5}, font=dict(family=\"STIXGeneral\"))\n",
    "fig.update_yaxes(title_text='Probability')\n",
    "fig.update_xaxes(title_text='Crime Count')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# crime distirbution distribution of hour of day by type\n",
    "fig = px.histogram(\n",
    "    data_frame=sub_cat,\n",
    "    x='hour of day',\n",
    "    y='crimes', \n",
    "    facet_col='Primary Type',\n",
    "    facet_col_wrap=2,\n",
    "    height=800,\n",
    "    histnorm='probability density',\n",
    "    title=\"Crime Type Distribution by Hour\",\n",
    ")\n",
    "fig.update_layout(title={'x':0.5}, font=dict(family=\"STIXGeneral\"))\n",
    "fig.update_yaxes(title_text='Probability',col=1)\n",
    "fig.update_xaxes(title_text='Hour of Day')\n",
    "fig.show()\n",
    "\n",
    "# distribution of day of week\n",
    "fig = px.histogram(\n",
    "    data_frame=sub_cat,\n",
    "    x='day of week',\n",
    "    y='crimes', \n",
    "    facet_col='Primary Type',\n",
    "    facet_col_wrap=2,\n",
    "    height=800,\n",
    "    histnorm='probability density',\n",
    "    title=\"Crime Type Distribution by Weekday\",\n",
    ")\n",
    "fig.update_layout(title={'x':0.5}, font=dict(family=\"STIXGeneral\"))\n",
    "fig.update_yaxes(title_text='Probability',col=1)\n",
    "fig.update_xaxes(\n",
    "    title_text='Day of Week',\n",
    "    tickmode = 'array',\n",
    "    tickvals = [0,1,2,3,4,5,6],\n",
    "    ticktext = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'],    \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binned_data, bins = bin_data_frame(df,state)\n",
    "mean_map, xbins, ybins = counts_mean = get_mean_map(df, state)\n",
    "new_heatmap(z=mean_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geo-plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapbox_access_token = open(\".mapbox_token\").read()\n",
    "# mapbox_access_token = \"open-street-map\"\n",
    "mapbox_access_token\n",
    "\n",
    "on_state = ('#f050ae', 8)\n",
    "off_state = ('#ffab00', 8)\n",
    "\n",
    "mapbox_styles = {\n",
    "    \"sat\": \"mapbox://styles/bernsblack/ckecz0wr52pfc1at7tvu43fmj\", \n",
    "    \"mono\": \"mapbox://styles/bernsblack/ckecyyizy065w19psrikmeo5d\",\n",
    "    \"dark\": \"mapbox://styles/bernsblack/ckeikbchd254619s57np6iyum\",\n",
    "}\n",
    "\n",
    "color_palette = [\"#33a8c7\",\"#52e3e1\",\"#a0e426\",\"#fdf148\",\"#ffab00\",\"#f77976\",\"#f050ae\",\"#d883ff\",\"#9336fd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plots import hist2d_to_geo\n",
    "# get block infos for whole df\n",
    "\n",
    "sub = filter_frame(df,state).sample(10_000)\n",
    "\n",
    "binned_data, (tbins,cbins,ybins,xbins) = bin_data_frame(sub,state)\n",
    " \n",
    "counts_sum = binned_data.sum(0).sum(0)\n",
    "counts_mean = binned_data.mean(0).mean(0)\n",
    "\n",
    "blocks_geo, blocks_info = hist2d_to_geo(counts_mean,xbins,ybins,filter_zero=True)\n",
    "\n",
    "heatmap_geo = go.Choroplethmapbox(\n",
    "    geojson=blocks_geo,\n",
    "    locations=blocks_info.id,\n",
    "    z=blocks_info.value,\n",
    "    colorscale=\"Viridis\",\n",
    "    zmin=blocks_info.value.min(),\n",
    "    zmax=blocks_info.value.max(),\n",
    "    marker_opacity=0.5,\n",
    "    marker_line_width=0,\n",
    "    name='heatmap',\n",
    "    hoverinfo='text',\n",
    "    hovertext=blocks_info[['y','x','value']],\n",
    ")\n",
    "\n",
    "# scatter_geo = go.Scattermapbox(\n",
    "#     lon=sub.Longitude,\n",
    "#     lat=sub.Latitude,\n",
    "#     opacity=.4,\n",
    "#     hoverinfo='skip',\n",
    "#     name='scatter',\n",
    "# )\n",
    "\n",
    "scatter_geo = []\n",
    "for cat in crime_categories:\n",
    "    tmp = sub[sub[\"Primary Type\"] == cat]\n",
    "    scatter = go.Scattermapbox(\n",
    "        lon=tmp.Longitude,\n",
    "        lat=tmp.Latitude,\n",
    "        opacity=.4,\n",
    "        hoverinfo='skip',\n",
    "        name=cat,\n",
    "    )\n",
    "    scatter_geo.append(scatter)\n",
    "    \n",
    "    \n",
    "\n",
    "fig_geo = go.FigureWidget(data=[heatmap_geo, *scatter_geo])\n",
    "\n",
    "fig_geo.update_layout(\n",
    "    font=dict(family=\"STIXGeneral\"),\n",
    "    clickmode='event+select',\n",
    "    mapbox_style=mapbox_styles[\"sat\"],\n",
    "    mapbox_accesstoken=mapbox_access_token,\n",
    "    mapbox_zoom=10,\n",
    "    mapbox_center = {\"lat\": np.mean(ybins), \"lon\": np.mean(xbins)},\n",
    "    margin={\"r\":0,\"t\":30,\"l\":0,\"b\":10},\n",
    "    height=500,\n",
    "    showlegend=True,\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.99,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01,\n",
    "    ),\n",
    ")\n",
    "\n",
    "heatmap_geo = fig_geo.data[0]  \n",
    "\n",
    "# def heatmap_geo_on_select(trace,points,selector):\n",
    "#     global state\n",
    "    \n",
    "#     inds = points.point_inds\n",
    "#     selection = blocks_info.iloc[inds]\n",
    "#     _,_,f_x_min,f_y_min = selection.min()\n",
    "#     _,_,f_x_max,f_y_max = selection.max()\n",
    "\n",
    "#     state.lon_min, state.lon_max = xbins[[f_x_min,f_x_max]]\n",
    "#     state.lat_min, state.lat_max = ybins[[f_y_min,f_y_max]]\n",
    "    \n",
    "      \n",
    "# heatmap_geo.on_selection(heatmap_geo_on_select)\n",
    "\n",
    "fig_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
