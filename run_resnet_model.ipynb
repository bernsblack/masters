{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24833,
     "status": "ok",
     "timestamp": 1572984969030,
     "user": {
      "displayName": "Bernard Swart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA7uSA62RDxMrL_HdFxD2SxWswIX97G3OjMRiFvmMU=s64",
      "userId": "00293673988406756138"
     },
     "user_tz": -120
    },
    "id": "MO1IajwdeyAs",
    "outputId": "3b47cff2-e2f1-4f08-c1e3-7f617f08fabd"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd /content/gdrive/My\\ Drive/masters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4701,
     "status": "ok",
     "timestamp": 1572958457747,
     "user": {
      "displayName": "Bernard Swart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA7uSA62RDxMrL_HdFxD2SxWswIX97G3OjMRiFvmMU=s64",
      "userId": "00293673988406756138"
     },
     "user_tz": -120
    },
    "id": "tsPg_sEloTio",
    "outputId": "a049e1ee-6335-4a09-97ee-793af8917f53"
   },
   "outputs": [],
   "source": [
    "# %ls ./data/processed\n",
    "# # T12H-X850M-Y880M_2013-01-01_2015-01-01/\n",
    "# # T1H-X1700M-Y1760M_2013-01-01_2015-01-01/\n",
    "# # T1H-X850M-Y880M_2013-01-01_2015-01-01/\n",
    "# # T24H-X255M-Y220M_2013-01-01_2015-01-01/\n",
    "# # T24H-X425M-Y440M_2013-01-01_2015-01-01/\n",
    "# # T24H-X850M-Y880M_2013-01-01_2015-01-01/\n",
    "# # T24H-X85M-Y110M_2013-01-01_2015-01-01/\n",
    "# # T3H-X850M-Y880M_2013-01-01_2015-01-01/\n",
    "# # T6H-X850M-Y880M_2013-01-01_2015-01-01/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TvtFIzBxb8fR"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import logging as log\n",
    "from time import strftime\n",
    "from copy import deepcopy\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from utils.data_processing import *\n",
    "from logger.logger import setup_logging\n",
    "from utils.configs import BaseConf\n",
    "from utils.metrics import best_threshold\n",
    "from utils.utils import write_json, Timer\n",
    "from dataloaders.grid_loader import GridDataLoaders\n",
    "from datasets.grid_dataset import GridDataGroup\n",
    "from utils.metrics import PRCurvePlotter, ROCCurvePlotter, LossPlotter, best_threshold, get_y_pred, \\\n",
    "                                get_y_pred_by_thresholds, best_thresholds\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score\n",
    "from models.model_result import ModelResult, ModelMetrics\n",
    "from trainers.generic_trainer import train_model\n",
    "from utils.plots import im\n",
    "from utils.utils import pshape, get_data_sub_paths\n",
    "from models.model_result import save_metrics, compare_models,get_metrics_table, get_models_metrics, get_models_results\n",
    "from models.st_resnet_models import STResNet, STResNetExtra\n",
    "from models.st_resnet_models import train_epoch_for_st_res_net, train_epoch_for_st_res_net_extra\n",
    "from models.st_resnet_models import evaluate_st_res_net, evaluate_st_res_net_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub_paths = get_data_sub_paths()\n",
    "data_sub_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jt49pMZNb8fY"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1605,
     "status": "ok",
     "timestamp": 1572960485086,
     "user": {
      "displayName": "Bernard Swart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA7uSA62RDxMrL_HdFxD2SxWswIX97G3OjMRiFvmMU=s64",
      "userId": "00293673988406756138"
     },
     "user_tz": -120
    },
    "id": "MyPcEJeMb8fV",
    "outputId": "ff265c03-5dce-46f8-c34a-d6f485b2862a"
   },
   "outputs": [],
   "source": [
    "USE_EXTRA = False # todo move extra model to own notebook\n",
    "\n",
    "start_date = \"2013-01-01\"\n",
    "end_date = \"2015-01-01\" \n",
    "\n",
    "data_dim_str = 'T24H-X255M-Y220M' # \"T24H-X850M-Y880M\" # \"T1H-X1700M-Y1760M\" #\n",
    "conf = BaseConf()\n",
    "\n",
    "if USE_EXTRA:\n",
    "    conf.model_name = \"ST-RESNET-Extra\"  # needs to be created\n",
    "else:     \n",
    "    conf.model_name = \"ST-RESNET\"  # needs to be created\n",
    "\n",
    "conf.data_path = f\"./data/processed/{data_dim_str}_{start_date}_{end_date}/\"\n",
    "\n",
    "if not os.path.exists(conf.data_path):\n",
    "    raise Exception(f\"Directory ({conf.data_path}) needs to exist.\")\n",
    "\n",
    "conf.model_path =  f\"{conf.data_path}models/{conf.model_name}/\"\n",
    "os.makedirs(conf.data_path, exist_ok=True)\n",
    "os.makedirs(conf.model_path, exist_ok=True)\n",
    "\n",
    "# logging config is set globally thus we only need to call this in this file\n",
    "# imported function logs will follow the configuration\n",
    "setup_logging(save_dir=conf.model_path, log_config='./logger/standard_logger_config.json', default_level=log.INFO)\n",
    "log.info(\"=====================================BEGIN=====================================\")\n",
    "\n",
    "info = deepcopy(conf.__dict__)\n",
    "info[\"start_time\"] = strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "# DATA LOADER SETUP\n",
    "np.random.seed(conf.seed)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed( conf.seed)\n",
    "else:\n",
    "    torch.manual_seed(conf.seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "log.info(f\"Device: {device}\")\n",
    "info[\"device\"] = device.type\n",
    "conf.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4912,
     "status": "ok",
     "timestamp": 1572960488409,
     "user": {
      "displayName": "Bernard Swart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA7uSA62RDxMrL_HdFxD2SxWswIX97G3OjMRiFvmMU=s64",
      "userId": "00293673988406756138"
     },
     "user_tz": -120
    },
    "id": "5QyALyMZb8fb",
    "outputId": "993ee8f5-7399-47d7-8e86-31175f683f78"
   },
   "outputs": [],
   "source": [
    "conf.batch_size = 256\n",
    "\n",
    "# CRIME DATA\n",
    "data_group = GridDataGroup(data_path=conf.data_path,\n",
    "                           conf=conf)\n",
    "\n",
    "loaders = GridDataLoaders(data_group=data_group,\n",
    "                          conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jt49pMZNb8fY"
   },
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33190,
     "status": "ok",
     "timestamp": 1572960516695,
     "user": {
      "displayName": "Bernard Swart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA7uSA62RDxMrL_HdFxD2SxWswIX97G3OjMRiFvmMU=s64",
      "userId": "00293673988406756138"
     },
     "user_tz": -120
    },
    "id": "y24-YZ6Tb8fc",
    "outputId": "c77ac097-0cff-474c-f70d-eff832602cfb",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SET THE HYPER PARAMETERS\n",
    "conf.dropout = 0#0.2\n",
    "conf.weight_decay = 1e-8\n",
    "conf.lr = 1e-3\n",
    "conf.checkpoint =  \"best\" # \"latest\" # \n",
    "conf.resume = False\n",
    "conf.freqstr = data_group.t_range.freqstr  \n",
    "conf.early_stopping = False\n",
    "conf.max_epochs = 20\n",
    "\n",
    "# SET LOSS FUNCTION\n",
    "# size averaged - so more epochs or larger lr for smaller batches\n",
    "loss_function = nn.MSELoss()  \n",
    "\n",
    "# SETUP MODEL\n",
    "dataset = loaders.train_loader.dataset\n",
    "_, h_size, w_size = dataset.crimes.shape\n",
    "_, n_ext_features = dataset.time_vectors.shape\n",
    "\n",
    "\n",
    "# todo setup - hyper-optimiser\n",
    "conf.n_layers = 5  # number of res-unit layers\n",
    "conf.n_channels = 3 # inner channel size of the res-units \n",
    "\n",
    "if USE_EXTRA:\n",
    "    train_epoch_fn = train_epoch_for_st_res_net_extra\n",
    "    evaluate_fn = evaluate_st_res_net_extra\n",
    "    model = STResNetExtra(n_layers=conf.n_layers,\n",
    "                          n_channels=conf.n_channels,\n",
    "                          y_size=h_size,\n",
    "                          x_size=w_size,\n",
    "\n",
    "                          lc=dataset.n_steps_c,\n",
    "                          lp=dataset.n_steps_p,\n",
    "                          lq=dataset.n_steps_q,\n",
    "\n",
    "                          n_ext_features=n_ext_features,\n",
    "                          n_demog_features=37,\n",
    "                          n_demog_channels=10,\n",
    "                          n_demog_layers=3,\n",
    "\n",
    "                          n_gsv_features=512,\n",
    "                          n_gsv_channels=10,\n",
    "                          n_gsv_layers=3)\n",
    "else:\n",
    "    train_epoch_fn = train_epoch_for_st_res_net\n",
    "    evaluate_fn = evaluate_st_res_net\n",
    "    model = STResNet(n_layers=conf.n_layers,\n",
    "                     n_channels=conf.n_channels,\n",
    "                     y_size=h_size,\n",
    "                     x_size=w_size,\n",
    "\n",
    "                     lc=dataset.n_steps_c,\n",
    "                     lp=dataset.n_steps_p,\n",
    "                     lq=dataset.n_steps_q,\n",
    "\n",
    "                     n_ext_features=n_ext_features)    \n",
    "    \n",
    "# todo implement model_arch for res-net\n",
    "model.to(conf.device)\n",
    "\n",
    "# SETUP OPTIMISER\n",
    "parameters = model.parameters()\n",
    "# todo (optional): setup model parameters dynamically \n",
    "\n",
    "optimiser = optim.Adam(params=parameters, lr=conf.lr, weight_decay=conf.weight_decay)\n",
    "\n",
    "if conf.resume:\n",
    "    try:\n",
    "        # resume from previous check point or resume from best validaton score checkpoint\n",
    "        # load model state\n",
    "        model_state_dict = torch.load(f\"{conf.model_path}model_{conf.checkpoint}.pth\",\n",
    "                                      map_location=conf.device.type)\n",
    "        model.load_state_dict(model_state_dict)\n",
    "        \n",
    "        # load optimiser state\n",
    "        optimiser_state_dict = torch.load(f\"{conf.model_path}optimiser_{conf.checkpoint}.pth\",\n",
    "                                          map_location=conf.device.type)\n",
    "        optimiser.load_state_dict(optimiser_state_dict) \n",
    "\n",
    "        # new optimiser hyper-parameters\n",
    "        optimiser.param_groups[0]['lr'] = conf.lr\n",
    "        optimiser.param_groups[0]['weight_decay'] = conf.weight_decay\n",
    "\n",
    "    except Exception as e:\n",
    "        log.error(f\"Nothing to resume from, training from scratch \\n\\t-> {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jt49pMZNb8fY"
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(f\"lr: \\t\\t{optimiser.param_groups[0]['lr']}\")\n",
    "log.info(f\"weight_decay: \\t{optimiser.param_groups[0]['weight_decay']}\")\n",
    "trn_epoch_losses, val_epoch_losses, stopped_early = train_model(model=model,\n",
    "                                           optimiser=optimiser,\n",
    "                                           loaders=loaders,\n",
    "                                           train_epoch_fn=train_epoch_fn,\n",
    "                                           loss_fn=loss_function,\n",
    "                                           conf=conf)    \n",
    "\n",
    "print(f\"stopped_early: {stopped_early}\") # use the current epoch instead\n",
    "# if stopped_early -> continue with best_model - new hyper-parameters -> no n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for x in [trn_epoch_losses, val_epoch_losses]:\n",
    "    plt.plot(x[-10:],marker='|',alpha=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gX7qhAv3b8ff"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load latest or best validation model\n",
    "# conf.checkpoint = \"latest\"\n",
    "conf.checkpoint = \"best\"\n",
    "\n",
    "log.info(f\"Loading model from checkpoint ({conf.checkpoint}) for evaluation\")\n",
    "\n",
    "# resume from previous check point or resume from best validaton score checkpoint\n",
    "# load model state\n",
    "log.info(f\"loading model from {conf.model_path}\")\n",
    "model_state_dict = torch.load(f\"{conf.model_path}model_{conf.checkpoint}.pth\",\n",
    "                                map_location=conf.device.type)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 80740,
     "status": "ok",
     "timestamp": 1572960564290,
     "user": {
      "displayName": "Bernard Swart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA7uSA62RDxMrL_HdFxD2SxWswIX97G3OjMRiFvmMU=s64",
      "userId": "00293673988406756138"
     },
     "user_tz": -120
    },
    "id": "Oc2okw15b8fn",
    "outputId": "483d112e-c02e-4e21-e69d-ccd9872c4b8c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trn_y_counts, trn_y_true, trn_probas_pred, trn_t_range = evaluate_fn(model=model,\n",
    "                                                                     batch_loader=loaders.train_loader,\n",
    "                                                                     conf=conf) \n",
    "thresh = best_threshold(trn_y_true, trn_probas_pred) \n",
    "\n",
    "tst_y_counts, tst_y_true, tst_probas_pred, tst_t_range = evaluate_fn(model=model,\n",
    "                                                                     batch_loader=loaders.test_loader,\n",
    "                                                                     conf=conf)\n",
    "\n",
    "\n",
    "tst_y_true = np.expand_dims(tst_y_true, axis=1)\n",
    "tst_probas_pred = np.expand_dims(tst_probas_pred, axis=1) \n",
    "\n",
    "tst_y_true = data_group.shaper.squeeze(tst_y_true)\n",
    "tst_probas_pred = data_group.shaper.squeeze(tst_probas_pred)\n",
    "\n",
    "\n",
    "tst_y_pred = get_y_pred(thresh, tst_probas_pred)\n",
    "save_metrics(y_true=tst_y_true,\n",
    "             y_pred=tst_y_pred,\n",
    "             probas_pred=tst_probas_pred,\n",
    "             t_range=tst_t_range,\n",
    "             shaper=data_group.shaper,                \n",
    "             conf=conf)\n",
    "compare_models(data_path=conf.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results = get_models_results(data_path=conf.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = models_results[0]\n",
    "\n",
    "def norm(x):\n",
    "#     return x\n",
    "    x = x - np.min(x)\n",
    "    x = x / np.max(x)\n",
    "    return x\n",
    "\n",
    "i = 0\n",
    "lim = 100\n",
    "for m in models_results:\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    y_true = m.y_true[:lim,0,i]#.sum(1)\n",
    "    plt.plot(norm(y_true),label='true')\n",
    "\n",
    "    x0 = m.probas_pred[:lim,0,i]#.sum(1)\n",
    "    plt.plot(norm(x0),label=m.model_name)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = models_results[1]\n",
    "m.y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [m.shaper for m in models_results]\n",
    "for t in targets:\n",
    "    print(t.l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZskT0-MmKFk_"
   },
   "source": [
    "## All in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import logging as log\n",
    "from time import strftime\n",
    "from copy import deepcopy\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from utils.data_processing import *\n",
    "from logger.logger import setup_logging\n",
    "from utils.configs import BaseConf\n",
    "from utils.utils import write_json, Timer\n",
    "from dataloaders.grid_loader import GridDataLoaders\n",
    "from datasets.grid_dataset import GridDataGroup\n",
    "from utils.metrics import PRCurvePlotter, ROCCurvePlotter, LossPlotter, best_threshold, get_y_pred\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score\n",
    "from models.model_result import ModelResult, ModelMetrics\n",
    "from trainers.generic_trainer import train_model\n",
    "from utils.plots import im\n",
    "from utils.utils import pshape, get_data_sub_paths\n",
    "from models.model_result import save_metrics, compare_models, get_models_metrics, get_models_results\n",
    "from models.st_resnet_models import STResNet, STResNetExtra\n",
    "from models.st_resnet_models import train_epoch_for_st_res_net, train_epoch_for_st_res_net_extra\n",
    "from models.st_resnet_models import evaluate_st_res_net, evaluate_st_res_net_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub_paths = get_data_sub_paths()\n",
    "data_sub_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub_paths = ['T24H-X850M-Y880M_2013-01-01_2015-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data_sub_path in data_sub_paths:\n",
    "    log.info(f\"\\n========================= {data_sub_path} =========================\\n\")    \n",
    "    for USE_EXTRA in [False, True]:\n",
    "        conf = BaseConf()\n",
    "\n",
    "        if USE_EXTRA:\n",
    "            conf.model_name = \"ST-RESNET-Extra\"  # needs to be created\n",
    "        else:     \n",
    "            conf.model_name = \"ST-RESNET\"  # needs to be created\n",
    "\n",
    "        conf.data_path = f\"./data/processed/{data_dim_str}_{start_date}_{end_date}/\"\n",
    "\n",
    "        if not os.path.exists(conf.data_path):\n",
    "            raise Exception(f\"Directory ({conf.data_path}) needs to exist.\")\n",
    "\n",
    "        conf.model_path =  f\"{conf.data_path}models/{conf.model_name}/\"\n",
    "        os.makedirs(conf.data_path, exist_ok=True)\n",
    "        os.makedirs(conf.model_path, exist_ok=True)\n",
    "\n",
    "        # logging config is set globally thus we only need to call this in this file\n",
    "        # imported function logs will follow the configuration\n",
    "        setup_logging(save_dir=conf.model_path, log_config='./logger/standard_logger_config.json', default_level=log.INFO)\n",
    "        log.info(\"=====================================BEGIN=====================================\")\n",
    "\n",
    "        info = deepcopy(conf.__dict__)\n",
    "        info[\"start_time\"] = strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "        # DATA LOADER SETUP\n",
    "        np.random.seed(conf.seed)\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        if use_cuda:\n",
    "            torch.cuda.manual_seed( conf.seed)\n",
    "        else:\n",
    "            torch.manual_seed(conf.seed)\n",
    "\n",
    "        device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "        log.info(f\"Device: {device}\")\n",
    "        info[\"device\"] = device.type\n",
    "        conf.device = device\n",
    "\n",
    "\n",
    "        # SET THE HYPER PARAMETERS\n",
    "        conf.dropout = 0#0.2\n",
    "        conf.weight_decay = 0# 1e-8\n",
    "        conf.checkpoint = \"best\" # [\"best\"|\"latest\"]\n",
    "        conf.lr = 1e-3\n",
    "        conf.batch_size = 256\n",
    "\n",
    "        # CRIME DATA\n",
    "        data_group = GridDataGroup(data_path=conf.data_path,\n",
    "                                   conf=conf)\n",
    "\n",
    "        loaders = GridDataLoaders(data_group=data_group,\n",
    "                                  conf=conf)\n",
    "\n",
    "        conf.checkpoint =  \"best\" # \"latest\" # \n",
    "        conf.resume = False\n",
    "        conf.freqstr = data_group.t_range.freqstr  \n",
    "        conf.early_stopping = False\n",
    "        conf.max_epochs = 60\n",
    "\n",
    "        # SET LOSS FUNCTION\n",
    "        # size averaged - so more epochs or larger lr for smaller batches\n",
    "        loss_function = nn.MSELoss()  \n",
    "\n",
    "        # SETUP MODEL\n",
    "        dataset = loaders.train_loader.dataset\n",
    "        _, h_size, w_size = dataset.crimes.shape\n",
    "        _, n_ext_features = dataset.time_vectors.shape\n",
    "\n",
    "\n",
    "        # todo setup - hyper-optimiser\n",
    "        conf.n_layers = 3  # number of res-unit layers\n",
    "        conf.n_channels = 3 # inner channel size of the res-units \n",
    "\n",
    "        if USE_EXTRA:\n",
    "            train_epoch_fn = train_epoch_for_st_res_net_extra\n",
    "            evaluate_fn = evaluate_st_res_net_extra\n",
    "            model = STResNetExtra(n_layers=conf.n_layers,\n",
    "                                  n_channels=conf.n_channels,\n",
    "                                  y_size=h_size,\n",
    "                                  x_size=w_size,\n",
    "\n",
    "                                  lc=dataset.n_steps_c,\n",
    "                                  lp=dataset.n_steps_p,\n",
    "                                  lq=dataset.n_steps_q,\n",
    "\n",
    "                                  n_ext_features=n_ext_features,\n",
    "                                  n_demog_features=37,\n",
    "                                  n_demog_channels=10,\n",
    "                                  n_demog_layers=3,\n",
    "\n",
    "                                  n_gsv_features=512,\n",
    "                                  n_gsv_channels=10,\n",
    "                                  n_gsv_layers=3)\n",
    "        else:\n",
    "            train_epoch_fn = train_epoch_for_st_res_net\n",
    "            evaluate_fn = evaluate_st_res_net\n",
    "            model = STResNet(n_layers=conf.n_layers,\n",
    "                             n_channels=conf.n_channels,\n",
    "                             y_size=h_size,\n",
    "                             x_size=w_size,\n",
    "\n",
    "                             lc=dataset.n_steps_c,\n",
    "                             lp=dataset.n_steps_p,\n",
    "                             lq=dataset.n_steps_q,\n",
    "\n",
    "                             n_ext_features=n_ext_features)    \n",
    "\n",
    "        # todo implement model_arch for res-net\n",
    "        model.to(conf.device)\n",
    "\n",
    "        # SETUP OPTIMISER\n",
    "        parameters = model.parameters()\n",
    "        # todo (optional): setup model parameters dynamically \n",
    "\n",
    "        optimiser = optim.Adam(params=parameters, lr=conf.lr, weight_decay=conf.weight_decay)\n",
    "\n",
    "        if conf.resume:\n",
    "            try:\n",
    "                # resume from previous check point or resume from best validaton score checkpoint\n",
    "                # load model state\n",
    "                model_state_dict = torch.load(f\"{conf.model_path}model_{conf.checkpoint}.pth\",\n",
    "                                              map_location=conf.device.type)\n",
    "                model.load_state_dict(model_state_dict)\n",
    "\n",
    "                # load optimiser state\n",
    "                optimiser_state_dict = torch.load(f\"{conf.model_path}optimiser_{conf.checkpoint}.pth\",\n",
    "                                                  map_location=conf.device.type)\n",
    "                optimiser.load_state_dict(optimiser_state_dict) \n",
    "\n",
    "                # new optimiser hyper-parameters\n",
    "                optimiser.param_groups[0]['lr'] = conf.lr\n",
    "                optimiser.param_groups[0]['weight_decay'] = conf.weight_decay\n",
    "\n",
    "            except Exception as e:\n",
    "                log.error(f\"Nothing to resume from, training from scratch \\n\\t-> {e}\")\n",
    "\n",
    "        log.info(f\"lr: \\t\\t{optimiser.param_groups[0]['lr']}\")\n",
    "        log.info(f\"weight_decay: \\t{optimiser.param_groups[0]['weight_decay']}\")\n",
    "        trn_epoch_losses, val_epoch_losses, stopped_early = train_model(model=model,\n",
    "                                                   optimiser=optimiser,\n",
    "                                                   loaders=loaders,\n",
    "                                                   train_epoch_fn=train_epoch_fn,\n",
    "                                                   loss_fn=loss_function,\n",
    "                                                   conf=conf)    \n",
    "\n",
    "        print(f\"stopped_early: {stopped_early}\") # use the current epoch instead\n",
    "        # if stopped_early -> continue with best_model - new hyper-parameters -> no n \n",
    "\n",
    "        # Load latest or best validation model\n",
    "        # conf.checkpoint = \"latest\"\n",
    "        conf.checkpoint = \"best\"\n",
    "\n",
    "        log.info(f\"Loading model from checkpoint ({conf.checkpoint}) for evaluation\")\n",
    "\n",
    "        # resume from previous check point or resume from best validaton score checkpoint\n",
    "        # load model state\n",
    "        model_state_dict = torch.load(f\"{conf.model_path}model_{conf.checkpoint}.pth\",\n",
    "                                        map_location=conf.device.type)\n",
    "        model.load_state_dict(model_state_dict)\n",
    "\n",
    "        trn_y_counts, trn_y_true, trn_probas_pred, trn_t_range = evaluate_fn(model=model,\n",
    "                                                                                   batch_loader=loaders.train_loader,\n",
    "                                                                                   conf=conf) \n",
    "        thresh = best_threshold(trn_y_true, trn_probas_pred) \n",
    "\n",
    "        tst_y_counts, tst_y_true, tst_probas_pred, tst_t_range = evaluate_fn(model=model,\n",
    "                                                                   batch_loader=loaders.test_loader,\n",
    "                                                                   conf=conf)\n",
    "\n",
    "\n",
    "        tst_y_true = np.expand_dims(tst_y_true, axis=1)\n",
    "        tst_probas_pred = np.expand_dims(tst_probas_pred, axis=1) \n",
    "\n",
    "        tst_y_true = data_group.shaper.squeeze(tst_y_true)\n",
    "        tst_probas_pred = data_group.shaper.squeeze(tst_probas_pred)\n",
    "\n",
    "\n",
    "        tst_y_pred = get_y_pred(thresh, tst_probas_pred)\n",
    "        save_metrics(y_true=tst_y_true,\n",
    "                     y_pred=tst_y_pred,\n",
    "                     probas_pred=tst_probas_pred,\n",
    "                     t_range=tst_t_range,\n",
    "                     shaper=data_group.shaper,                \n",
    "                     conf=conf)\n",
    "        compare_models(data_path=conf.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0u1dNxGfb8fv"
   },
   "outputs": [],
   "source": [
    "for data_sub_path in get_data_sub_paths():\n",
    "    log.info(f\"{data_sub_path}\\n\")\n",
    "    data_path = f\"./data/processed/{data_sub_path}/\"\n",
    "\n",
    "    models_metrics = get_models_metrics(data_path)\n",
    "    metrics_table = get_metrics_table(models_metrics)\n",
    "    print(metrics_table)\n",
    "    print(\"\\n===================================================================================================\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "run_resnet_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
