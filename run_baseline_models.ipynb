{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# note: do evaluation in (N,C,L) format, this way the accuracy is better reflected, and we still get stel predictions over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: historic average and need a map of time step to historic step...\n",
    "- ### The number of hours of the division should give an indication of cell plot scales \n",
    "- ### Separate model results and model metrics: allows for less disc space being used\n",
    "\n",
    "\n",
    "### What will have more weight false positive or false negative? Obviously false positive is a lot more important. Intuitively put, recisions measures to how many of our class guesses did we waste, where as recall measures how many of the actual occurrences did we catch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging as log\n",
    "from time import strftime\n",
    "from copy import deepcopy\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from utils.data_processing import *\n",
    "from logger.logger import setup_logging\n",
    "from utils.configs import BaseConf\n",
    "from utils.utils import write_json, Timer\n",
    "from models.kangkang_fnn_models import KangFeedForwardNetwork\n",
    "from dataloaders.flat_loader import FlatDataLoaders\n",
    "from datasets.flat_dataset import FlatDataGroup, BaseDataGroup\n",
    "from utils.plots import DistributionPlotter\n",
    "from utils.metrics import PRCurvePlotter, ROCCurvePlotter, LossPlotter, CellPlotter\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from utils.mock_data import mock_data\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.plots import im\n",
    "from utils.metrics import best_threshold, get_y_pred\n",
    "from models.model_result import ModelResult\n",
    "from models.baseline_models import ExponentialMovingAverage,\\\n",
    "                UniformMovingAverage, TriangularMovingAverage, HistoricAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T6H-X850M-Y880M',\n",
       " 'T24H-X85M-Y110M',\n",
       " 'T24H-X850M-Y880M',\n",
       " 'T24H-X425M-Y440M',\n",
       " 'T12H-X850M-Y880M',\n",
       " 'T1H-X1700M-Y1760M',\n",
       " 'T3H-X850M-Y880M']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./data/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo add to utils\n",
    "def get_time_step_from_data_folder(folder_name):\n",
    "    \"\"\"\n",
    "    Also used to get the window on the cell plots\n",
    "    \"\"\"\n",
    "    i = folder_name.find(\"H\")\n",
    "    if i < 0:\n",
    "        return None\n",
    "    return int(folder_name[1:i])\n",
    "\n",
    "def get_historic_step_from_time_step(time_step):\n",
    "    if time_step:\n",
    "        return int(24/time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_dict = {\n",
    "    \"seed\": 3,\n",
    "    \"use_cuda\": False,\n",
    "    \n",
    "    \"use_crime_types\": False,\n",
    "    \n",
    "    # data group/data set related\n",
    "    \"val_ratio\": 0.1,  # ratio of the total dataset\n",
    "    \"tst_ratio\": 0.2,# ratio of the total dataset\n",
    "    \"seq_len\": 0,\n",
    "    \"flatten_grid\": True,  # if the shaper should be used to squeeze the data\n",
    "    \n",
    "    # shaper related \n",
    "    \"shaper_top_k\": -1,  # if less then 0, top_k will not be applied\n",
    "    \"shaper_threshold\": 0,\n",
    "\n",
    "    \n",
    "    # data loader related\n",
    "    \"sub_sample_train_set\": True,\n",
    "    \"sub_sample_validation_set\": True,\n",
    "    \"sub_sample_test_set\": False,\n",
    "    \n",
    "    # training parameters\n",
    "    \"resume\": False,\n",
    "    \"early_stopping\": False,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-8,\n",
    "    \"max_epochs\": 1,\n",
    "    \"batch_size\": 64,\n",
    "    \"dropout\": 0,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 6,\n",
    "}\n",
    "\n",
    "conf = BaseConf(conf_dict)\n",
    "\n",
    "\n",
    "# data_dim_str = 'T6H-X850M-Y880M'\n",
    "# data_dim_str = 'T24H-X85M-Y110M'\n",
    "data_dim_str = 'T24H-X850M-Y880M'\n",
    "# data_dim_str = 'T24H-X425M-Y440M'\n",
    "# data_dim_str = 'T12H-X850M-Y880M'\n",
    "# data_dim_str = 'T3H-X850M-Y880M'\n",
    "# data_dim_str = 'T1H-X1700M-Y1760M'\n",
    "\n",
    "data_path = f\"./data/processed/{data_dim_str}/\"\n",
    "os.makedirs(data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the model_results - just save targets and probas_pred - the predictions should be handled by a function,\n",
    "for example getting the best_threshold per cell and then getting the y_pred - hard classifications.\n",
    "\n",
    "this allows that the format of the results are in the correct order. Be bold, work constantly. Try new things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im(data=crimes[:,0].mean(0),figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 11, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.preprocessing import Shaper\n",
    "\n",
    "\n",
    "with np.load(data_path + \"generated_data.npz\") as zip_file:\n",
    "    t_range = pd.read_pickle(data_path + \"t_range.pkl\")\n",
    "    log.info(f\"\\tt_range shape {np.shape(t_range)}\")\n",
    "\n",
    "    if conf.use_crime_types:\n",
    "        crimes = zip_file[\"crime_types_grids\"]\n",
    "    else:\n",
    "        crimes = zip_file[\"crime_grids\"]\n",
    "\n",
    "conf.shaper_threshold = 0\n",
    "conf.shaper_top_k = 100\n",
    "\n",
    "shaper = Shaper(data=crimes,\n",
    "                threshold=conf.shaper_threshold,\n",
    "                top_k=conf.shaper_top_k)\n",
    "\n",
    "crimes_ = shaper.squeeze(crimes)\n",
    "crimes_.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.shaper_threshold = 0\n",
    "conf.shaper_top_k = -1\n",
    "data_group = FlatDataGroup(data_path=data_path, conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize the cells that we are dropping\n",
    "conf.shaper_threshold = 0\n",
    "conf.shaper_top_k = -1\n",
    "\n",
    "for i in [-1]:\n",
    "    conf.shaper_top_k = i\n",
    "    data_group = FlatDataGroup(data_path=data_path, conf=conf)\n",
    "    print(f\"threshold = {i}, {data_group.targets.shape}\")\n",
    "    vals, counts = np.unique(data_group.targets,return_counts=True)\n",
    "    counts = counts/np.sum(counts)\n",
    "    dist = dict(zip(vals,counts))\n",
    "    print(dist)\n",
    "    \n",
    "    sorted_indices = data_group.sorted_indices\n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(data_group.shaper.unsqueeze(data_group.crimes)[:,0].mean(0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_reg: 1.0\n",
      "dummy (stratified): 0.56\n",
      "dummy (most_frequent): 0.54\n",
      "dummy (prior): 0.54\n",
      "dummy (uniform): 0.54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "dummy = DummyClassifier(strategy='prior')\n",
    "dummy.fit(X,y)\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X,y)\n",
    "\n",
    "print(\"log_reg:\",accuracy_score(y, lr.predict_proba(X)[:,1].round()))\n",
    "\n",
    "for strat in ['stratified', 'most_frequent', 'prior', 'uniform']:\n",
    "    dummy = DummyClassifier(strategy=strat)\n",
    "    dummy.fit(X,y)\n",
    "    print(f\"dummy ({strat}):\",accuracy_score(y, dummy.predict_proba(X)[:,1].round()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get mean model as the starting position.\n",
    "then train with only the new values to see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group.crimes[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                         multi_class='multinomial')\n",
    "\n",
    "clf..fit(X, y)\n",
    "clf.predict(X[:2, :])\n",
    "clf.predict_proba(X[:2, :]) \n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "X = data_group.crimes[:400,0,data_group.sorted_indices]\n",
    "aspect = X.shape[1]/X.shape[0]\n",
    "\n",
    "plt.imshow(X=X,aspect=aspect,cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hawkes models incorporate the mean and the self exciting variables - when we train each cell on the data and \n",
    "l(k) = u + wet-t-1 - save the parameters in a grid and plot. Should show us how much the thing is influence.\n",
    "Espetially the ratio between the average and the actual excitation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Historic average model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = get_historic_step_from_time_step(get_time_step_from_data_folder(data_dim_str))\n",
    "print(f\"using time step: {time_step}\")\n",
    "\n",
    "ha = HistoricAverage(step=time_step)\n",
    "all_crimes = data_group.crimes[:,0]\n",
    "all_targets = data_group.targets\n",
    "tst_targets = data_group.testing_set.targets\n",
    "all_crimes_ha = ha(all_crimes)  # todo re-write using the convolve function - it loses the \n",
    "tst_crimes_ha = all_crimes_ha[-len(tst_targets):]\n",
    "trn_crimes_ha = all_crimes_ha[time_step+1:len(tst_targets)] # skip all the nan values\n",
    "trn_targets = all_targets[time_step+1:len(tst_targets)]\n",
    "\n",
    "\n",
    "\n",
    "N,L = tst_targets.shape\n",
    "\n",
    "\n",
    "y_true = tst_targets\n",
    "probas_pred = tst_crimes_ha\n",
    "thresh = best_threshold(y_true, probas_pred)\n",
    "y_pred = get_y_pred(thresh, probas_pred)  # might want to do this for each cell either?\n",
    "\n",
    "# alternatively - might want to do this for each cell either?\n",
    "# thresholds_ha = []\n",
    "# y_pred = np.empty_like(y_true)\n",
    "# for i in range(L):\n",
    "#     # important note thresh should eb for the training data\n",
    "#     thresh = best_threshold(y_true=trn_targets[:,i],probas_pred=trn_crimes_ha[:,i], verbose=False)  \n",
    "#     thresholds_ha.append(thresh)\n",
    "#     y_pred[:,i] = get_y_pred(thresh, probas_pred[:,i])\n",
    "    \n",
    "ha_model_result = ModelResult(model_name=f\"HA One Thresh {time_step}\",\n",
    "                                y_true=y_true.flatten(),\n",
    "                                y_pred=y_pred.flatten(),\n",
    "                                probas_pred=probas_pred.flatten(),\n",
    "                                t_range=data_group.testing_set.t_range,\n",
    "                                shaper=data_group.shaper)\n",
    "\n",
    "model_results.append(ha_model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean of training data as future prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of training data as future prediction\n",
    "trn_crimes = data_group.training_set.crimes\n",
    "\n",
    "# only get the mean of the trn_set\n",
    "crimes_mean = np.mean(trn_crimes[:,0],axis=0,keepdims=True)  # keep dims used to make scalar product easy\n",
    "crimes_ones = np.ones_like(data_group.testing_set.targets)\n",
    "y_pred_sparse = crimes_mean*crimes_ones\n",
    "tst_targets = data_group.testing_set.targets\n",
    "\n",
    "N,L = tst_targets.shape\n",
    "targets_shape = N,L\n",
    "\n",
    "\n",
    "y_pred_dense = y_pred_sparse\n",
    "\n",
    "probas_pred = y_pred_dense.flatten()\n",
    "y_true = tst_targets.flatten()\n",
    "thresh = best_threshold(y_true, probas_pred)\n",
    "y_pred = np.copy(probas_pred)\n",
    "y_pred[y_pred >= thresh] = 1\n",
    "y_pred[y_pred < thresh] = 0\n",
    "\n",
    "mean_model_result = ModelResult(model_name=\"Train Mean\",\n",
    "                                y_true=y_true,\n",
    "                                y_pred=y_pred,\n",
    "                                probas_pred=probas_pred,\n",
    "                                t_range=data_group.testing_set.t_range,\n",
    "                                shaper=data_group.shaper)\n",
    "\n",
    "model_results.append(mean_model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rolling mean of all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window_len in [time_step*7]:\n",
    "    for alpha in [1e1, 1e2,1e-1]:\n",
    "        ma = ExponentialMovingAverage(alpha=alpha,window_len=window_len)\n",
    "        all_crimes = data_group.crimes[:,0]\n",
    "        tst_targets = data_group.testing_set.targets\n",
    "        all_crimes_ma = ma(all_crimes)\n",
    "        tst_crimes_ma = all_crimes_ma[-len(tst_targets):]\n",
    "\n",
    "        N,L = tst_targets.shape\n",
    "        targets_shape = N,L\n",
    "\n",
    "        targets_dense = tst_targets\n",
    "\n",
    "        y_pred_dense = tst_crimes_ma\n",
    "\n",
    "        probas_pred = y_pred_dense.flatten()\n",
    "        y_true = targets_dense.flatten()\n",
    "\n",
    "        thresh = best_threshold(y_true, probas_pred)\n",
    "        y_pred = np.copy(probas_pred)\n",
    "        y_pred[y_pred >= thresh] = 1\n",
    "        y_pred[y_pred < thresh] = 0\n",
    "\n",
    "        ma_model_result = ModelResult(model_name=f\"EMA window={window_len}, alpha={alpha}\",\n",
    "                                        y_true=y_true,\n",
    "                                        y_pred=y_pred,\n",
    "                                        probas_pred=probas_pred,\n",
    "                                        t_range=data_group.testing_set.t_range,\n",
    "                                        shaper=data_group.shaper)\n",
    "\n",
    "        model_results.append(ma_model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding random noise to the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_std in [0.4,0.8]:\n",
    "    tst_crimes = data_group.testing_set.targets  # only mask the targets as the outputs\n",
    "\n",
    "\n",
    "    noise = noise_std*np.random.randn(*np.shape(tst_crimes))\n",
    "    # should be a flip seeing that the class distribution is so skew\n",
    "\n",
    "    y_pred_sparse = tst_crimes + noise\n",
    "    targets_dense = data_group.testing_set.targets\n",
    "    y_pred_dense = y_pred_sparse\n",
    "\n",
    "    probas_pred = y_pred_dense.flatten()\n",
    "    \n",
    "    N,L = targets_dense.shape\n",
    "    targets_shape = N,L\n",
    "    \n",
    "    y_true = targets_dense.flatten()\n",
    "    thresh = best_threshold(y_true, probas_pred)\n",
    "    y_pred = np.copy(probas_pred)\n",
    "    y_pred[y_pred >= thresh] = 1\n",
    "    y_pred[y_pred < thresh] = 0\n",
    "\n",
    "    noise_model_result = ModelResult(model_name=f\"Noise model std={noise_std}\",\n",
    "                                    y_true=y_true,\n",
    "                                    y_pred=y_pred,\n",
    "                                    probas_pred=probas_pred,\n",
    "                                    t_range=data_group.testing_set.t_range,\n",
    "                                     shaper=data_group.shaper)\n",
    "\n",
    "    model_results.append(noise_model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for result in model_results:\n",
    "    print(result)\n",
    "\n",
    "pr_plotter = PRCurvePlotter()\n",
    "for result in model_results:\n",
    "    pr_plotter.add_curve(result.y_true, result.probas_pred, label_name=result.model_name)\n",
    "pr_plotter.show()\n",
    "# pr_plotter.savefig(model_path + \"plot_pr_curve.png\")\n",
    "\n",
    "roc_plotter = ROCCurvePlotter()\n",
    "for result in model_results:\n",
    "    roc_plotter.add_curve(result.y_true, result.probas_pred, label_name=result.model_name)\n",
    "roc_plotter.show()\n",
    "# roc_plotter.savefig(model_path + \"plot_roc_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo create function do unflatten y_true, y_probs, and probas_true\n",
    "# use shape of the model and just rnp.reshape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Hawkes Model](https://x-datainitiative.github.io/tick/modules/generated/tick.hawkes.HawkesSumExpKern.html)\n",
    "does support multi variate but we are only using univariate for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis Hawks-proces using the EM kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo get average using convolutions given the kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tick.plot import plot_hawkes_kernels\n",
    "from tick.hawkes import SimuHawkesSumExpKernels, SimuHawkesMulti, \\\n",
    "    HawkesSumExpKern, HawkesEM\n",
    "\n",
    "\n",
    "class IndHawkesModel:\n",
    "    \"\"\"\n",
    "    Indipendent Hawkes Modles where all cells are indipendent\n",
    "    \n",
    "    Using Tikc library from:\n",
    "    - https://x-datainitiative.github.io/tick/modules/generated/tick.hawkes.HawkesSumExpKern.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.baselines = []   \n",
    "        self.kernels = []\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        data: (N,L)\n",
    "        \"\"\"\n",
    "        N, L = data.shape\n",
    "        self.baselines = []\n",
    "        self.kernels = []\n",
    "\n",
    "        # convert into format for the hawkes trainer\n",
    "        for i in range(L):\n",
    "            realizations = []\n",
    "            data_counts = data[:,i]\n",
    "            time_stamps = np.argwhere(data_counts).astype(np.float)\n",
    "            realizations.append([time_stamps[:,0]])\n",
    "\n",
    "            # kernel_discretization if set explicitly it overrides kernel_support and kernel_size\n",
    "            # todo: have kernel values be set by conf_dict\n",
    "            em = HawkesEM(kernel_discretization=np.arange(self.kernel_size).astype(np.float),\n",
    "                          n_threads=8,\n",
    "                          verbose=False,\n",
    "                          tol=1e-3,\n",
    "                          max_iter=1000)\n",
    "            em.fit(realizations)\n",
    "            baseline = em.baseline.flatten()[0]\n",
    "            kernel = em.kernel.flatten()\n",
    "            self.baselines.append(baseline)\n",
    "            self.kernels.append(kernel)\n",
    "\n",
    "        \n",
    "    def transform(self, data):\n",
    "        # todo consider training saving a kernel AND baseline for each cell\n",
    "        # kernels -> (N,L,kernel_size)\n",
    "        # baselines -> (N,L,1)\n",
    "        N,L = np.shape(data)\n",
    "        result = np.empty_like(data)\n",
    "        for i in range(L):    \n",
    "            result[:,i] = self.baselines[i] + np.convolve(data[:,i],self.kernels[i])[:N]\n",
    "        return result\n",
    "    \n",
    "    def fit_transform(self,data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_inpt = data_group.training_set.crimes[:,0]\n",
    "trn_trg = data_group.training_set.targets\n",
    "\n",
    "tst_inpt = data_group.testing_set.crimes[:,0]\n",
    "tst_trg = data_group.testing_set.targets\n",
    "\n",
    "\n",
    "N,L = np.shape(trn_inpt)\n",
    "\n",
    "model = IndHawkesModel(kernel_size=time_step*21 + 1)\n",
    "trn_out = model.fit_transform(trn_inpt)\n",
    "tst_out = model.transform(tst_inpt)\n",
    "\n",
    "y_true = tst_trg\n",
    "probas_pred = tst_out\n",
    "thresh = best_threshold(y_true, probas_pred)\n",
    "y_pred = get_y_pred(thresh, probas_pred)  # might want to do this for each cell either?\n",
    "\n",
    "hawkes_ind_model = ModelResult(model_name=f\"Hawkes Independent Cells\",\n",
    "                                y_true=y_true.flatten(),\n",
    "                                y_pred=y_pred.flatten(),\n",
    "                                probas_pred=probas_pred.flatten(),\n",
    "                                t_range=data_group.testing_set.t_range,\n",
    "                               shaper=data_group.shaper)\n",
    "\n",
    "model_results.append(hawkes_ind_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = np.array(model.kernels)\n",
    "kernel_mean = np.mean(kernels,0)\n",
    "kernel_std = np.std(kernels,0)\n",
    "plt.plot(kernel_mean,alpha=.4)\n",
    "\n",
    "x = np.concatenate([np.arange(len(kernel_mean)),np.arange(len(kernel_mean))[::-1]])\n",
    "y = np.concatenate([kernel_mean-1.5*kernel_std,np.array(kernel_mean+1.5*kernel_std)[::-1]])\n",
    "plt.fill(x,y,alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HawkesModelGeneral:\n",
    "    \"\"\"\n",
    "    Using the HawkesEM learner from Tick library\n",
    "    \n",
    "    Using Tikc library from:\n",
    "    - https://x-datainitiative.github.io/tick/modules/generated/tick.hawkes.HawkesSumExpKern.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.kernel = None\n",
    "        self.baseline = None\n",
    "        self.em = None  \n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        data: (N,L)\n",
    "        \"\"\"\n",
    "        N, L = data.shape\n",
    "\n",
    "        # convert into format for the hawkes trainer\n",
    "        realizations = []\n",
    "        for i in range(L):\n",
    "            data_counts = data[:,i]\n",
    "            time_stamps = np.argwhere(data_counts).astype(np.float)\n",
    "        realizations.append([time_stamps[:,0]])\n",
    "\n",
    "        # kernel_discretization if set explicitly it overrides kernel_support and kernel_size\n",
    "        # todo: have kernel values be set by conf_dict\n",
    "        self.em = HawkesEM(kernel_discretization=np.arange(self.kernel_size).astype(np.float),\n",
    "                      n_threads=8,\n",
    "                      verbose=False,\n",
    "                      tol=1e-3,\n",
    "                      max_iter=1000)\n",
    "        self.em.fit(realizations)\n",
    "        self.baseline = self.em.baseline.flatten()[0]\n",
    "        self.kernel = self.em.kernel.flatten()\n",
    "\n",
    "        \n",
    "    def transform(self, data):\n",
    "        # todo consider training saving a kernel AND baseline for each cell\n",
    "        # kernels -> (N,L,kernel_size)\n",
    "        # baselines -> (N,L,1)\n",
    "        N,L = np.shape(data)\n",
    "        result = np.empty_like(data)\n",
    "        for i in range(L):    \n",
    "            result[:,i] = self.baseline + np.convolve(data[:,i],self.kernel)[:N]\n",
    "        return result\n",
    "    \n",
    "    def fit_transform(self,data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "    \n",
    "    def plot_kernel(self):\n",
    "        plot_hawkes_kernels(self.em, hawkes=None, show=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_inpt = data_group.training_set.crimes[:,0]\n",
    "trn_trg = data_group.training_set.targets\n",
    "\n",
    "tst_inpt = data_group.testing_set.crimes[:,0]\n",
    "tst_trg = data_group.testing_set.targets\n",
    "\n",
    "\n",
    "N,L = np.shape(trn_inpt)\n",
    "\n",
    "model = HawkesModelGeneral(kernel_size=time_step*20 + 1)\n",
    "trn_out = model.fit_transform(trn_inpt)\n",
    "tst_out = model.transform(tst_inpt)\n",
    "\n",
    "y_true = tst_trg\n",
    "probas_pred = tst_out\n",
    "thresh = best_threshold(y_true, probas_pred)\n",
    "y_pred = get_y_pred(thresh, probas_pred)  # might want to do this for each cell either?\n",
    "\n",
    "hawkes_general_model = ModelResult(model_name=f\"Hawkes General Model\",\n",
    "                                y_true=y_true.flatten(),\n",
    "                                y_pred=y_pred.flatten(),\n",
    "                                probas_pred=probas_pred.flatten(),\n",
    "                                t_range=data_group.testing_set.t_range,\n",
    "                                   shaper=data_group.shaper)\n",
    "\n",
    "model_results.append(hawkes_general_model)\n",
    "\n",
    "plt.plot(model.kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try and get cosine similarity between the kernels and baselines - should give a good indicaiton if we can compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISSUE: is that we have some cells where no crime takes place - in either the testing or the training set\n",
    "### thougths - look for data where to ranking of the cells actually changes with time - this will indicate how much crime actaully moves arround over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trn_inpt = data_group.training_set.crimes[:,0]\n",
    "trn_trg = data_group.training_set.targets\n",
    "\n",
    "tst_inpt = data_group.testing_set.crimes[:,0]\n",
    "tst_trg = data_group.testing_set.targets\n",
    "\n",
    "\n",
    "N,L = np.shape(trn_inpt)\n",
    "\n",
    "model = IndHawkesModel(kernel_size=time_step*3 + 1)\n",
    "trn_out = model.fit_transform(trn_inpt)\n",
    "tst_out = model.transform(tst_inpt)\n",
    "\n",
    "limit = 200\n",
    "top_k = 10\n",
    "i = 3000\n",
    "\n",
    "\n",
    "# todo check how this influences the ROC and PR curves\n",
    "def i2p(intensity):\n",
    "    \"\"\"\n",
    "    intensity to probability\n",
    "    \"\"\"\n",
    "    return 1 - np.exp(-1*intensity)\n",
    "    \n",
    "       \n",
    "for i in range(top_k):\n",
    "    for j in range(2):\n",
    "        print(f\"-------------------------------{j}----------------------------------\")\n",
    "        plt.figure(figsize=(10,2))\n",
    "        plt.plot(tst_trg[i:i+limit,i])\n",
    "\n",
    "        y_true = tst_trg[:,i]\n",
    "        if j == 0:\n",
    "            probas_pred = i2p(tst_out[:,i])\n",
    "        else:     \n",
    "            probas_pred = tst_out[:,i]\n",
    "\n",
    "        thresh = best_threshold(y_true, probas_pred)\n",
    "        y_pred = np.copy(probas_pred)\n",
    "        y_pred[y_pred >= thresh] = 1\n",
    "        y_pred[y_pred < thresh] = 0\n",
    "\n",
    "        print(classification_report(y_true=y_true,y_pred=y_pred))\n",
    "\n",
    "        plt.plot(y_pred[i:i+limit])\n",
    "        plt.plot(probas_pred[i:i+limit])\n",
    "    #     plt.ylim([0,1])\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"------------------------------------------------------------------\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,4,100))\n",
    "plt.plot(i2p(np.linspace(0,4,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for realization in realizations[:5]:#multi.timestamps:\n",
    "    plt.figure(figsize=(10,1))\n",
    "    for var in realization:\n",
    "        plt.scatter(var, np.ones_like(var), alpha=.2, marker=\"|\")    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
