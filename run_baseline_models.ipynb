{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# note: do evaluation in (N,C,L) format, this way the accuracy is better reflected, and we still get stel predictions over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: historic average and need a map of time step to historic step...\n",
    "- ### The number of hours of the division should give an indication of cell plot scales \n",
    "- ### Separate model results and model metrics: allows for less disc space being used\n",
    "\n",
    "\n",
    "### What will have more weight false positive or false negative? Obviously false positive is a lot more important. Intuitively put, recisions measures to how many of our class guesses did we waste, where as recall measures how many of the actual occurrences did we catch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging as log\n",
    "from time import strftime\n",
    "from copy import deepcopy\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from utils.data_processing import *\n",
    "from logger.logger import setup_logging\n",
    "from utils.configs import BaseConf\n",
    "from utils.utils import write_json, Timer\n",
    "from models.kangkang_fnn_models import KangFeedForwardNetwork\n",
    "from dataloaders.flat_loader import FlatDataLoaders\n",
    "from datasets.flat_dataset import FlatDataGroup, BaseDataGroup\n",
    "from utils.plots import DistributionPlotter\n",
    "from utils.metrics import PRCurvePlotter, ROCCurvePlotter, LossPlotter, CellPlotter\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.plots import im\n",
    "from utils.metrics import best_threshold, get_y_pred\n",
    "from models.model_result import ModelResult\n",
    "from models.baseline_models import ExponentialMovingAverage,\\\n",
    "                UniformMovingAverage, TriangularMovingAverage, HistoricAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T6H-X850M-Y880M',\n",
       " 'T24H-X85M-Y110M',\n",
       " 'T24H-X850M-Y880M',\n",
       " 'T24H-X425M-Y440M',\n",
       " 'T12H-X850M-Y880M',\n",
       " 'T1H-X1700M-Y1760M',\n",
       " 'T3H-X850M-Y880M']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./data/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo add to utils\n",
    "def get_time_step_from_data_folder(folder_name):\n",
    "    \"\"\"\n",
    "    Also used to get the window on the cell plots\n",
    "    \"\"\"\n",
    "    i = folder_name.find(\"H\")\n",
    "    if i < 0:\n",
    "        return None\n",
    "    return int(folder_name[1:i])\n",
    "\n",
    "def get_historic_step_from_time_step(time_step):\n",
    "    if time_step:\n",
    "        return int(24/time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_dict = {\n",
    "    \"seed\": 3,\n",
    "    \"use_cuda\": False,\n",
    "    \n",
    "    \"use_crime_types\": True,\n",
    "    \n",
    "    # data related hyper-params\n",
    "    \"val_ratio\": 0.1,  # ratio of the total dataset\n",
    "    \"tst_ratio\": 0.2,# ratio of the total dataset\n",
    "    \"sub_sample_train_set\": True,\n",
    "    \"sub_sample_validation_set\": True,\n",
    "    \"sub_sample_test_set\": False,\n",
    "    \"flatten_grid\": True,  # if the shaper should be used to squeeze the data\n",
    "    \"seq_len\": 1,\n",
    "    \"shaper_top_k\": -1,  # if less then 0, top_k will not be applied\n",
    "    \"shaper_threshold\": 0,\n",
    "    \n",
    "    # training parameters\n",
    "    \"resume\": False,\n",
    "    \"early_stopping\": False,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-8,\n",
    "    \"max_epochs\": 1,\n",
    "    \"batch_size\": 64,\n",
    "    \"dropout\": 0,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 6,\n",
    "}\n",
    "\n",
    "conf = BaseConf(conf_dict)\n",
    "\n",
    "\n",
    "# data_dim_str = 'T6H-X850M-Y880M'\n",
    "data_dim_str = 'T24H-X85M-Y110M'\n",
    "# data_dim_str = 'T24H-X850M-Y880M'\n",
    "# data_dim_str = 'T24H-X425M-Y440M'\n",
    "# data_dim_str = 'T12H-X850M-Y880M'\n",
    "# data_dim_str = 'T3H-X850M-Y880M'\n",
    "# data_dim_str = 'T1H-X1700M-Y1760M'\n",
    "\n",
    "data_path = f\"./data/processed/{data_dim_str}/\"\n",
    "os.makedirs(data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crime_feature_indices', 'crime_types_grids', 'crime_grids', 'demog_grid', 'street_grid', 'time_vectors', 'weather_vectors', 'x_range', 'y_range']\n",
      "0 0.0018770694732666016\n",
      "1 11.558954000473022\n",
      "2 11.847982168197632\n",
      "3 11.84822392463684\n",
      "success: False\n",
      "crimes_og: (365, 11, 379, 323)\n",
      "crimes_dense: (365, 11, 379, 323)\n",
      "crimes_flat: (365, 11, 0)\n",
      "f: 17.927111864089966\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocessing import Shaper\n",
    "from utils.utils import timeit\n",
    "from time import time\n",
    "@timeit\n",
    "def f():\n",
    "    t = time()\n",
    "    top_percent = 50\n",
    "    top_k = int(31690*top_percent/100)\n",
    "\n",
    "    conf.shaper_threshold = 10\n",
    "    conf.shaper_top_k = top_k#-1\n",
    "\n",
    "    zip_file = np.load(data_path + \"generated_data.npz\")  # loading takes 11 secods\n",
    "    print(zip_file.files)\n",
    "    print(f\"0 {time() - t}\")\n",
    "    crimes_og = zip_file[\"crime_types_grids\"]#[:,0]\n",
    "\n",
    "\n",
    "    print(f\"1 {time() - t}\")\n",
    "    shaper = Shaper(data=crimes_og[:,0:1],\n",
    "                         threshold=conf.shaper_threshold,\n",
    "                         top_k=conf.shaper_top_k)\n",
    "\n",
    "    print(f\"2 {time() - t}\")\n",
    "    crimes_flat = shaper.squeeze(crimes_og)\n",
    "    print(f\"3 {time() - t}\")\n",
    "\n",
    "    crimes_dense = shaper.unsqueeze(crimes_flat)  # squeezing takes a lot - thus to mimimize loading time we need separate datas\n",
    "    print(\"success:\",np.array_equal(crimes_og,crimes_dense))\n",
    "    print(\"crimes_og:\",crimes_og.shape)\n",
    "    print(\"crimes_dense:\",crimes_dense.shape)\n",
    "    print(\"crimes_flat:\",crimes_flat.shape)\n",
    "    \n",
    "f()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showmean(data):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(np.mean(data[:,0],0),aspect=1,cmap='Reds')\n",
    "    plt.show()\n",
    "    \n",
    "def show(fn, *args):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.imshow(fn(args[0][:,0],0),aspect=1,cmap='Reds')\n",
    "    plt.colorbar()    \n",
    "    plt.show()        \n",
    "    \n",
    "def showmax(data):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(np.max(data[:,0],0),aspect=1,cmap='Reds')\n",
    "    plt.colorbar()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np.array([1,3,4,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = result of the test data - save the shaper too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crimes_dense[crimes_dense > 1] = 1\n",
    "crimes_og[crimes_og > 1] = 1\n",
    "\n",
    "show(np.sum, crimes_og, 0)\n",
    "show(np.sum, crimes_dense, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes = zip_file[\"crime_grids\"]#[:,0]\n",
    "# crimes = np.log2(1 + crimes)\n",
    "targets = np.copy(crimes[1:])\n",
    "crimes = crimes[:-1]\n",
    "targets[targets > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,h = np.unique(crimes.flatten(),return_counts=True)\n",
    "h = h/np.sum(h)*100\n",
    "plt.bar(x,h)\n",
    "plt.ylim([0,100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(crimes.mean(0),aspect=1,cmap='hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can't use the squeezer if we use the top_k_cells - rather have a function to just filter out the top k ones\n",
    "\n",
    "`top_k_mask = indices[:top_k]`\n",
    "\n",
    "also: for the model_results - just save targets and probas_pred - the predictions should be handled by a function,\n",
    "for example getting the best_threshold per cell and then getting the y_pred - hard classifications.\n",
    "\n",
    "this allows that the format of the results are in the correct order. Be bold, work constantly. Try new things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize the cells that we are dropping\n",
    "top_percent = 50\n",
    "top_k = int(31690*top_percent/100)\n",
    "\n",
    "conf.shaper_threshold = 10\n",
    "conf.shaper_top_k = top_k#-1\n",
    "\n",
    "for i in [-1,top_k]:\n",
    "    conf.shaper_top_k = i\n",
    "    data_group = FlatDataGroup(data_path=data_path, conf=conf)\n",
    "    print(f\"threshold = {i}, {data_group.targets.shape}\")\n",
    "    vals, counts = np.unique(data_group.targets,return_counts=True)\n",
    "    counts = counts/np.sum(counts)\n",
    "    dist = dict(zip(vals,counts))\n",
    "    print(dist)\n",
    "    \n",
    "    sorted_indices = data_group.sorted_indices\n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(data_group.shaper.unsqueeze(data_group.crimes)[:,0].mean(0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get mean model as the starting position.\n",
    "then train with only the new values to see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group.crimes[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                         multi_class='multinomial')\n",
    "\n",
    "clf..fit(X, y)\n",
    "clf.predict(X[:2, :])\n",
    "clf.predict_proba(X[:2, :]) \n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "X = data_group.crimes[:400,0,data_group.sorted_indices]\n",
    "aspect = X.shape[1]/X.shape[0]\n",
    "\n",
    "plt.imshow(X=X,aspect=aspect,cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hawkes models incorporate the mean and the self exciting variables - when we train each cell on the data and \n",
    "l(k) = u + wet-t-1 - save the parameters in a grid and plot. Should show us how much the thing is influence.\n",
    "Espetially the ratio between the average and the actual excitation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Historic average model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = get_historic_step_from_time_step(get_time_step_from_data_folder(data_dim_str))\n",
    "print(f\"using time step: {time_step}\")\n",
    "\n",
    "ha = HistoricAverage(step=time_step)\n",
    "all_crimes = data_group.crimes[:,0]\n",
    "all_targets = data_group.targets\n",
    "tst_targets = data_group.testing_set.targets\n",
    "all_crimes_ha = ha(all_crimes)  # todo re-write using the convolve function - it loses the \n",
    "tst_crimes_ha = all_crimes_ha[-len(tst_targets):]\n",
    "trn_crimes_ha = all_crimes_ha[time_step+1:len(tst_targets)] # skip all the nan values\n",
    "trn_targets = all_targets[time_step+1:len(tst_targets)]\n",
    "\n",
    "\n",
    "\n",
    "N,L = tst_targets.shape\n",
    "\n",
    "\n",
    "y_true = tst_targets\n",
    "probas_pred = tst_crimes_ha\n",
    "thresh = best_threshold(y_true, probas_pred)\n",
    "y_pred = get_y_pred(thresh, probas_pred)  # might want to do this for each cell either?\n",
    "\n",
    "# alternatively - might want to do this for each cell either?\n",
    "# thresholds_ha = []\n",
    "# y_pred = np.empty_like(y_true)\n",
    "# for i in range(L):\n",
    "#     # important note thresh should eb for the training data\n",
    "#     thresh = best_threshold(y_true=trn_targets[:,i],probas_pred=trn_crimes_ha[:,i], verbose=False)  \n",
    "#     thresholds_ha.append(thresh)\n",
    "#     y_pred[:,i] = get_y_pred(thresh, probas_pred[:,i])\n",
    "    \n",
    "ha_model_result = ModelResult(model_name=f\"HA One Thresh {time_step}\",\n",
    "                                y_true=y_true.flatten(),\n",
    "                                y_pred=y_pred.flatten(),\n",
    "                                probas_pred=probas_pred.flatten(),\n",
    "                                t_range=data_group.testing_set.t_range)\n",
    "\n",
    "model_results.append(ha_model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean of training data as future prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of training data as future prediction\n",
    "trn_crimes = data_group.training_set.crimes\n",
    "\n",
    "# only get the mean of the trn_set\n",
    "crimes_mean = np.mean(trn_crimes[:,0],axis=0,keepdims=True)  # keep dims used to make scalar product easy\n",
    "crimes_ones = np.ones_like(data_group.testing_set.targets)\n",
    "y_pred_sparse = crimes_mean*crimes_ones\n",
    "tst_targets = data_group.testing_set.targets\n",
    "\n",
    "N,L = tst_targets.shape\n",
    "targets_shape = N,L\n",
    "\n",
    "\n",
    "y_pred_dense = y_pred_sparse\n",
    "\n",
    "probas_pred = y_pred_dense.flatten()\n",
    "y_true = tst_targets.flatten()\n",
    "thresh = best_threshold(y_true, probas_pred)\n",
    "y_pred = np.copy(probas_pred)\n",
    "y_pred[y_pred >= thresh] = 1\n",
    "y_pred[y_pred < thresh] = 0\n",
    "\n",
    "mean_model_result = ModelResult(model_name=\"Train Mean\",\n",
    "                                y_true=y_true,\n",
    "                                y_pred=y_pred,\n",
    "                                probas_pred=probas_pred,\n",
    "                                t_range=data_group.testing_set.t_range)\n",
    "\n",
    "model_results.append(mean_model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rolling mean of all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window_len in [time_step*7]:\n",
    "    for alpha in [1e1, 1e2,1e-1]:\n",
    "        ma = ExponentialMovingAverage(alpha=alpha,window_len=window_len)\n",
    "        all_crimes = data_group.crimes[:,0]\n",
    "        tst_targets = data_group.testing_set.targets\n",
    "        all_crimes_ma = ma(all_crimes)\n",
    "        tst_crimes_ma = all_crimes_ma[-len(tst_targets):]\n",
    "\n",
    "        N,L = tst_targets.shape\n",
    "        targets_shape = N,L\n",
    "\n",
    "        targets_dense = tst_targets\n",
    "\n",
    "        y_pred_dense = tst_crimes_ma\n",
    "\n",
    "        probas_pred = y_pred_dense.flatten()\n",
    "        y_true = targets_dense.flatten()\n",
    "\n",
    "        thresh = best_threshold(y_true, probas_pred)\n",
    "        y_pred = np.copy(probas_pred)\n",
    "        y_pred[y_pred >= thresh] = 1\n",
    "        y_pred[y_pred < thresh] = 0\n",
    "\n",
    "        ma_model_result = ModelResult(model_name=f\"EMA window={window_len}, alpha={alpha}\",\n",
    "                                        y_true=y_true,\n",
    "                                        y_pred=y_pred,\n",
    "                                        probas_pred=probas_pred,\n",
    "                                        t_range=data_group.testing_set.t_range)\n",
    "\n",
    "        model_results.append(ma_model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding random noise to the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_std in [0.4,0.8]:\n",
    "    tst_crimes = data_group.testing_set.targets  # only mask the targets as the outputs\n",
    "\n",
    "\n",
    "    noise = noise_std*np.random.randn(*np.shape(tst_crimes))\n",
    "    # should be a flip seeing that the class distribution is so skew\n",
    "\n",
    "    y_pred_sparse = tst_crimes + noise\n",
    "    targets_dense = data_group.testing_set.targets\n",
    "    y_pred_dense = y_pred_sparse\n",
    "\n",
    "    probas_pred = y_pred_dense.flatten()\n",
    "    \n",
    "    N,L = targets_dense.shape\n",
    "    targets_shape = N,L\n",
    "    \n",
    "    y_true = targets_dense.flatten()\n",
    "    thresh = best_threshold(y_true, probas_pred)\n",
    "    y_pred = np.copy(probas_pred)\n",
    "    y_pred[y_pred >= thresh] = 1\n",
    "    y_pred[y_pred < thresh] = 0\n",
    "\n",
    "    noise_model_result = ModelResult(model_name=f\"Noise model std={noise_std}\",\n",
    "                                    y_true=y_true,\n",
    "                                    y_pred=y_pred,\n",
    "                                    probas_pred=probas_pred,\n",
    "                                    t_range=data_group.testing_set.t_range) # shape should be targets - shape\n",
    "\n",
    "    model_results.append(noise_model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for result in model_results:\n",
    "    print(result)\n",
    "\n",
    "pr_plotter = PRCurvePlotter()\n",
    "for result in model_results:\n",
    "    pr_plotter.add_curve(result.y_true, result.probas_pred, label_name=result.model_name)\n",
    "pr_plotter.show()\n",
    "# pr_plotter.savefig(model_path + \"plot_pr_curve.png\")\n",
    "\n",
    "roc_plotter = ROCCurvePlotter()\n",
    "for result in model_results:\n",
    "    roc_plotter.add_curve(result.y_true, result.probas_pred, label_name=result.model_name)\n",
    "roc_plotter.show()\n",
    "# roc_plotter.savefig(model_path + \"plot_roc_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo create function do unflatten y_true, y_probs, and probas_true\n",
    "# use shape of the model and just rnp.reshape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Hawkes Model](https://x-datainitiative.github.io/tick/modules/generated/tick.hawkes.HawkesSumExpKern.html)\n",
    "does support multi variate but we are only using univariate for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis Hawks-proces using the EM kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo get average using convolutions given the kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tick.plot import plot_hawkes_kernels\n",
    "from tick.hawkes import SimuHawkesSumExpKernels, SimuHawkesMulti, \\\n",
    "    HawkesSumExpKern, HawkesEM\n",
    "\n",
    "\n",
    "class IndHawkesModel:\n",
    "    \"\"\"\n",
    "    Indipendent Hawkes Modles where all cells are indipendent\n",
    "    \n",
    "    Using Tikc library from:\n",
    "    - https://x-datainitiative.github.io/tick/modules/generated/tick.hawkes.HawkesSumExpKern.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.baselines = []   \n",
    "        self.kernels = []\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        data: (N,L)\n",
    "        \"\"\"\n",
    "        N, L = data.shape\n",
    "        self.baselines = []\n",
    "        self.kernels = []\n",
    "\n",
    "        # convert into format for the hawkes trainer\n",
    "        for i in range(L):\n",
    "            realizations = []\n",
    "            data_counts = data[:,i]\n",
    "            time_stamps = np.argwhere(data_counts).astype(np.float)\n",
    "            realizations.append([time_stamps[:,0]])\n",
    "\n",
    "            # kernel_discretization if set explicitly it overrides kernel_support and kernel_size\n",
    "            # todo: have kernel values be set by conf_dict\n",
    "            em = HawkesEM(kernel_discretization=np.arange(self.kernel_size).astype(np.float),\n",
    "                          n_threads=8,\n",
    "                          verbose=False,\n",
    "                          tol=1e-3,\n",
    "                          max_iter=1000)\n",
    "            em.fit(realizations)\n",
    "            baseline = em.baseline.flatten()[0]\n",
    "            kernel = em.kernel.flatten()\n",
    "            self.baselines.append(baseline)\n",
    "            self.kernels.append(kernel)\n",
    "\n",
    "        \n",
    "    def transform(self, data):\n",
    "        # todo consider training saving a kernel AND baseline for each cell\n",
    "        # kernels -> (N,L,kernel_size)\n",
    "        # baselines -> (N,L,1)\n",
    "        N,L = np.shape(data)\n",
    "        result = np.empty_like(data)\n",
    "        for i in range(L):    \n",
    "            result[:,i] = self.baselines[i] + np.convolve(data[:,i],self.kernels[i])[:N]\n",
    "        return result\n",
    "    \n",
    "    def fit_transform(self,data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_inpt = data_group.training_set.crimes[:,0]\n",
    "trn_trg = data_group.training_set.targets\n",
    "\n",
    "tst_inpt = data_group.testing_set.crimes[:,0]\n",
    "tst_trg = data_group.testing_set.targets\n",
    "\n",
    "\n",
    "N,L = np.shape(trn_inpt)\n",
    "\n",
    "model = IndHawkesModel(kernel_size=time_step*21 + 1)\n",
    "trn_out = model.fit_transform(trn_inpt)\n",
    "tst_out = model.transform(tst_inpt)\n",
    "\n",
    "y_true = tst_trg\n",
    "probas_pred = tst_out\n",
    "thresh = best_threshold(y_true, probas_pred)\n",
    "y_pred = get_y_pred(thresh, probas_pred)  # might want to do this for each cell either?\n",
    "\n",
    "hawkes_ind_model = ModelResult(model_name=f\"Hawkes Independent Cells\",\n",
    "                                y_true=y_true.flatten(),\n",
    "                                y_pred=y_pred.flatten(),\n",
    "                                probas_pred=probas_pred.flatten(),\n",
    "                                t_range=data_group.testing_set.t_range) # shape should be targets - shape\n",
    "\n",
    "model_results.append(hawkes_ind_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = np.array(model.kernels)\n",
    "kernel_mean = np.mean(kernels,0)\n",
    "kernel_std = np.std(kernels,0)\n",
    "plt.plot(kernel_mean,alpha=.4)\n",
    "\n",
    "x = np.concatenate([np.arange(len(kernel_mean)),np.arange(len(kernel_mean))[::-1]])\n",
    "y = np.concatenate([kernel_mean-1.5*kernel_std,np.array(kernel_mean+1.5*kernel_std)[::-1]])\n",
    "plt.fill(x,y,alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HawkesModelGeneral:\n",
    "    \"\"\"\n",
    "    Using the HawkesEM learner from Tick library\n",
    "    \n",
    "    Using Tikc library from:\n",
    "    - https://x-datainitiative.github.io/tick/modules/generated/tick.hawkes.HawkesSumExpKern.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.kernel = None\n",
    "        self.baseline = None\n",
    "        self.em = None  \n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        data: (N,L)\n",
    "        \"\"\"\n",
    "        N, L = data.shape\n",
    "\n",
    "        # convert into format for the hawkes trainer\n",
    "        realizations = []\n",
    "        for i in range(L):\n",
    "            data_counts = data[:,i]\n",
    "            time_stamps = np.argwhere(data_counts).astype(np.float)\n",
    "        realizations.append([time_stamps[:,0]])\n",
    "\n",
    "        # kernel_discretization if set explicitly it overrides kernel_support and kernel_size\n",
    "        # todo: have kernel values be set by conf_dict\n",
    "        self.em = HawkesEM(kernel_discretization=np.arange(self.kernel_size).astype(np.float),\n",
    "                      n_threads=8,\n",
    "                      verbose=False,\n",
    "                      tol=1e-3,\n",
    "                      max_iter=1000)\n",
    "        self.em.fit(realizations)\n",
    "        self.baseline = self.em.baseline.flatten()[0]\n",
    "        self.kernel = self.em.kernel.flatten()\n",
    "\n",
    "        \n",
    "    def transform(self, data):\n",
    "        # todo consider training saving a kernel AND baseline for each cell\n",
    "        # kernels -> (N,L,kernel_size)\n",
    "        # baselines -> (N,L,1)\n",
    "        N,L = np.shape(data)\n",
    "        result = np.empty_like(data)\n",
    "        for i in range(L):    \n",
    "            result[:,i] = self.baseline + np.convolve(data[:,i],self.kernel)[:N]\n",
    "        return result\n",
    "    \n",
    "    def fit_transform(self,data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "    \n",
    "    def plot_kernel(self):\n",
    "        plot_hawkes_kernels(self.em, hawkes=None, show=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_inpt = data_group.training_set.crimes[:,0]\n",
    "trn_trg = data_group.training_set.targets\n",
    "\n",
    "tst_inpt = data_group.testing_set.crimes[:,0]\n",
    "tst_trg = data_group.testing_set.targets\n",
    "\n",
    "\n",
    "N,L = np.shape(trn_inpt)\n",
    "\n",
    "model = HawkesModelGeneral(kernel_size=time_step*20 + 1)\n",
    "trn_out = model.fit_transform(trn_inpt)\n",
    "tst_out = model.transform(tst_inpt)\n",
    "\n",
    "y_true = tst_trg\n",
    "probas_pred = tst_out\n",
    "thresh = best_threshold(y_true, probas_pred)\n",
    "y_pred = get_y_pred(thresh, probas_pred)  # might want to do this for each cell either?\n",
    "\n",
    "hawkes_general_model = ModelResult(model_name=f\"Hawkes General Model\",\n",
    "                                y_true=y_true.flatten(),\n",
    "                                y_pred=y_pred.flatten(),\n",
    "                                probas_pred=probas_pred.flatten(),\n",
    "                                t_range=data_group.testing_set.t_range) # shape should be targets - shape\n",
    "\n",
    "model_results.append(hawkes_general_model)\n",
    "\n",
    "plt.plot(model.kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try and get cosine similarity between the kernels and baselines - should give a good indicaiton if we can compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISSUE: is that we have some cells where no crime takes place - in either the testing or the training set\n",
    "### thougths - look for data where to ranking of the cells actually changes with time - this will indicate how much crime actaully moves arround over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trn_inpt = data_group.training_set.crimes[:,0]\n",
    "trn_trg = data_group.training_set.targets\n",
    "\n",
    "tst_inpt = data_group.testing_set.crimes[:,0]\n",
    "tst_trg = data_group.testing_set.targets\n",
    "\n",
    "\n",
    "N,L = np.shape(trn_inpt)\n",
    "\n",
    "model = IndHawkesModel(kernel_size=time_step*3 + 1)\n",
    "trn_out = model.fit_transform(trn_inpt)\n",
    "tst_out = model.transform(tst_inpt)\n",
    "\n",
    "limit = 200\n",
    "top_k = 10\n",
    "i = 3000\n",
    "\n",
    "\n",
    "# todo check how this influences the ROC and PR curves\n",
    "def i2p(intensity):\n",
    "    \"\"\"\n",
    "    intensity to probability\n",
    "    \"\"\"\n",
    "    return 1 - np.exp(-1*intensity)\n",
    "    \n",
    "       \n",
    "for i in range(top_k):\n",
    "    for j in range(2):\n",
    "        print(f\"-------------------------------{j}----------------------------------\")\n",
    "        plt.figure(figsize=(10,2))\n",
    "        plt.plot(tst_trg[i:i+limit,i])\n",
    "\n",
    "        y_true = tst_trg[:,i]\n",
    "        if j == 0:\n",
    "            probas_pred = i2p(tst_out[:,i])\n",
    "        else:     \n",
    "            probas_pred = tst_out[:,i]\n",
    "\n",
    "        thresh = best_threshold(y_true, probas_pred)\n",
    "        y_pred = np.copy(probas_pred)\n",
    "        y_pred[y_pred >= thresh] = 1\n",
    "        y_pred[y_pred < thresh] = 0\n",
    "\n",
    "        print(classification_report(y_true=y_true,y_pred=y_pred))\n",
    "\n",
    "        plt.plot(y_pred[i:i+limit])\n",
    "        plt.plot(probas_pred[i:i+limit])\n",
    "    #     plt.ylim([0,1])\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"------------------------------------------------------------------\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,4,100))\n",
    "plt.plot(i2p(np.linspace(0,4,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for realization in realizations[:5]:#multi.timestamps:\n",
    "    plt.figure(figsize=(10,1))\n",
    "    for var in realization:\n",
    "        plt.scatter(var, np.ones_like(var), alpha=.2, marker=\"|\")    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
