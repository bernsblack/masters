{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# note: do evaluation in (N,C,L) format, this way the accuracy is better reflected, and we still get stel predictions over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: historic average and need a map of time step to historic step...\n",
    "- ### The number of hours of the division should give an indication of cell plot scales \n",
    "- ### Separate model results and model metrics: allows for less disc space being used\n",
    "\n",
    "\n",
    "### What will have more weight false positive or false negative? Obviously false positive is a lot more important. Intuitively put, recisions measures to how many of our class guesses did we waste, where as recall measures how many of the actual occurrences did we catch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging as log\n",
    "from time import strftime\n",
    "from copy import deepcopy\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from utils.data_processing import *\n",
    "from logger.logger import setup_logging\n",
    "from utils.configs import BaseConf\n",
    "from utils.utils import write_json, Timer\n",
    "from models.kangkang_fnn_models import KangFeedForwardNetwork\n",
    "from dataloaders.flat_loader import FlatDataLoaders\n",
    "from datasets.flat_dataset import FlatDataGroup\n",
    "from utils.plots import DistributionPlotter\n",
    "from utils.metrics import PRCurvePlotter, ROCCurvePlotter, LossPlotter, CellPlotter\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from utils.mock_data import mock_fnn_data_classification\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.plots import im\n",
    "from utils.metrics import best_threshold, get_y_pred\n",
    "from models.model_result import ModelResult\n",
    "from models.baseline_models import ExponentialMovingAverage,\\\n",
    "                UniformMovingAverage, TriangularMovingAverage, HistoricAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'T24H-X85M-Y110M_2013-01-01_2015-01-01',\n",
       " 'T1H-X1700M-Y1760M_2013-01-01_2015-01-01',\n",
       " 'T24H-X255M-Y220M_2013-01-01_2015-01-01',\n",
       " 'T24H-X425M-Y440M_2013-01-01_2015-01-01',\n",
       " 'T24H-X850M-Y880M_2013-01-01_2015-01-01',\n",
       " 'T1H-X850M-Y880M_2013-01-01_2015-01-01']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./data/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-29T23:48:21 | root | INFO | =====================================BEGIN=====================================\n",
      "2019-10-29T23:48:21 | root | INFO | Device: cpu\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2013-01-01\"\n",
    "end_date = \"2015-01-01\" \n",
    "\n",
    "data_dim_str = \"T24H-X850M-Y880M\"  #\"T1H-X1700M-Y1760M\"  # needs to exist\n",
    "model_name = \"FNN-CRIME-MODEL\"  # needs to be created\n",
    "data_path = f\"./data/processed/{data_dim_str}_{start_date}_{end_date}/\"\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    raise Exception(f\"Directory ({data_path}) needs to exist.\")\n",
    "\n",
    "model_path = data_path + f\"models/{model_name}/\"\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# logging config is set globally thus we only need to call this in this file\n",
    "# imported function logs will follow the configuration\n",
    "setup_logging(save_dir=model_path, log_config='./logger/standard_logger_config.json', default_level=log.INFO)\n",
    "log.info(\"=====================================BEGIN=====================================\")\n",
    "\n",
    "timer = Timer()\n",
    "# manually set the config\n",
    "# manually set the config\n",
    "conf_dict = {\n",
    "    \"seed\": 3,\n",
    "    \"use_cuda\": False,\n",
    "    \n",
    "    \"use_crime_types\": False,\n",
    "    \n",
    "    # data group/data set related\n",
    "    \"val_ratio\": 0.1,  # ratio of the total dataset\n",
    "    \"tst_ratio\": 0.3,# ratio of the total dataset\n",
    "    \"seq_len\": 1,\n",
    "    \"flatten_grid\": True,  # if the shaper should be used to squeeze the data\n",
    "    \n",
    "    # shaper related \n",
    "    \"shaper_top_k\": -1,  # if less then 0, top_k will not be applied\n",
    "    \"shaper_threshold\": 0,\n",
    "\n",
    "    \n",
    "    # data loader related\n",
    "    \"sub_sample_train_set\": True,\n",
    "    \"sub_sample_validation_set\": True,\n",
    "    \"sub_sample_test_set\": False,\n",
    "    \n",
    "    # training parameters\n",
    "    \"resume\": False,\n",
    "    \"early_stopping\": False,\n",
    "    \"tolerance\": 1e-8,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-8,\n",
    "    \"max_epochs\": 1,\n",
    "    \"batch_size\": 64,\n",
    "    \"dropout\": 0.2,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 6,\n",
    "    \n",
    "    # attached global variables - bad practice -find alternative\n",
    "    \"device\": None,  # pytorch device object [CPU|GPU]\n",
    "    \"timer\": Timer(),\n",
    "    \"model_name\": model_name,\n",
    "    \"model_path\": model_path,\n",
    "    \"checkpoint\": \"best\",\n",
    "    \n",
    "    \"use_seq_loss\": True,\n",
    "}\n",
    "conf = BaseConf(conf_dict=conf_dict)\n",
    "\n",
    "info = deepcopy(conf.__dict__)\n",
    "info[\"start_time\"] = strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "# DATA LOADER SETUP\n",
    "np.random.seed(conf.seed)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed( conf.seed)\n",
    "else:\n",
    "    torch.manual_seed(conf.seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "log.info(f\"Device: {device}\")\n",
    "info[\"device\"] = device.type\n",
    "conf.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-29T23:48:21 | root | INFO | Data shapes of files in generated_data.npz\n",
      "2019-10-29T23:48:21 | root | INFO | \tcrime_feature_indices shape (10,)\n",
      "2019-10-29T23:48:21 | root | INFO | \tcrime_types_grids shape (730, 10, 47, 33)\n",
      "2019-10-29T23:48:21 | root | INFO | \tcrime_grids shape (730, 1, 47, 33)\n",
      "2019-10-29T23:48:21 | root | INFO | \ttract_count_grids shape (730, 1, 47, 33)\n",
      "2019-10-29T23:48:21 | root | INFO | \tdemog_grid shape (1, 37, 47, 33)\n",
      "2019-10-29T23:48:21 | root | INFO | \tstreet_grid shape (1, 512, 47, 33)\n",
      "2019-10-29T23:48:21 | root | INFO | \ttime_vectors shape (731, 52)\n",
      "2019-10-29T23:48:21 | root | INFO | \tweather_vectors shape (365, 11)\n",
      "2019-10-29T23:48:21 | root | INFO | \tx_range shape (33,)\n",
      "2019-10-29T23:48:21 | root | INFO | \ty_range shape (47,)\n",
      "2019-10-29T23:48:21 | root | INFO | \tt_range shape (731,)\n",
      "threshold: -1 - targets.shape: (729, 1, 770)\n",
      "class distribution: {0.0: 0.564881620437176, 1.0: 0.435118379562824}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the cells that we are dropping\n",
    "conf.shaper_threshold = 0\n",
    "conf.shaper_top_k = -1\n",
    "\n",
    "for i in [-1]:\n",
    "    conf.shaper_top_k = i\n",
    "    data_group = FlatDataGroup(data_path=data_path, conf=conf)\n",
    "    print(f\"threshold: {i} - targets.shape: {data_group.targets.shape}\")\n",
    "    vals, counts = np.unique(data_group.targets,return_counts=True)\n",
    "    counts = counts/np.sum(counts)\n",
    "    dist = dict(zip(vals,counts))\n",
    "    print(f\"class distribution: {dist}\")\n",
    "    \n",
    "    sorted_indices = data_group.sorted_indices\n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(data_group.shaper.unsqueeze(data_group.crimes)[:,0].mean(0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-29T23:48:25 | root | INFO | Data shapes of files in generated_data.npz\n",
      "2019-10-29T23:48:25 | root | INFO | \tcrime_feature_indices shape (10,)\n",
      "2019-10-29T23:48:25 | root | INFO | \tcrime_types_grids shape (730, 10, 47, 33)\n",
      "2019-10-29T23:48:25 | root | INFO | \tcrime_grids shape (730, 1, 47, 33)\n",
      "2019-10-29T23:48:25 | root | INFO | \ttract_count_grids shape (730, 1, 47, 33)\n",
      "2019-10-29T23:48:25 | root | INFO | \tdemog_grid shape (1, 37, 47, 33)\n",
      "2019-10-29T23:48:25 | root | INFO | \tstreet_grid shape (1, 512, 47, 33)\n",
      "2019-10-29T23:48:25 | root | INFO | \ttime_vectors shape (731, 52)\n",
      "2019-10-29T23:48:25 | root | INFO | \tweather_vectors shape (365, 11)\n",
      "2019-10-29T23:48:25 | root | INFO | \tx_range shape (33,)\n",
      "2019-10-29T23:48:25 | root | INFO | \ty_range shape (47,)\n",
      "2019-10-29T23:48:25 | root | INFO | \tt_range shape (731,)\n"
     ]
    }
   ],
   "source": [
    "conf.shaper_threshold = 0\n",
    "conf.shaper_top_k = -1\n",
    "\n",
    "# CRIME DATA\n",
    "data_group = FlatDataGroup(data_path=data_path, conf=conf)\n",
    "loaders = FlatDataLoaders(data_group=data_group, conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_set_size = data_group.testing_set.target_shape[0]\n",
    "crimes = data_group.shaper.unsqueeze(data_group.crimes)\n",
    "im(crimes.mean(0)[0])\n",
    "crimes = data_group.crimes\n",
    "t_range = data_group.t_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historic average model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using time step: 1\n",
      "2019-10-29T23:22:49 | root | INFO | f1_score: 0.7256978172389156 at index 84344, new threshold 0.0883857531569978\n"
     ]
    }
   ],
   "source": [
    "# time step in this context is used for \n",
    "freqstr = t_range.freqstr\n",
    "time_step = int(24 / int(freqstr[:freqstr.find(\"H\")]))\n",
    "\n",
    "print(f\"using time step: {time_step}\")\n",
    "\n",
    "ha = HistoricAverage(step=time_step)\n",
    "all_crimes = data_group.crimes[:,0]\n",
    "all_targets = data_group.targets\n",
    "tst_targets = data_group.testing_set.targets\n",
    "all_crimes_ha = ha(all_crimes)  # todo re-write using the convolve function - it loses the \n",
    "tst_crimes_ha = all_crimes_ha[-len(tst_targets):]\n",
    "trn_crimes_ha = all_crimes_ha[time_step+1:len(tst_targets)] # skip all the nan values\n",
    "trn_targets = all_targets[time_step+1:len(tst_targets)]\n",
    "\n",
    "\n",
    "N,_,L = tst_targets.shape\n",
    "\n",
    "\n",
    "thresh = best_threshold(trn_targets, trn_crimes_ha) # should only come from the train predictions\n",
    "\n",
    "y_true = tst_targets\n",
    "probas_pred = tst_crimes_ha\n",
    "y_pred = get_y_pred(thresh, probas_pred)  # might want to do this for each cell either?\n",
    "\n",
    "# alternatively - might want to do this for each cell either?\n",
    "# thresholds_ha = []\n",
    "# y_pred = np.empty_like(y_true)\n",
    "# for i in range(L):\n",
    "#     # important note thresh should eb for the training data\n",
    "#     thresh = best_threshold(y_true=trn_targets[:,i],probas_pred=trn_crimes_ha[:,i], verbose=False)  \n",
    "#     thresholds_ha.append(thresh)\n",
    "#     y_pred[:,i] = get_y_pred(thresh, probas_pred[:,i])\n",
    "    \n",
    "ha_model_result = ModelResult(model_name=f\"HA One Thresh {time_step}\",\n",
    "                                y_true=y_true,\n",
    "                                y_pred=y_pred,\n",
    "                                probas_pred=probas_pred,\n",
    "                                t_range=data_group.testing_set.t_range,\n",
    "                                shaper=data_group.shaper)\n",
    "\n",
    "model_results.append(ha_model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ha_model_result.pkl\",\"wb\") as file:\n",
    "    pickle.dump(ha_model_result, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ha_model_result.pkl\",\"rb\") as file:\n",
    "    old_result = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364980,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ha_model_result.y_pred.shape\n",
    "# im(old_result.shaper.unsqueeze(old_result.y_true).mean(0)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean of training data as future prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of training data as future prediction\n",
    "trn_crimes = data_group.training_set.crimes\n",
    "\n",
    "# only get the mean of the trn_set\n",
    "crimes_mean = np.mean(trn_crimes[:,0],axis=0,keepdims=True)  # keep dims used to make scalar product easy\n",
    "crimes_ones = np.ones_like(data_group.testing_set.targets)\n",
    "y_pred_sparse = crimes_mean*crimes_ones\n",
    "tst_targets = data_group.testing_set.targets\n",
    "\n",
    "N,L = tst_targets.shape\n",
    "targets_shape = N,L\n",
    "\n",
    "\n",
    "y_pred_dense = y_pred_sparse\n",
    "\n",
    "probas_pred = y_pred_dense.flatten()\n",
    "y_true = tst_targets.flatten()\n",
    "thresh = best_threshold(y_true, probas_pred) # should only come from the train predictions\n",
    "y_pred = np.copy(probas_pred)\n",
    "y_pred[y_pred >= thresh] = 1\n",
    "y_pred[y_pred < thresh] = 0\n",
    "\n",
    "mean_model_result = ModelResult(model_name=\"Train Mean\",\n",
    "                                y_true=y_true,\n",
    "                                y_pred=y_pred,\n",
    "                                probas_pred=probas_pred,\n",
    "                                t_range=data_group.testing_set.t_range,\n",
    "                                shaper=data_group.shaper)\n",
    "\n",
    "model_results.append(mean_model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling mean of all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window_len in [time_step*7]:\n",
    "    for alpha in [1e1, 1e2,1e-1]:\n",
    "        ma = ExponentialMovingAverage(alpha=alpha,window_len=window_len)\n",
    "        all_crimes = data_group.crimes[:,0]\n",
    "        tst_targets = data_group.testing_set.targets\n",
    "        all_crimes_ma = ma(all_crimes)\n",
    "        tst_crimes_ma = all_crimes_ma[-len(tst_targets):]\n",
    "\n",
    "        N,L = tst_targets.shape\n",
    "        targets_shape = N,L\n",
    "\n",
    "        targets_dense = tst_targets\n",
    "\n",
    "        y_pred_dense = tst_crimes_ma\n",
    "\n",
    "        probas_pred = y_pred_dense.flatten()\n",
    "        y_true = targets_dense.flatten()\n",
    "\n",
    "        thresh = best_threshold(y_true, probas_pred) # should only come from the train predictions\n",
    "        y_pred = np.copy(probas_pred)\n",
    "        y_pred[y_pred >= thresh] = 1\n",
    "        y_pred[y_pred < thresh] = 0\n",
    "\n",
    "        ma_model_result = ModelResult(model_name=f\"EMA window={window_len}, alpha={alpha}\",\n",
    "                                        y_true=y_true,\n",
    "                                        y_pred=y_pred,\n",
    "                                        probas_pred=probas_pred,\n",
    "                                        t_range=data_group.testing_set.t_range,\n",
    "                                        shaper=data_group.shaper)\n",
    "\n",
    "        model_results.append(ma_model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding random noise to the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_std in [0.4,0.8]:\n",
    "    tst_crimes = data_group.testing_set.targets  # only mask the targets as the outputs\n",
    "\n",
    "\n",
    "    noise = noise_std*np.random.randn(*np.shape(tst_crimes))\n",
    "    # should be a flip seeing that the class distribution is so skew\n",
    "\n",
    "    y_pred_sparse = tst_crimes + noise\n",
    "    targets_dense = data_group.testing_set.targets\n",
    "    y_pred_dense = y_pred_sparse\n",
    "\n",
    "    probas_pred = y_pred_dense.flatten()\n",
    "    \n",
    "    N,L = targets_dense.shape\n",
    "    targets_shape = N,L\n",
    "    \n",
    "    y_true = targets_dense.flatten()\n",
    "    thresh = best_threshold(y_true, probas_pred) # should only come from the train predictions\n",
    "    y_pred = np.copy(probas_pred)\n",
    "    y_pred[y_pred >= thresh] = 1\n",
    "    y_pred[y_pred < thresh] = 0\n",
    "\n",
    "    noise_model_result = ModelResult(model_name=f\"Noise model std={noise_std}\",\n",
    "                                    y_true=y_true,\n",
    "                                    y_pred=y_pred,\n",
    "                                    probas_pred=probas_pred,\n",
    "                                    t_range=data_group.testing_set.t_range,\n",
    "                                     shaper=data_group.shaper)\n",
    "\n",
    "    model_results.append(noise_model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for result in model_results:\n",
    "    print(result)\n",
    "\n",
    "pr_plotter = PRCurvePlotter()\n",
    "for result in model_results:\n",
    "    pr_plotter.add_curve(result.y_true, result.probas_pred, label_name=result.model_name)\n",
    "pr_plotter.show()\n",
    "# pr_plotter.savefig(model_path + \"plot_pr_curve.png\")\n",
    "\n",
    "roc_plotter = ROCCurvePlotter()\n",
    "for result in model_results:\n",
    "    roc_plotter.add_curve(result.y_true, result.probas_pred, label_name=result.model_name)\n",
    "roc_plotter.show()\n",
    "# roc_plotter.savefig(model_path + \"plot_roc_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo create function do unflatten y_true, y_probs, and probas_true\n",
    "# use shape of the model and just rnp.reshape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Hawkes Model](https://x-datainitiative.github.io/tick/modules/generated/tick.hawkes.HawkesSumExpKern.html)\n",
    "does support multi variate but we are only using univariate for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis Hawks-proces using the EM kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo get average using convolutions given the kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tick.plot import plot_hawkes_kernels\n",
    "from tick.hawkes import SimuHawkesSumExpKernels, SimuHawkesMulti, \\\n",
    "    HawkesSumExpKern, HawkesEM\n",
    "\n",
    "\n",
    "class IndHawkesModel:\n",
    "    \"\"\"\n",
    "    Indipendent Hawkes Modles where all cells are indipendent\n",
    "    \n",
    "    Using Tikc library from:\n",
    "    - https://x-datainitiative.github.io/tick/modules/generated/tick.hawkes.HawkesSumExpKern.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.baselines = []   \n",
    "        self.kernels = []\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        data: (N,L)\n",
    "        \"\"\"\n",
    "        N, L = data.shape\n",
    "        self.baselines = []\n",
    "        self.kernels = []\n",
    "\n",
    "        # convert into format for the hawkes trainer\n",
    "        for i in range(L):\n",
    "            realizations = []\n",
    "            data_counts = data[:,i]\n",
    "            time_stamps = np.argwhere(data_counts).astype(np.float)\n",
    "            realizations.append([time_stamps[:,0]])\n",
    "\n",
    "            # kernel_discretization if set explicitly it overrides kernel_support and kernel_size\n",
    "            # todo: have kernel values be set by conf_dict\n",
    "            em = HawkesEM(kernel_discretization=np.arange(self.kernel_size).astype(np.float),\n",
    "                          n_threads=8,\n",
    "                          verbose=False,\n",
    "                          tol=1e-3,\n",
    "                          max_iter=1000)\n",
    "            em.fit(realizations)\n",
    "            baseline = em.baseline.flatten()[0]\n",
    "            kernel = em.kernel.flatten()\n",
    "            self.baselines.append(baseline)\n",
    "            self.kernels.append(kernel)\n",
    "\n",
    "        \n",
    "    def transform(self, data):\n",
    "        # todo consider training saving a kernel AND baseline for each cell\n",
    "        # kernels -> (N,L,kernel_size)\n",
    "        # baselines -> (N,L,1)\n",
    "        N,L = np.shape(data)\n",
    "        result = np.empty_like(data)\n",
    "        for i in range(L):    \n",
    "            result[:,i] = self.baselines[i] + np.convolve(data[:,i],self.kernels[i])[:N]\n",
    "        return result\n",
    "    \n",
    "    def fit_transform(self,data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_inpt = data_group.training_set.crimes[:,0]\n",
    "trn_trg = data_group.training_set.targets\n",
    "\n",
    "tst_inpt = data_group.testing_set.crimes[:,0]\n",
    "tst_trg = data_group.testing_set.targets\n",
    "\n",
    "\n",
    "N,L = np.shape(trn_inpt)\n",
    "\n",
    "model = IndHawkesModel(kernel_size=time_step*21 + 1)\n",
    "trn_out = model.fit_transform(trn_inpt)\n",
    "tst_out = model.transform(tst_inpt)\n",
    "\n",
    "y_true = tst_trg\n",
    "probas_pred = tst_out\n",
    "thresh = best_threshold(y_true, probas_pred) # should only come from the train predictions\n",
    "y_pred = get_y_pred(thresh, probas_pred)  # might want to do this for each cell either?\n",
    "\n",
    "hawkes_ind_model = ModelResult(model_name=f\"Hawkes Independent Cells\",\n",
    "                                y_true=y_true,\n",
    "                                y_pred=y_pred,\n",
    "                                probas_pred=probas_pred,\n",
    "                                t_range=data_group.testing_set.t_range,\n",
    "                               shaper=data_group.shaper)\n",
    "\n",
    "model_results.append(hawkes_ind_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = np.array(model.kernels)\n",
    "kernel_mean = np.mean(kernels,0)\n",
    "kernel_std = np.std(kernels,0)\n",
    "plt.plot(kernel_mean,alpha=.4)\n",
    "\n",
    "x = np.concatenate([np.arange(len(kernel_mean)),np.arange(len(kernel_mean))[::-1]])\n",
    "y = np.concatenate([kernel_mean-1.5*kernel_std,np.array(kernel_mean+1.5*kernel_std)[::-1]])\n",
    "plt.fill(x,y,alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HawkesModelGeneral:\n",
    "    \"\"\"\n",
    "    Using the HawkesEM learner from Tick library\n",
    "    \n",
    "    Using Tikc library from:\n",
    "    - https://x-datainitiative.github.io/tick/modules/generated/tick.hawkes.HawkesSumExpKern.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.kernel = None\n",
    "        self.baseline = None\n",
    "        self.em = None  \n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        data: (N,L)\n",
    "        \"\"\"\n",
    "        N, L = data.shape\n",
    "\n",
    "        # convert into format for the hawkes trainer\n",
    "        realizations = []\n",
    "        for i in range(L):\n",
    "            data_counts = data[:,i]\n",
    "            time_stamps = np.argwhere(data_counts).astype(np.float)\n",
    "        realizations.append([time_stamps[:,0]])\n",
    "\n",
    "        # kernel_discretization if set explicitly it overrides kernel_support and kernel_size\n",
    "        # todo: have kernel values be set by conf_dict\n",
    "        self.em = HawkesEM(kernel_discretization=np.arange(self.kernel_size).astype(np.float),\n",
    "                      n_threads=8,\n",
    "                      verbose=False,\n",
    "                      tol=1e-3,\n",
    "                      max_iter=1000)\n",
    "        self.em.fit(realizations)\n",
    "        self.baseline = self.em.baseline.flatten()[0]\n",
    "        self.kernel = self.em.kernel.flatten()\n",
    "\n",
    "        \n",
    "    def transform(self, data):\n",
    "        # todo consider training saving a kernel AND baseline for each cell\n",
    "        # kernels -> (N,L,kernel_size)\n",
    "        # baselines -> (N,L,1)\n",
    "        N,L = np.shape(data)\n",
    "        result = np.empty_like(data)\n",
    "        for i in range(L):    \n",
    "            result[:,i] = self.baseline + np.convolve(data[:,i],self.kernel)[:N]\n",
    "        return result\n",
    "    \n",
    "    def fit_transform(self,data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "    \n",
    "    def plot_kernel(self):\n",
    "        plot_hawkes_kernels(self.em, hawkes=None, show=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_inpt = data_group.training_set.crimes[:,0]\n",
    "trn_trg = data_group.training_set.targets\n",
    "\n",
    "tst_inpt = data_group.testing_set.crimes[:,0]\n",
    "tst_trg = data_group.testing_set.targets\n",
    "\n",
    "\n",
    "N,L = np.shape(trn_inpt)\n",
    "\n",
    "model = HawkesModelGeneral(kernel_size=time_step*20 + 1)\n",
    "trn_out = model.fit_transform(trn_inpt)\n",
    "tst_out = model.transform(tst_inpt)\n",
    "\n",
    "y_true = tst_trg\n",
    "probas_pred = tst_out\n",
    "thresh = best_threshold(y_true, probas_pred) # should only come from the train predictions\n",
    "y_pred = get_y_pred(thresh, probas_pred)  # might want to do this for each cell either?\n",
    "\n",
    "hawkes_general_model = ModelResult(model_name=f\"Hawkes General Model\",\n",
    "                                y_true=y_true,\n",
    "                                y_pred=y_pred,\n",
    "                                probas_pred=probas_pred,\n",
    "                                t_range=data_group.testing_set.t_range,\n",
    "                                   shaper=data_group.shaper)\n",
    "\n",
    "model_results.append(hawkes_general_model)\n",
    "\n",
    "plt.plot(model.kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try and get cosine similarity between the kernels and baselines - should give a good indicaiton if we can compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISSUE: is that we have some cells where no crime takes place - in either the testing or the training set\n",
    "### thougths - look for data where to ranking of the cells actually changes with time - this will indicate how much crime actaully moves arround over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trn_inpt = data_group.training_set.crimes[:,0]\n",
    "trn_trg = data_group.training_set.targets\n",
    "\n",
    "tst_inpt = data_group.testing_set.crimes[:,0]\n",
    "tst_trg = data_group.testing_set.targets\n",
    "\n",
    "\n",
    "N,L = np.shape(trn_inpt)\n",
    "\n",
    "model = IndHawkesModel(kernel_size=time_step*3 + 1)\n",
    "trn_out = model.fit_transform(trn_inpt)\n",
    "tst_out = model.transform(tst_inpt)\n",
    "\n",
    "limit = 200\n",
    "top_k = 10\n",
    "i = 3000\n",
    "\n",
    "\n",
    "# todo check how this influences the ROC and PR curves\n",
    "def i2p(intensity):\n",
    "    \"\"\"\n",
    "    intensity to probability\n",
    "    \"\"\"\n",
    "    return 1 - np.exp(-1*intensity)\n",
    "    \n",
    "       \n",
    "for i in range(top_k):\n",
    "    for j in range(2):\n",
    "        print(f\"-------------------------------{j}----------------------------------\")\n",
    "        plt.figure(figsize=(10,2))\n",
    "        plt.plot(tst_trg[i:i+limit,i])\n",
    "\n",
    "        y_true = tst_trg[:,i]\n",
    "        if j == 0:\n",
    "            probas_pred = i2p(tst_out[:,i])\n",
    "        else:     \n",
    "            probas_pred = tst_out[:,i]\n",
    "\n",
    "        thresh = best_threshold(y_true, probas_pred) # should only come from the train predictions\n",
    "        y_pred = np.copy(probas_pred)\n",
    "        y_pred[y_pred >= thresh] = 1\n",
    "        y_pred[y_pred < thresh] = 0\n",
    "\n",
    "        print(classification_report(y_true=y_true,y_pred=y_pred))\n",
    "\n",
    "        plt.plot(y_pred[i:i+limit])\n",
    "        plt.plot(probas_pred[i:i+limit])\n",
    "    #     plt.ylim([0,1])\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"------------------------------------------------------------------\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,4,100))\n",
    "plt.plot(i2p(np.linspace(0,4,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for realization in realizations[:5]:#multi.timestamps:\n",
    "    plt.figure(figsize=(10,1))\n",
    "    for var in realization:\n",
    "        plt.scatter(var, np.ones_like(var), alpha=.2, marker=\"|\")    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dummy = DummyClassifier(strategy='prior')\n",
    "dummy.fit(X,y)\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X,y)\n",
    "\n",
    "print(\"log_reg:\",accuracy_score(y, lr.predict_proba(X)[:,1].round()))\n",
    "\n",
    "for strat in ['stratified', 'most_frequent', 'prior', 'uniform']:\n",
    "    dummy = DummyClassifier(strategy=strat)\n",
    "    dummy.fit(X,y)\n",
    "    print(f\"dummy ({strat}):\",accuracy_score(y, dummy.predict_proba(X)[:,1].round()))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(X.shape, y.shape)\n",
    "get mean model as the starting position.\n",
    "then train with only the new values to see the difference\n",
    "print(data_group.crimes[:,0].shape)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                         multi_class='multinomial')\n",
    "\n",
    "clf..fit(X, y)\n",
    "clf.predict(X[:2, :])\n",
    "clf.predict_proba(X[:2, :]) \n",
    "clf.score(X, y)\n",
    "\n",
    "print(f\"clf.coef_ -> {clf.coef_}\")\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "X = data_group.crimes[:400,0,data_group.sorted_indices]\n",
    "aspect = X.shape[1]/X.shape[0]\n",
    "\n",
    "plt.imshow(X=X,aspect=aspect,cmap='viridis')\n",
    "plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
